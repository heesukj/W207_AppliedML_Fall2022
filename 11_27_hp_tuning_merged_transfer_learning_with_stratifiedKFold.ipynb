{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/W207_AppliedML_Fall2022/blob/main/11_27_hp_tuning_merged_transfer_learning_with_stratifiedKFold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import random\n",
        "from itertools import product\n",
        "import gc\n",
        "import subprocess\n",
        "import shutil\n",
        "import copy\n",
        "import statistics as st\n",
        "from scipy import stats\n",
        "\n",
        "from imutils import rotate as rotate\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from skimage.color import gray2rgb\n",
        "import skimage.io as skio\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import classification_report, cohen_kappa_score, zero_one_loss\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# from tensorflow.keras.preprocessing.image import array_to_img\n",
        "# from tensorflow.keras.preprocessing.image import img_to_array\n",
        "# from tensorflow.keras.preprocessing.image import load_img\n",
        "# from tensorflow.keras.preprocessing.image import save_img\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
        "#from livelossplot import PlotLossesKeras\n",
        "\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Multiply\n",
        "# from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import RandomFlip, RandomZoom, RandomRotation, Conv2D, AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import PReLU, ReLU, LeakyReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import SeparableConv1D\n",
        "from keras.layers.convolutional import SeparableConv2D \n",
        "from keras.layers.core import Activation\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad, RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import *\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.nasnet import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import *\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, save_img\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.applications import ResNet152V2, VGG16, VGG19\n",
        "\n",
        "tf.get_logger().setLevel('INFO')\n",
        "\n",
        "import cv2 as cv\n",
        "import skimage.io as io\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "AqvUA0UoCPSd",
        "outputId": "46e64336-1625-4ca6-ddb8-cf559808db7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-174109d93f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mephemeral\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       readonly=readonly)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 125\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random_state = 1234\n",
        "\n",
        "# def build_transfer_learning_model(chosen_modelel):\n",
        "#     \"\"\"\n",
        "#     This function utilizes transfer learning of a given model.\n",
        "#     \"\"\"\n",
        "#     tf.random.set_seed(random_state)\n",
        "#     np.random.seed(random_state)\n",
        "#     tf.keras.backend.clear_session()\n",
        "#     input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "#     if chosen_model == 'VGG19':\n",
        "#         model_tl = VGG19(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     elif chosen_model == 'DenseNet201':\n",
        "#         model_tl = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     elif chosen_model == 'ResNet50':\n",
        "#         model_tl = tf.keras.applications.resnet50.ResNet50(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     elif chosen_model == 'VGG16':\n",
        "#         model_tl = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     elif chosen_model == 'EfficientNetB7':\n",
        "#         model_tl = tf.keras.applications.efficientnet.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     elif chosen_model == 'MobileNet':\n",
        "#         model_tl = tf.keras.applications.MobileNet(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     elif chosen_model == 'Xception':\n",
        "#         model_tl = tf.keras.applications.Xception(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     elif chosen_model == 'InceptionV3':\n",
        "#         model_tl = tf.keras.applications.InceptionV3(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "#     return model_tl\n"
      ],
      "metadata": {
        "id": "TQpQkoi5N07r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chosen_model = 'ResNet50'\n",
        "# IMG_SIZE = 96\n",
        "# dropout_rate = .5"
      ],
      "metadata": {
        "id": "fufUTTNQOHxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random_state = 1234\n",
        "\n",
        "# model_tl = build_transfer_learning_model(chosen_model = chosen_model)\n",
        "# model_tl.trainable = False\n",
        "        \n",
        "# # Plug the pre-trained model to custom model\n",
        "# print(f\"Plugging in the pretainined model for {chosen_model} to custom model\")\n",
        "# try:\n",
        "#     del model\n",
        "# except:\n",
        "#     None\n",
        "# input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "# inputs = tf.keras.Input(input_shape)\n",
        "# m_tltl = tf.keras.layers.GlobalAveragePooling2D()(model_tl(inputs))\n",
        "# m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "# m_tl = tf.keras.layers.Dense(512, activation = 'relu')(m_tl)\n",
        "# m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "# m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "# m_tl = tf.keras.layers.Dense(256, activation = 'relu')(m_tl)\n",
        "# m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "# m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "# m_tl = tf.keras.layers.Flatten()(m_tl)\n",
        "# m_tl = tf.keras.layers.Dense(1, activation = None)(m_tl)\n",
        "# model = tf.keras.Model(inputs = inputs, outputs = m_tl)"
      ],
      "metadata": {
        "id": "zMJktLhlN52U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.utils.plot_model(model)"
      ],
      "metadata": {
        "id": "1yl8KLZbOqcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/MyDrive/Kaggle/CNN_IDC/Dataset.zip                  "
      ],
      "metadata": {
        "id": "ftiQ04jV6roA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete a full folder including all its files and subfolders\n",
        "!rm -rf processed_images/                    "
      ],
      "metadata": {
        "id": "dFwV9FlsaApf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr Dataset"
      ],
      "metadata": {
        "id": "WjE-qGmqW9qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ls -ltr: List the contents of the current directory in the long listing format ( -l ), \n",
        "#   sorted by modification time ( -t ) in reverse order ( -r ) of all files and directories beginning with file* .\n",
        "# wc -l: count the number of lines\n",
        "\n",
        "!ls -ltr Dataset/Train/0|wc -l\n",
        "!ls -ltr Dataset/Train/1|wc -l\n",
        "\n",
        "!ls -ltr Dataset/Test/0|wc -l\n",
        "!ls -ltr Dataset/Test/1|wc -l\n",
        "\n",
        "!ls -ltr Dataset/Validate/0|wc -l\n",
        "!ls -ltr Dataset/Validate/1|wc -l"
      ],
      "metadata": {
        "id": "rNK-XNrxXBVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_image_directory = '/content/Dataset/Validate'\n",
        "train_image_directory = '/content/Dataset/Train'\n",
        "test_image_directory = '/content/Dataset/Test'\n",
        "directory_path = '/content/Dataset'\n",
        "\n",
        "tgt_directory_path = '/content/processed_images'\n",
        "tgt_train_1_image_path = '/content/processed_images/train/1/'\n",
        "tgt_train_0_image_path = '/content/processed_images/train/0/'\n",
        "tgt_val_1_image_path = '/content/processed_images/val/1/'\n",
        "tgt_val_0_image_path = '/content/processed_images/val/0/'\n",
        "tgt_test_1_image_path = '/content/processed_images/test/1/'\n",
        "tgt_test_0_image_path = '/content/processed_images/test/0/'\n",
        "\n",
        "tgt_path_list = [tgt_train_1_image_path, tgt_train_0_image_path,\n",
        "                 tgt_val_1_image_path, tgt_val_0_image_path,\n",
        "                 tgt_test_1_image_path, tgt_test_0_image_path\n",
        "                ]"
      ],
      "metadata": {
        "id": "UATtHsgNSRqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data_dir):\n",
        "  images_path_1 = [data_dir + '/' +  dir + '/' for dir in os.listdir(data_dir) if dir != '.DS_Store'][0]\n",
        "  images_path_0 = [data_dir + '/' +  dir + '/' for dir in os.listdir(data_dir) if dir != '.DS_Store'][1]\n",
        "\n",
        "  images_list_1 = [images_path_1 + file for file in list(os.walk(images_path_1))[0][2] if file[0] != '.']\n",
        "  images_list_0 = [images_path_0 + file for file in list(os.walk(images_path_0))[0][2] if file[0] != '.']\n",
        "\n",
        "  return images_list_1, images_list_0\n"
      ],
      "metadata": {
        "id": "F0Q-ykr5SbLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1_images_path = [train_image_directory + '/' +  dir + '/' for dir in os.listdir(train_image_directory) if dir != '.DS_Store'][0]\n",
        "train_0_images_path = [train_image_directory + '/' +  dir + '/' for dir in os.listdir(train_image_directory) if dir != '.DS_Store'][1]\n",
        "\n",
        "test_1_images_path = [test_image_directory + '/' +  dir + '/' for dir in os.listdir(test_image_directory) if dir != '.DS_Store'][0]\n",
        "test_0_images_path = [test_image_directory + '/' +  dir + '/' for dir in os.listdir(test_image_directory) if dir != '.DS_Store'][1]\n",
        "\n",
        "val_1_images_path = [val_image_directory + '/' +  dir + '/' for dir in os.listdir(val_image_directory) if dir != '.DS_Store'][0]\n",
        "val_0_images_path = [val_image_directory + '/' +  dir + '/' for dir in os.listdir(val_image_directory) if dir != '.DS_Store'][1]"
      ],
      "metadata": {
        "id": "dh1GbkYSTXYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1_images_list = [train_1_images_path + file for file in list(os.walk(train_1_images_path))[0][2] if file[0] != '.']\n",
        "train_0_images_list = [train_0_images_path + file for file in list(os.walk(train_0_images_path))[0][2] if file[0] != '.']\n",
        "\n",
        "test_1_images_list = [test_1_images_path + file for file in list(os.walk(test_1_images_path))[0][2] if file[0] != '.']\n",
        "test_0_images_list = [test_0_images_path + file for file in list(os.walk(test_0_images_path))[0][2] if file[0] != '.']\n",
        "\n",
        "val_1_images_list = [val_1_images_path + file for file in list(os.walk(val_1_images_path))[0][2] if file[0] != '.']\n",
        "val_0_images_list = [val_0_images_path + file for file in list(os.walk(val_0_images_path))[0][2] if file[0] != '.']"
      ],
      "metadata": {
        "id": "zbL0x9QHShXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_1_images_list + train_0_images_list + test_1_images_list + test_0_images_list + val_1_images_list + val_0_images_list)"
      ],
      "metadata": {
        "id": "BmVWCg1geoxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_1_images_list), len(train_0_images_list), len(test_1_images_list), len(test_0_images_list), len(val_1_images_list), len(val_0_images_list)"
      ],
      "metadata": {
        "id": "XNjz53EpXpb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = load_img(train_1_images_list[0], color_mode =\"grayscale\")\n",
        "test_img_arry = img_to_array(test_img)\n",
        "print(type(test_img))\n",
        "print(test_img.format)\n",
        "print(test_img.mode)\n",
        "print(test_img.size)\n",
        "print(test_img.getbands())\n",
        "print(test_img_arry.shape)\n",
        "print(\"****\")\n",
        "test_img1 = load_img(train_1_images_list[0])\n",
        "test_img1_arry = img_to_array(test_img1)\n",
        "print(test_img1_arry.shape)\n",
        "print(test_img1.getbands())"
      ],
      "metadata": {
        "id": "V_g0AF4Xd-LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display the first 5 images for each class\n",
        ": IDC Malignant (1) vs. IDC Benign (0)\n"
      ],
      "metadata": {
        "id": "vVq4Le9MIfV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 50"
      ],
      "metadata": {
        "id": "UUgKYziVkc_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(subclass, class_name):\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(17,6))\n",
        "  for idx, ax in enumerate(axes.flat):\n",
        "    img = io.imread(subclass[idx])\n",
        "    img = cv.resize(img, (IMG_SIZE, IMG_SIZE))    # resize an image from 50 by 50 to 512 by 512\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(class_name)\n",
        "    # ax.set_xticks([])       # remove xticks passing an empty array\n",
        "    # ax.set_yticks([])       # remove yticks passing an empty array\n",
        "  fig.tight_layout() \n",
        "  plt.show() \n",
        "\n",
        "display_images(train_1_images_list, 'IDC Malignant (1)')\n",
        "display_images(train_0_images_list, ' IDC Benign (0)')"
      ],
      "metadata": {
        "id": "cbpAbSsOH9Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# RESIZED_SIZE = 62\n",
        "\n",
        "# fig = plt.figure(figsize=(22,9))\n",
        "\n",
        "# # orig_gs = load_img(train_1_images_list[0], color_mode =\"grayscale\")\n",
        "# # arr_orig_gs = img_to_array(orig_gs)\n",
        "\n",
        "# orig_cs = load_img(train_1_images_list[0], color_mode =\"rgb\")\n",
        "# arr_orig_cs = img_to_array(orig_cs)\n",
        "\n",
        "# # =============== Original =================================\n",
        "# original = io.imread(train_1_images_list[0], as_gray=False)\n",
        "# ax = fig.add_subplot(2,5,1)\n",
        "# ax.imshow(original)\n",
        "# ax.set_title(f\"Original: {IMG_SIZE} X {IMG_SIZE}\", size=14)\n",
        "\n",
        "# # # =============== Resize =================================\n",
        "# resize = cv.resize(original, (RESIZED_SIZE,RESIZED_SIZE))\n",
        "# # cv.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "# ax = fig.add_subplot(2,5,2)\n",
        "# ax.imshow(resize)\n",
        "# ax.set_title(f\"Resize: {RESIZED_SIZE} X {RESIZED_SIZE}\", size=14)\n",
        "\n",
        "# # =============== Horizontal Flip =========================\n",
        "# h_flip = cv2.flip(original, 1)\n",
        "# ax = fig.add_subplot(2,5,3)\n",
        "# ax.imshow(h_flip)\n",
        "# ax.set_title(f\"Horizontal Flip\", size=14)\n",
        "\n",
        "# # =============== Vertical Flip ===========================\n",
        "# v_flip = cv2.flip(original, 0)\n",
        "# ax = fig.add_subplot(2,5,4)\n",
        "# ax.imshow(v_flip)\n",
        "# ax.set_title(f\"Vertical Flip\", size=14)\n",
        "\n",
        "# # # =============== Rotation 45 =============================\n",
        "# rot_45 = int(random.uniform(-45, 45))\n",
        "# print('rot_45', rot_45)\n",
        "# # # h, w = arr_orig_cs.shape[:2]\n",
        "# # # print('h, w', h, w)\n",
        "# # M = cv2.getRotationMatrix2D((int(IMG_SIZE/2), int(IMG_SIZE/2)), rot_45, 1)\n",
        "# # rotated_img_gs = cv2.warpAffine(arr_orig_cs, M, (w, h))\n",
        "# # rotated_img_gs = img_to_array(rotated_img_gs)\n",
        "# # print(\"rot45****\")\n",
        "# ax = fig.add_subplot(2,5,5)\n",
        "# # ax.imshow(rotated_img_gs)\n",
        "# # cv2_imshow(rotated_img_gs)\n",
        "\n",
        "# rot90_img = tf.image.rot90(original, k=1)\n",
        "# ax.imshow(rot90_img)\n",
        "# # ax.axis('off')\n",
        "# ax.set_title('Rotate 90', size=14)\n",
        "\n",
        "\n",
        "# resized = cv2.resize(test_img_arry, (224, 224), interpolation = cv2.INTER_AREA) \n",
        "# print('Resized Dimensions : ',resized.shape) \n",
        "# cv2_imshow(resized)\n",
        "\n",
        "# # =============== Rotation 90 =============================\n",
        "# angle = int(random.uniform(-90, 90))\n",
        "# print('angle', angle)\n",
        "# # h, w = test_img_arry.shape[:2]\n",
        "# # M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "# # rotated_img_gs = cv2.warpAffine(test_img_arry, M, (w, h))\n",
        "# # rotated_img_gs = img_to_array(rotated_img_gs)\n",
        "# # print(\"rot90****\")\n",
        "# # cv2_imshow(rotated_img_gs)\n",
        "# # print();cv2_imshow(arr_original)\n",
        "\n",
        "# # =============== Rotation 180 ============================\n",
        "# # angle = int(random.uniform(-180, 180))\n",
        "# # h, w = test_img_arry.shape[:2]\n",
        "# # M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "# # rotated_img_gs = cv2.warpAffine(test_img_arry, M, (w, h))\n",
        "# # rotated_img_gs = img_to_array(rotated_img_gs)\n",
        "# # print(\"rot180****\")\n",
        "# # cv2_imshow(rotated_img_gs)\n",
        "\n",
        "# # # rotate ccw\n",
        "# # out=cv2.transpose(test_img_arry)\n",
        "# # out=cv2.flip(out,flipCode=0)\n",
        "# # rotated_img_gs = img_to_array(out)\n",
        "# # print(\"90ccwrot****\")\n",
        "# # cv2_imshow(out)\n",
        "\n",
        "# # out=cv2.transpose(test_img_arry)\n",
        "# # out=cv2.flip(out,flipCode=1)\n",
        "# # rotated_img_gs = img_to_array(out)\n",
        "# # print(\"90rot****\")\n",
        "# # cv2_imshow(out)\n"
      ],
      "metadata": {
        "id": "r7bXcuyZJhBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "test_img = load_img(train_1_images_list[0], color_mode =\"grayscale\")\n",
        "test_img_arry = img_to_array(test_img_arry)\n",
        "print(\"original****\")\n",
        "cv2_imshow(test_img_arry)\n",
        "\n",
        "hflip_img_gs = cv2.flip(test_img_arry, 1)\n",
        "vflip_img_gs = cv2.flip(test_img_arry, 0)\n",
        "print(\"vflip****\")\n",
        "cv2_imshow(vflip_img_gs)\n",
        "print(\"hflip****\")\n",
        "cv2_imshow(hflip_img_gs)\n",
        "\n",
        "angle = int(random.uniform(-90, 90))\n",
        "h, w = test_img_arry.shape[:2]\n",
        "M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "rotated_img_gs = cv2.warpAffine(test_img_arry, M, (w, h))\n",
        "rotated_img_gs = img_to_array(rotated_img_gs)\n",
        "print(\"rot90****\")\n",
        "cv2_imshow(rotated_img_gs)\n",
        "\n",
        "angle = int(random.uniform(-45, 45))\n",
        "h, w = test_img_arry.shape[:2]\n",
        "M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "rotated_img_gs = cv2.warpAffine(test_img_arry, M, (w, h))\n",
        "rotated_img_gs = img_to_array(rotated_img_gs)\n",
        "print(\"rot45****\")\n",
        "cv2_imshow(rotated_img_gs)\n",
        "\n",
        "angle = int(random.uniform(-180, 180))\n",
        "h, w = test_img_arry.shape[:2]\n",
        "M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "rotated_img_gs = cv2.warpAffine(test_img_arry, M, (w, h))\n",
        "rotated_img_gs = img_to_array(rotated_img_gs)\n",
        "print(\"rot180****\")\n",
        "cv2_imshow(rotated_img_gs)\n",
        "\n",
        "# rotate ccw\n",
        "out=cv2.transpose(test_img_arry)\n",
        "out=cv2.flip(out,flipCode=0)\n",
        "rotated_img_gs = img_to_array(out)\n",
        "print(\"90ccwrot****\")\n",
        "cv2_imshow(out)\n",
        "\n",
        "out=cv2.transpose(test_img_arry)\n",
        "out=cv2.flip(out,flipCode=1)\n",
        "rotated_img_gs = img_to_array(out)\n",
        "print(\"90rot****\")\n",
        "cv2_imshow(out)"
      ],
      "metadata": {
        "id": "TCVsAcTIzjXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized = cv2.resize(test_img_arry, (224, 224), interpolation = cv2.INTER_AREA) \n",
        "print('Resized Dimensions : ',resized.shape) \n",
        "cv2_imshow(resized)"
      ],
      "metadata": {
        "id": "5I6GPlMm_6GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odd_images = []\n",
        "def extract_odd_images(file_list, IMG_SIZE = 50):\n",
        "    for file_name in file_list:\n",
        "        test_img = load_img(file_name, color_mode =\"grayscale\")\n",
        "        test_img_arry = img_to_array(test_img)\n",
        "        if test_img_arry.shape[0] != IMG_SIZE or test_img_arry.shape[1] != IMG_SIZE:\n",
        "            odd_images.append(file_name)"
      ],
      "metadata": {
        "id": "ksYFBFjrdbFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_odd_images(train_1_images_list + train_0_images_list + test_1_images_list + test_0_images_list + val_1_images_list + val_0_images_list)"
      ],
      "metadata": {
        "id": "BewtIomPefkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odd_images"
      ],
      "metadata": {
        "id": "zcBUXUXqe6Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_0_images_list[:5]"
      ],
      "metadata": {
        "id": "oVtUbzBwSkOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_1_images_list[0].split(\"/\")[-1], train_1_images_list[0][:train_1_images_list[0].rfind(\"/\") + 1]"
      ],
      "metadata": {
        "id": "2BcU0Mx5ShaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf processed_images"
      ],
      "metadata": {
        "id": "MvNu2SfA9Kbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = 'processed_images'\n",
        "\n",
        "os.makedirs(f'{root_dir}', exist_ok = True)\n",
        "for dir in ['train', 'val', 'test']:\n",
        "    for sub_dir in ['1', '0']:\n",
        "        os.makedirs(f'{root_dir}/{dir}/{sub_dir}', exist_ok=True)"
      ],
      "metadata": {
        "id": "NuLyO5-kX9RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation"
      ],
      "metadata": {
        "id": "BK4hkV9niRAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gs_files(file_list, dest_dir, ind):\n",
        "  # print(file_list, dest_dir, ind)\n",
        "  lst_train_1_gs, lst_train_0_gs = [], []\n",
        "  lst_val_1_gs, lst_val_0_gs = [], []\n",
        "  lst_test_1_gs, lst_test_0_gs = [], []\n",
        "\n",
        "  file_extension = '.png'\n",
        "  for image_file in file_list:\n",
        "      #print(image_file)\n",
        "      if image_file[0] == '.' or image_file in odd_images:                                     # if image_file = .DS_Store or an odd image then ignore\n",
        "          continue\n",
        "      img_gs = load_img(image_file, color_mode = \"grayscale\")                                     # convert images from colorscale to grayscale\n",
        "      img_array_gs = img_to_array(img_gs)                                                         # convert grayscale images to array\n",
        "      #print(\"a\")\n",
        "      #img_array_gs = cv2.resize(img_array_gs, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "      \n",
        "      file_name = image_file.split(\"/\")[-1]                                                       # extract only filenames from the full file path\n",
        "      save_img(dest_dir + file_name.split(\".\")[0] + '_gs' + file_extension, img_array_gs)\n",
        "      if ind == 1:\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_gs' + file_extension)\n",
        "          \n",
        "          hflip_img_gs = cv2.flip(img_array_gs, 1)\n",
        "          img_array_hflip_gs = img_to_array(hflip_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_hflip_gs' + file_extension, img_array_hflip_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_hflip_gs' + file_extension)\n",
        "          #print(\"b\")\n",
        "\n",
        "          vflip_img_gs = cv2.flip(img_array_gs, 0)\n",
        "          img_array_vflip_gs = img_to_array(vflip_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_vflip_gs' + file_extension, img_array_vflip_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_vflip_gs' + file_extension)\n",
        "          #print(\"c\")\n",
        " \n",
        "          angle = int(random.uniform(-90, 90))\n",
        "          h, w = img_array_gs.shape[:2]\n",
        "          M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "          rotated_img_gs = cv2.warpAffine(img_array_gs, M, (w, h))\n",
        "          img_array_rotated_gs = img_to_array(rotated_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rotated_gs' + file_extension, img_array_rotated_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rotated_gs' + file_extension)\n",
        "         '''\n",
        "          angle = int(random.uniform(-279, 270))\n",
        "          h, w = img_array_gs.shape[:2]\n",
        "          M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "          rotated_img_gs = cv2.warpAffine(img_array_gs, M, (w, h))\n",
        "          img_array_rotated_gs = img_to_array(rotated_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_270rotated_gs' + file_extension, img_array_rotated_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_270rotated_gs' + file_extension)\n",
        "          \n",
        "          img_90rot_gs = cv2.rotate(img_gs, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
        "          img_array_90rot_gs = img_to_array(img_90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension, img_array_90rot_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension)\n",
        "          \n",
        "          img_180rot_gs = cv2.rotate(img_gs, cv2.cv2.ROTATE_180_CLOCKWISE)\n",
        "          img_array_180rot_gs = img_to_array(img_180rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_180rot_gs' + file_extension, img_array_180rot_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_180rot_gs' + file_extension)\n",
        "\n",
        "          img_270rot_gs = cv2.rotate(img_gs, cv2.cv2.ROTATE_270_CLOCKWISE)\n",
        "          img_array_270rot_gs = img_to_array(img_90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension, img_array_270rot_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension)\n",
        "          '''\n",
        "          img_gs = cv2.imread(image_file, 0)\n",
        "          #img_array_gs = img_to_array(img_gs)\n",
        "          img_array_enhanced_gs = cv2.equalizeHist(img_gs)\n",
        "          img_array_enhanced_gs = img_to_array(img_array_enhanced_gs)\n",
        "          #img_array_enhanced_gs = cv2.resize(img_array_enhanced_gs, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_enhance_gs' + file_extension, img_array_enhanced_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_enhanced_gs' + file_extension)\n",
        "          #print(\"d\")\n",
        "\n",
        "          img_ccw90rot_gs = cv2.transpose(img_array_gs)\n",
        "          img_ccw90rot_gs = cv2.flip(img_ccw90rot_gs, flipCode = 0)\n",
        "          rotatedccw90_img_gs = img_to_array(img_ccw90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_ccw90rot_gs' + file_extension, rotatedccw90_img_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_ccw90rot_gs' + file_extension)\n",
        "          #print(\"e\")\n",
        "\n",
        "          img_90rot_gs = cv2.transpose(img_array_gs)\n",
        "          img_90rot_gs = cv2.flip(img_90rot_gs, flipCode = 1)\n",
        "          rotated90_img_gs = img_to_array(img_90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension, rotated90_img_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension)\n",
        "          #print(\"f\")\n",
        "\n",
        "      elif ind == 2:\n",
        "          lst_train_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_gs' + file_extension)\n",
        "          hflip_img_gs = cv2.flip(img_array_gs, 1)\n",
        "          img_array_hflip_gs = img_to_array(hflip_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_hflip_gs' + file_extension, img_array_hflip_gs)\n",
        "          lst_train_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_hflip_gs' + file_extension)\n",
        "          #print(\"b\")\n",
        "\n",
        "          vflip_img_gs = cv2.flip(img_array_gs, 0)\n",
        "          img_array_vflip_gs = img_to_array(vflip_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_vflip_gs' + file_extension, img_array_vflip_gs)\n",
        "          lst_train_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_vflip_gs' + file_extension)\n",
        "          #print(\"c\")\n",
        "\n",
        "          angle = int(random.uniform(-90, 90))\n",
        "          h, w = img_array_gs.shape[:2]\n",
        "          M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "          rotated_img_gs = cv2.warpAffine(img_array_gs, M, (w, h))\n",
        "          img_array_rotated_gs = img_to_array(rotated_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rotated_gs' + file_extension, img_array_rotated_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rotated_gs' + file_extension)\n",
        "         '''\n",
        "          angle = int(random.uniform(-279, 270))\n",
        "          h, w = img_array_gs.shape[:2]\n",
        "          M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
        "          rotated_img_gs = cv2.warpAffine(img_array_gs, M, (w, h))\n",
        "          img_array_rotated_gs = img_to_array(rotated_img_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_270rotated_gs' + file_extension, img_array_rotated_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_270rotated_gs' + file_extension)\n",
        "          \n",
        "          img_90rot_gs = cv2.rotate(img_gs, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
        "          img_array_90rot_gs = img_to_array(img_90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension, img_array_90rot_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension)\n",
        "          \n",
        "          img_180rot_gs = cv2.rotate(img_gs, cv2.cv2.ROTATE_180_CLOCKWISE)\n",
        "          img_array_180rot_gs = img_to_array(img_180rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_180rot_gs' + file_extension, img_array_180rot_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_180rot_gs' + file_extension)\n",
        "\n",
        "          img_270rot_gs = cv2.rotate(img_gs, cv2.cv2.ROTATE_270_CLOCKWISE)\n",
        "          img_array_270rot_gs = img_to_array(img_90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension, img_array_270rot_gs)\n",
        "          lst_train_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension)\n",
        "          '''\n",
        "          img_gs = cv2.imread(image_file, 0)\n",
        "          #img_array_gs = img_to_array(img_gs)\n",
        "          img_array_enhanced_gs = cv2.equalizeHist(img_gs)\n",
        "          img_array_enhanced_gs = img_to_array(img_array_enhanced_gs)\n",
        "          #img_array_enhanced_gs = cv2.resize(img_array_enhanced_gs, (224, 224), interpolation = cv2.INTER_AREA)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_enhance_gs' + file_extension, img_array_enhanced_gs)\n",
        "          lst_train_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_enhanced_gs' + file_extension)\n",
        "          #print(\"d\")\n",
        "\n",
        "          img_ccw90rot_gs = cv2.transpose(img_array_gs)\n",
        "          img_ccw90rot_gs = cv2.flip(img_ccw90rot_gs, flipCode = 0)\n",
        "          rotatedccw90_img_gs = img_to_array(img_ccw90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_ccw90rot_gs' + file_extension, rotatedccw90_img_gs)\n",
        "          lst_train_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_ccw90rot_gs' + file_extension)\n",
        "          #print(\"e\")\n",
        "\n",
        "          img_90rot_gs = cv2.transpose(img_array_gs)\n",
        "          img_90rot_gs = cv2.flip(img_90rot_gs, flipCode = 1)\n",
        "          rotated90_img_gs = img_to_array(img_90rot_gs)\n",
        "          save_img(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension, rotated90_img_gs)\n",
        "          lst_train_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_90rot_gs' + file_extension)\n",
        "          #print(\"f\")\n",
        "      elif ind == 3:\n",
        "          lst_val_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_gs' + file_extension)\n",
        "      elif ind == 4:\n",
        "          lst_val_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_gs' + file_extension)\n",
        "      elif ind == 5:\n",
        "          lst_test_1_gs.append(dest_dir + file_name.split(\".\")[0] + '_gs' + file_extension)\n",
        "      elif ind == 6:\n",
        "          lst_test_0_gs.append(dest_dir + file_name.split(\".\")[0] + '_gs' + file_extension)\n",
        "              "
      ],
      "metadata": {
        "id": "3-MFsdu1Shc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/Dataset/Validate/0'))"
      ],
      "metadata": {
        "id": "RRzsJjRdYI-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_gs_files(train_1_images_list, tgt_train_1_image_path, 1)\n",
        "print(len(os.listdir('/content/Dataset/Train/1')))\n",
        "print(len(os.listdir(tgt_train_1_image_path)))\n",
        "create_gs_files(train_0_images_list, tgt_train_0_image_path, 2)\n",
        "print(len(os.listdir('/content/Dataset/Train/0')))\n",
        "print(len(os.listdir(tgt_train_0_image_path)))\n",
        "\n",
        "create_gs_files(val_1_images_list, tgt_val_1_image_path, 3)\n",
        "print(len(os.listdir('/content/Dataset/Validate/1')))\n",
        "print(len(os.listdir(tgt_val_1_image_path)))\n",
        "create_gs_files(val_0_images_list, tgt_val_0_image_path, 4)\n",
        "print(len(os.listdir('/content/Dataset/Validate/0')))\n",
        "print(len(os.listdir(tgt_val_0_image_path)))\n",
        "\n",
        "create_gs_files(test_1_images_list, tgt_test_1_image_path, 5)\n",
        "print(len(os.listdir('/content/Dataset/Test/1')))\n",
        "print(len(os.listdir(tgt_test_1_image_path)))\n",
        "create_gs_files(test_0_images_list, tgt_test_0_image_path, 6)\n",
        "print(len(os.listdir('/content/Dataset/Test/0')))\n",
        "print(len(os.listdir(tgt_test_0_image_path)))"
      ],
      "metadata": {
        "id": "Nn5sGtRqURP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/Dataset/Train/1/*.png|wc -l\n",
        "!ls -ltr /content/Dataset/Train/0/*.png|wc -l"
      ],
      "metadata": {
        "id": "X9_PlsJlbDak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltra /content/processed_images/train/1/*.png|wc -l\n",
        "!ls -ltra /content/processed_images/train/0/*.png|wc -l"
      ],
      "metadata": {
        "id": "I58crwAWUK-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def custom_augmentation(np_tensor):\n",
        " \n",
        "#     def random_contrast(np_tensor):\n",
        "#         return tf.image.random_contrast(np_tensor, 0.5, 2)\n",
        " \n",
        "#     def random_hue(np_tensor):\n",
        "#         return tf.image.random_hue(np_tensor, 0.5)\n",
        " \n",
        "#     def random_saturation(np_tensor):\n",
        "#         return tf.image.random_saturation(np_tensor, 0.2, 3)\n",
        " \n",
        "#     def gaussian_noise(np_tensor):\n",
        "#         mean = 0\n",
        "#         # variance: randomly between 1 to 25\n",
        "#         var = np.random.randint(1, 26)\n",
        "#         # sigma is square root of the variance value\n",
        "#         noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n",
        "#         return np.clip(np_tensor + noise, 0, 255).astype('int')\n",
        "\n",
        "#     augmnted_tensor = random_contrast(np_tensor)\n",
        "#     augmnted_tensor = random_hue(augmnted_tensor)\n",
        "#     augmnted_tensor = random_saturation(augmnted_tensor)\n",
        "#     augmented_tensor = gaussian_noise(augmnted_tensor)\n",
        "  \n",
        "#     return np.array(augmnted_tensor)\n",
        "\n",
        "# # Train data generator\n",
        "# train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#     #featurewise_center            = True, \n",
        "#     #featurewise_std_normalization = True,\n",
        "#     rescale                       = 1.0/255\n",
        "# )\n",
        "\n",
        "# # Validation data generator\n",
        "# val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#     #featurewise_center            = True, \n",
        "#     #featurewise_std_normalization = True\n",
        "#     rescale = 1.0/255\n",
        "#     )\n",
        "\n",
        "# # Test data generator\n",
        "# test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "#     #featurewise_center            = True, \n",
        "#     #featurewise_std_normalization = True\n",
        "#     rescale = 1.0/255\n",
        "#     )"
      ],
      "metadata": {
        "id": "hH1PhTDtgAHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transfer_learning_model(chosen_model):\n",
        "    \"\"\"\n",
        "    This function utilizes transfer learning of a given model.\n",
        "    \"\"\"\n",
        "    tf.random.set_seed(random_state)\n",
        "    np.random.seed(random_state)\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "    if chosen_model == 'VGG19':\n",
        "        model_tl = VGG19(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    elif chosen_model == 'DenseNet201':\n",
        "        model_tl = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    elif chosen_model == 'ResNet50':\n",
        "        model_tl = tf.keras.applications.resnet50.ResNet50(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    elif chosen_model == 'VGG16':\n",
        "        model_tl = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    elif chosen_model == 'EfficientNetB7':\n",
        "        model_tl = tf.keras.applications.efficientnet.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    elif chosen_model == 'MobileNet':\n",
        "        model_tl = tf.keras.applications.MobileNet(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    elif chosen_model == 'Xception':\n",
        "        model_tl = tf.keras.applications.Xception(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    elif chosen_model == 'InceptionV3':\n",
        "        model_tl = tf.keras.applications.InceptionV3(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "    return model_tl"
      ],
      "metadata": {
        "id": "dvw6LNAdkAW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chosen_model = 'MobileNetV2'\n",
        "\n",
        "# model_tl = build_transfer_learning_model(chosen_model = chosen_model)\n",
        "# model_tl.trainable = False\n",
        "        \n",
        "# # Plug the pre-trained model to custom model\n",
        "# print(f\"Plugging in the pretainined model for {chosen_model} to custom model\")\n",
        "\n",
        "# try:\n",
        "#     del model\n",
        "# except:\n",
        "#     None\n",
        "# input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "# inputs = tf.keras.Input(input_shape)\n",
        "# m_tl = tf.keras.layers.GlobalAveragePooling2D()(model_tl(inputs))\n",
        "# m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "# m_tl = tf.keras.layers.Dense(512, activation = 'relu')(m_tl)\n",
        "# m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "# m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "# m_tl = tf.keras.layers.Dense(256, activation = 'relu')(m_tl)\n",
        "# m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "# m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "# m_tl = tf.keras.layers.Flatten()(m_tl)\n",
        "# m_tl = tf.keras.layers.Dense(1, activation = None)(m_tl)\n",
        "# model = tf.keras.Model(inputs = inputs, outputs = m_tl)"
      ],
      "metadata": {
        "id": "6jwVoXjrkAHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_accuracy_and_loss(history, chosen_model):\n",
        "   \"\"\"\n",
        "   This method plots model training and validation accuracies.\n",
        "   \"\"\"\n",
        "   tf.keras.backend.clear_session()\n",
        "\n",
        "   hist = history.history\n",
        "   x_arr = np.arange(len(hist['loss'])) + 1\n",
        "        \n",
        "   fig = plt.figure(figsize=(12, 4))\n",
        "   ax = fig.add_subplot(1, 2, 1)\n",
        "   ax.plot(x_arr, hist['loss'], '-o', label = 'Train loss')\n",
        "   ax.plot(x_arr, hist['val_loss'], '--<', label = 'Validation loss')\n",
        "   ax.legend(fontsize=15)\n",
        "   ax.set_xlabel('Epoch', size = 15)\n",
        "   ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "   ax = fig.add_subplot(1, 2, 2)\n",
        "   ax.plot(x_arr, hist['accuracy'], '-o', label = 'Train acc.')\n",
        "   ax.plot(x_arr, hist['val_accuracy'], '--<', label = 'Validation acc.')\n",
        "   ax.legend(fontsize = 15)\n",
        "   ax.set_xlabel('Epoch', size = 15)\n",
        "   ax.set_ylabel('Accuracy', size = 15)\n",
        "   ax.set_ylim(0,1)\n",
        "   plt.title(f\"{chosen_model}\")\n",
        "   plt.show(block = False)"
      ],
      "metadata": {
        "id": "Kymn8vnZsPc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = .001\n",
        "epochs = 10\n",
        "dropout_rate = .5\n",
        "batch_size = 32\n",
        "random_state = 1234\n",
        "\n",
        "transfer_learning_model_list = ['VGG16', \n",
        "                                'VGG19', \n",
        "                                'DenseNet201', \n",
        "                                'InceptionV3', \n",
        "                                'ResNet50', \n",
        "                                'EfficientNetB7', \n",
        "                                'MobileNet', \n",
        "                                'Xception'\n",
        "                               ]"
      ],
      "metadata": {
        "id": "igoFfn5voLQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ranges of hyperparam values \n",
        "hp_kernel_size = hp.Int('kernel_size', min_value=3, max_value=5, step=1)\n",
        "hp_strides = hp.Int('strides', min_value=1, max_value=2, step=1)\n",
        "hp_pool_size = hp.Int('pool_size', min_value=2, max_value=3, step=1)\n",
        "hp_activation = hp.Choice('activation', values=['tanh', 'relu', 'leaky_relu', 'elu', 'gelu','selu'], default='relu')\n",
        "hp_optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'], default='adam')\n",
        "hp_dense = hp.Int('dense_units', min_value=256, max_value=1024, step=128)\n",
        "hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "hp_dropout = hp.Choice('dropout_rate',values=[0.2, 0.3, 0.4, 0.5, 0.6])\n",
        "# hp_dropout_2 = hp.Float('dropout_rate_2', min_value=0.3, max_value=0.5, default=0.25, step=0.1)\n",
        "# hp_dropout_3 = hp.Float('dropout_rate_3', min_value=0.3, max_value=0.5, default=0.35, step=0.1)\n",
        "hp_reduction_type = hp.Choice('reduction_type', values=['global_avg_pooling2d', 'max_pooling2d'])\n",
        "\n",
        "def build_cnn(chosen_model):\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.random.set_seed(0)\n",
        "\n",
        "  model_tl = build_transfer_learning_model(chosen_model = chosen_model)\n",
        "  model_tl.trainable = False            # freeze extraction layers\n",
        "  m_tl = model_tl.output\n",
        "\n",
        "  m_tl = GlobalAveragePooling2D(keepdims=True) if hp_reduction_type == 'global_avg_pooling2d' else MaxPooling2D(pool_size=(hp_pool_size,hp_pool_size), strides=(hp_strides,hp_strides))(m_tl)\n",
        "  m_tl = Dropout(hp_dropout) if hp.Boolean('dropout_1')(m_tl)\n",
        "  m_tl = Dense(units = hp_dense, activation = hp_activation)(m_tl)\n",
        "  m_tl = BatchNormalization()(m_tl)\n",
        "  m_tl = Dense(units = hp_dense, activation = hp_activation)(m_tl)\n",
        "  m_tl = BatchNormalization()(m_tl)\n",
        "  m_tl = Dropout(hp_dropout) if hp.Boolean('dropout_2')(m_tl)\n",
        "  m_tl = Flatten()(m_tl)\n",
        "  m_tl = Dense(units = hp_dense, activation = hp_activation)(m_tl)\n",
        "  m_tl = BatchNormalization()(m_tl)\n",
        "  m_tl = Dropout(hp_dropout) if hp.Boolean('dropout_3')(m_tl)\n",
        "  # predictions = Dense(2, activation='sigmoid')(m_tl)\n",
        "  predictions = Dense(2, activation='softmax')(m_tl)               # UPDATED from 'sigmoid' to 'softmax\n",
        "  model = Model(inputs=model_tl.input, outputs=predictions)\n",
        "\n",
        "  def selected_optimizer(optimizer):\n",
        "    if optimizer.lower() == 'sgd':\n",
        "        return SGD(learning_rate=hp_learning_rate)           # SGD(learning_rate=learning_rate, momentum=0.95, decay=1, nesterov=True)\n",
        "    elif optimizer.lower() == 'adam':\n",
        "        return Adam(learning_rate=hp_learning_rate)          # Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8, kappa=1-1e-8)\n",
        "    # elif optimizer.lower() == 'adadelta':\n",
        "    #     return Adadelta(learning_rate=hp_learning_rate)      # Adadelta(learning_rate=learning_rate, rho=0.95, epsilon=1e-6)\n",
        "    # elif optimizer.lower() == 'adagrad':\n",
        "    #     return Adagrad(learning_rate=hp_learning_rate)       # Adagrad(learning_rate=learning_rate, epsilon=1e-6)\n",
        "    elif optimizer.lower() == 'rmsprop':\n",
        "        return RMSprop(learning_rate=hp_learning_rate)       # RMSprop(learning_rate=learning_rate, rho=0.9, epsilon=1e-6)\n",
        "\n",
        "  model.compile(loss=CategoricalCrossentropy(), \n",
        "                optimizer=selected_optimizer(hp_optimizer), \n",
        "                metrics=['accuracy'])  \n",
        "                # tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                # tf.keras.metrics.Precision(name='precision'),\n",
        "                # tf.keras.metrics.Recall(name='recall'),  \n",
        "                # tf.keras.metrics.AUC(name='auc')])\n",
        "  return model\n",
        "\n",
        "model = build_cnn('VGG16')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_LyiIqesj9ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "tf.keras.utils.plot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\n",
        "Image(filename='convnet.png') \n",
        "\n",
        "# stop_early = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 3)\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n",
        "                ModelCheckpoint('model.hdf5', save_best_only=True)]\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# RandomSearch\n",
        "tuner = kt.RandomSearch(\n",
        "          # CNN_HyperModel(),\n",
        "          build_cnn,\n",
        "          objective=\"val_loss\",             # infer_metric_direction_by_name(): maybe due to this objective - https://github.com/keras-team/keras-tuner/issues/74 | https://github.com/keras-team/keras-tuner/pull/76\n",
        "          max_trials=5,                     # max_trials=50 or 10,\n",
        "          executions_per_trial=2,           # executions_per_trial=10,\n",
        "          overwrite=True,\n",
        "          directory=\"hj_dir\",\n",
        "          project_name=\"breast_cancer_classification\")\n",
        "\n",
        "tuner.search(train_data_generator, \n",
        "            #  epochs=EPOCHS, \n",
        "             epochs=20, \n",
        "             callbacks=[callbacks], \n",
        "             validation_data=validation_data_generator)"
      ],
      "metadata": {
        "id": "CmwBrbSCwMp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]     # num_trials=5\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "print(tuner.results_summary(1))"
      ],
      "metadata": {
        "id": "At8MbrHcuN9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ==================== Pretrained model =================================\n",
        "# chosen_model = 'VGG16'\n",
        "\n",
        "# start_time = time.time()\n",
        "\n",
        "# model_tl = build_transfer_learning_model(chosen_model = chosen_model)\n",
        "# model_tl.trainable = False            # freeze extraction layers\n",
        "\n",
        "# # add custom top layers\n",
        "# m_tl = model_tl.output\n",
        "# m_tl = GlobalAveragePooling2D()(m_tl)\n",
        "# m_tl = Dropout(0.2)(m_tl)\n",
        "# m_tl = Dense(512,activation=\"relu\")(m_tl)\n",
        "# m_tl = Dense(512,activation=\"relu\")(m_tl)\n",
        "# m_tl = Dropout(0.2)(m_tl)\n",
        "# m_tl = Dense(256,activation=\"relu\")(m_tl)\n",
        "# # predictions = Dense(2, activation='sigmoid')(m_tl)\n",
        "# predictions = Dense(2, activation='softmax')(m_tl)               # UPDATED from 'sigmoid' to 'softmax\n",
        "# model = Model(inputs=model_tl.input, outputs=predictions)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "1qD7cKukl08N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================== datagen.flow_from_directory =========================\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "processed_images_train_path = '/content/processed_images/train'           # contains augmented images with original images (4782 = IDC(1): 2400 + IDC(1): 2382)\n",
        "processed_images_validation_path = '/content/processed_images/val'\n",
        "processed_images_test_path = '/content/processed_images/test'\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "train_data_generator = datagen.flow_from_directory(processed_images_train_path,\n",
        "                                                                     target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                     class_mode = 'categorical',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'rgb',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "val_data_generator = datagen.flow_from_directory(processed_images_validation_path,\n",
        "                                                                 target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                 class_mode = 'categorical',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'rgb',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "test_data_generator = datagen.flow_from_directory(processed_images_test_path,\n",
        "                                                                   target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'categorical',\n",
        "                                                                   color_mode = 'rgb',\n",
        "                                                                   shuffle = False,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "# ============== model.fit ================================================\n",
        "history = model.fit(train_data_generator,\n",
        "                    epochs = epochs,\n",
        "                    steps_per_epoch = len(train_data_generator),\n",
        "                    validation_data = val_data_generator,\n",
        "                    validation_steps = len(val_data_generator),\n",
        "                    verbose = 1)\n",
        "\n",
        "# ============= Model save ================================================\n",
        "print(\"Saving model...\")\n",
        "tf.keras.backend.clear_session()\n",
        "# gc.collect()                                                      # UPDATED\n",
        "model.save('breast_cancer_detection_' + chosen_model + '.h5')\n",
        "\n",
        "# ============= Plot loss and accuracy of model: train vs val =============\n",
        "print(f\"{chosen_model}\")\n",
        "plot_model_accuracy_and_loss(history = history, chosen_model = chosen_model)"
      ],
      "metadata": {
        "id": "Hlq5aNZErceN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========== model.evaluate ===============================================\n",
        "# test_loss, test_accuracy, precision1, recall1, auc1 = model.evaluate(test_data_generator, verbose = 0)\n",
        "test_loss, test_accuracy = model.evaluate(test_data_generator, verbose = 0)\n",
        "training_accuracy = history.history['accuracy'][-1]\n",
        "val_accuracy = history.history['val_accuracy'][-1]\n",
        "count_params = model.count_params()\n",
        "\n",
        "# =========== model.predict (transform logits to probabilities) ===========\n",
        "classes = ['IDC(0)','IDC(1)']\n",
        "\n",
        "y_true = test_data_generator.classes\n",
        "y_pred = model.predict(test_data_generator, steps = (test_data_generator.n // batch_sizeb + 1), verbose = 0)\n",
        "# y_pred = model.predict(test_data_generator)\n",
        "y_pred_argmax = np.argmax(y_pred, axis=1) \n",
        "# print('\\ny_true: ', y_true[:5])\n",
        "# print('y_pred: ', y_pred[:5])\n",
        "# print('y_pred_argmax: ', y_pred_argmax[:5])\n",
        "# print('y_pred[:,1]: ', y_pred[:,1][:5])\n",
        "\n",
        "# ========== Precision, recall, f1score ====================================\n",
        "precision, recall, f1score, support = score(y_true, y_pred_argmax, average='macro')\n",
        "\n",
        "# ========== cohen_kappa score, zero_one loss\n",
        "cohen_kappa = round(cohen_kappa_score(y_true, y_pred_argmax), 2)\n",
        "zo_loss = round(zero_one_loss(y_true, y_pred_argmax), 2)\n",
        "\n",
        "# ========== Area under the ROC curve ======================================\n",
        "roc_log = roc_auc_score(y_true, y_pred[:,1], multi_class='ovr')   # for the roc curve, we need to use a vector of probabilities so just chose one column and all rows\n",
        "fpr, tpr, threshold = roc_curve(y_true, y_pred[:,1])\n",
        "area_under_curve = round(metrics.auc(fpr, tpr), 2) \n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot([0, 1], [0, 1], 'r--')  \n",
        "plt.plot(fpr, tpr, label='ROC-AUC: {:.2f}'.format(area_under_curve))  \n",
        "plt.xlabel('False positive rate', fontsize=14)\n",
        "plt.ylabel('True positive rate', fontsize=14)\n",
        "plt.title('ROC Area Under Curve', fontsize=18)\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# ========== Performace metrics summary ===================================\n",
        "perf_metrics = pd.DataFrame({'Test_Loss':round(test_loss,2), \n",
        "                             'Test_Acc':round(test_accuracy, 2), \n",
        "                             'Train_Acc':round(training_accuracy, 2), \n",
        "                             'Val_Acc':round(val_accuracy, 2), \n",
        "                             'Num_Params':  f'{count_params:,}',\n",
        "                             'Precision':round(precision, 2), \n",
        "                             'Recall':round(recall, 2), \n",
        "                             'F1_score': round(f1score, 2),\n",
        "                             'ROC-AUC':round(area_under_curve, 2), \n",
        "                             'Cohen Kappa': cohen_kappa,\n",
        "                             'Zero-One Loss': zo_loss}, index=[0])\n",
        "\n",
        "print();print('Execution time %s minutes: ' % round(int(time.time() - start_time)/60, 2),'\\n')\n",
        "perf_metrics"
      ],
      "metadata": {
        "id": "dlb5zvsdAZcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import metrics\n",
        "# from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "# # =========== model.predict (transform logits to probabilities) ===========\n",
        "\n",
        "# # Model Predict, transform logits to probabilities\n",
        "# # step_size_test = np.ceil(test_data_generator.n / test_data_generator.batch_size)\n",
        "# # step_size_test_heesuk = (test_data_generator.n // batch_size + 1)\n",
        "# # print('step_size_test_ceil: ',step_size_test)\n",
        "# # print('step_size_test_heesuk: ',step_size_test_heesuk)\n",
        "\n",
        "# # test_data_generator.reset()\n",
        "# # pred_logits = model.predict(test_data_generator, steps = (test_data_generator.n // batch_size + 1), verbose = 0)\n",
        "# # # print('pred_logits: ', pred_logits[:5])\n",
        "# # probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "# # # print('probas_sigmoid: ', probas_sigmoid[:5])\n",
        "# # probas_sigmoid = probas_sigmoid.numpy().flatten()\n",
        "# # # print('probas_sigmoid: ', probas_sigmoid[:5])\n",
        "# # predictions_binary = [1 if x > 0.5 else 0 for x in probas_sigmoid]\n",
        "# # # print('predictions_binary: ', predictions_binary[:5])\n",
        "\n",
        "# = model.evaluate(test_data_generator, verbose = 0)\n",
        "# training_accuracy = history.history['accuracy'][-1]\n",
        "# val_accuracy = history.history['val_accuracy'][-1]\n",
        "# count_params = model.count_params()\n",
        "\n",
        "# # # =============== hj conf.matrix ==========================\n",
        "# classes = ['IDC(0)','IDC(1)']\n",
        "\n",
        "# y_true = test_data_generator.classes\n",
        "# y_pred = model.predict(test_data_generator, steps = (test_data_generator.n // batch_size + 1), verbose = 1)\n",
        "# # y_pred = model.predict(test_data_generator)\n",
        "# y_pred_argmax = np.argmax(y_pred, axis=1) \n",
        "# # print('\\ny_true: ', y_true[:5])\n",
        "# # print('y_pred: ', y_pred[:5])\n",
        "# # print('y_pred_argmax: ', y_pred_argmax[:5])\n",
        "# # print('y_pred[:,1]: ', y_pred[:,1][:5])\n",
        "\n",
        "# # conf_max = confusion_matrix(y_true, y_pred_argmax) \n",
        "# # perf_conf_max = conf_max.astype('float')/conf_max.sum(axis=1)[:np.newaxis]*100\n",
        "# # df_perf_conf_max = pd.DataFrame(perf_conf_max, index=classes, columns=classes)\n",
        "\n",
        "# # plt.figure(figsize=(6,5))\n",
        "# # sns.heatmap(df_perf_conf_max, annot=True, cmap='coolwarm', annot_kws={'fontsize':16}, linewidth=0.5, fmt='.0f')  \n",
        "# # plt.xlabel('Predicted Label', fontsize=14)\n",
        "# # plt.ylabel('True Label', fontsize=14)\n",
        "# # plt.title('Confusion Matrix (%)', fontsize=15)\n",
        "\n",
        "# # # Classification report (classification_report should use 0s and 1s for y_pred)\n",
        "# # # print('\\n=============== Classification Report ===============\\n\\n', classification_report(y_true, y_pred_argmax, target_names=['Non-IDC', 'IDC']), '\\n=====================================================\\n')\n",
        "\n",
        "# # # Precision, recall, and f1_score\n",
        "# # tn, fp, fn, tp = confusion_matrix(y_true, y_pred_argmax).ravel()     # np.ravel(): returns contiguous flattened array (1D array with all the input-array elements and with the same type as it)\n",
        "# # recall_score = tp/(fn+tp)\n",
        "# # precision_score = tp/(fp+tp)\n",
        "# # print('recall_score', recall_score)\n",
        "# # print('precision_score', precision_score)\n",
        "# # f1score = round((2*precision_score*recall_score)/(precision_score+recall_score), 2)\n",
        "\n",
        "# precision1, recall1, f1score1, support = score(y_true, y_pred_argmax, average='macro')\n",
        "\n",
        "# # cohen_kappa score and zero_one loss\n",
        "# cohen_kappa = round(cohen_kappa_score(y_true, y_pred_argmax), 2)\n",
        "# zo_loss = round(zero_one_loss(y_true, y_pred_argmax), 2)\n",
        "\n",
        "# # # Area under the ROC curve\n",
        "# roc_log = roc_auc_score(y_true, y_pred[:,1], multi_class='ovr')   # for the roc curve, we need to use a vector of probabilities so just chose one column and all rows\n",
        "# fpr, tpr, threshold = roc_curve(y_true, y_pred[:,1])\n",
        "# area_under_curve = round(metrics.auc(fpr, tpr), 2) \n",
        "\n",
        "# plt.figure(figsize=(6,5))\n",
        "# plt.plot([0, 1], [0, 1], 'r--')  \n",
        "# plt.plot(fpr, tpr, label='ROC-AUC: {:.2f}'.format(area_under_curve))  \n",
        "# plt.xlabel('False positive rate', fontsize=14)\n",
        "# plt.ylabel('True positive rate', fontsize=14)\n",
        "# plt.title('ROC Curve', fontsize=18)\n",
        "# plt.legend(loc='best')\n",
        "# plt.show()\n",
        "\n",
        "# perf_metrics = pd.DataFrame({'Test_Loss':round(test_loss,2), \n",
        "#                              'Test_Acc':round(test_accuracy, 2), \n",
        "#                              'Train_Acc':round(training_accuracy, 2), \n",
        "#                              'Val_Acc':round(val_accuracy, 2), \n",
        "#                              'Num_params':  f'{count_params:,}',\n",
        "#                              'Precision':round(precision1, 2), \n",
        "#                              'Recall':round(recall1, 2), \n",
        "#                              'F1_score': round(f1score1, 2),\n",
        "#                              'ROC-AUC':round(area_under_curve, 2), \n",
        "#                              'Cohen Kappa': cohen_kappa,\n",
        "#                              'Zero-One Loss': zo_loss}, index=[0])\n",
        "\n",
        "# print();print('Execution time %s minutes: ' % (int(time.time() - start_time)/60),'\\n')\n",
        "# perf_metrics"
      ],
      "metadata": {
        "id": "psmiXO36RC5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Pretrained model =================================\n",
        "chosen_model = 'ResNet152'\n",
        "\n",
        "start_time = time.time()\n",
        "model_tl = build_transfer_learning_model(chosen_model = chosen_model)\n",
        "model_tl.trainable = False    \n",
        "\n",
        "# add custom top layers\n",
        "x = model_tl.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(2, activation='sigmoid')(x)\n",
        "model = Model(inputs=model_tl.input, outputs=predictions)\n",
        "model.summary()\n",
        "\n",
        "# random_state = 1234\n",
        "# num_classes = 2\n",
        "# model = Sequential([\n",
        "#      ResNet152(input_shape=(50,50,3),weights=\"imagenet\",include_top=False), \n",
        "#      GlobalAveragePooling2D(),\n",
        "#      #Dropout(.5),\n",
        "#      #Dense(256, activation='relu'),#, kernel_regularizer=keras.regularizers.l1(l=0.1)),\n",
        "#      #Dropout(.5),\n",
        "#      Dense(num_classes, activation='sigmoid',name='preds'),\n",
        "# ])\n",
        "# model.layers[0].trainable= False\n",
        "# # show model summary\n",
        "# model.summary()\n",
        "\n",
        "# ================== model.compile ===============================================\n",
        "from IPython.display import Image\n",
        "tf.keras.utils.plot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\n",
        "Image(filename='convnet.png') \n",
        "\n",
        "# stop_early = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 3)\n",
        "# checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n",
        "                ModelCheckpoint('model.hdf5',\n",
        "                                 save_best_only=True)]\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=[\n",
        "                tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall'),  \n",
        "                tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "# =================================================================================\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "processed_images_train_path = '/content/processed_images/train'\n",
        "processed_images_validation_path = '/content/processed_images/val'\n",
        "processed_images_test_path = '/content/processed_images/test'\n",
        "\n",
        "train_data_generator = datagen.flow_from_directory(processed_images_train_path,\n",
        "                                                                     target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                     class_mode = 'categorical',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'rgb',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "val_data_generator = datagen.flow_from_directory(processed_images_validation_path,\n",
        "                                                                 target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                 class_mode = 'categorical',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'rgb',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "test_data_generator = datagen.flow_from_directory(processed_images_test_path,\n",
        "                                                                   target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'categorical',\n",
        "                                                                   color_mode = 'rgb',\n",
        "                                                                   shuffle = False,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "  \n",
        "history = model.fit(train_data_generator,\n",
        "                    epochs = epochs,\n",
        "                    steps_per_epoch = len(train_data_generator),\n",
        "                    validation_data = val_data_generator,\n",
        "                    validation_steps = len(val_data_generator),\n",
        "                    callbacks = [callbacks],                        # ADDED\n",
        "                    verbose = 1\n",
        "                   )\n",
        "\n",
        "# Model save\n",
        "print(\"Saving model...\")\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect() \n",
        "model.save('breast_cancer_detection_' + chosen_model + '.h5')\n",
        "\n",
        "# Plot train and val accuracy and loss\n",
        "print(f\"Plotting train and validation accuracy and loss for model {chosen_model}\")\n",
        "plot_model_accuracy_and_loss(history = history, chosen_model = chosen_model)\n",
        "\n",
        "# Model Predict, transform logits to probabilities\n",
        "step_size_test = np.ceil(test_data_generator.n / test_data_generator.batch_size)\n",
        "test_data_generator.reset()\n",
        "pred_logits = model.predict(test_data_generator, steps = step_size_test, verbose = 1)\n",
        "probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "predictions_binary = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "\n",
        "print();print('Execution time %s seconds: ' % (time.time() - start_time),'\\n')\n",
        "# ========= model.evaluate =========================================================\n",
        "loss, accuracy, precision, recall, auc = model.evaluate(test_data_generator, verbose = 0)\n",
        "print(\"loss, accuracy, precision, recall,auc\")\n",
        "print(loss, accuracy, precision, recall,auc)\n",
        "\n",
        "perf_metrics = pd.DataFrame({'Loss':loss, 'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'ROC-AUC':auc}, index=[0])\n",
        "perf_metrics"
      ],
      "metadata": {
        "id": "qT0X9T-NsjfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Py7npvj_sPjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fz9Va7LQvGcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7rUj3RnMvGgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FXA26JGvGiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oRD0_UYBvGns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model_cnn_5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(50, 50, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Dropout(.5),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (4,4), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((3, 3), strides=2),\n",
        "    tf.keras.layers.Dropout(.5),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((4, 4), strides=2),\n",
        "    tf.keras.layers.Dropout(.5),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(.5),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation= None)\n",
        "])"
      ],
      "metadata": {
        "id": "pHqBK3J4l0lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn_5.summary()"
      ],
      "metadata": {
        "id": "ENHVynzTl_TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model_cnn_5)"
      ],
      "metadata": {
        "id": "T-Fi4VlvmCpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model_tl = build_transfer_learning_model(chosen_model = chosen_model)\n",
        "model_tl.trainable = False\n",
        "        \n",
        "# Plug the pre-trained model to custom model\n",
        "print(f\"Plugging in the pretainined model for {chosen_model} to custom model\")\n",
        "try:\n",
        "    del model\n",
        "except:\n",
        "    None\n",
        "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "inputs = tf.keras.Input(input_shape)\n",
        "m_tl = tf.keras.layers.GlobalAveragePooling2D()(model_tl(inputs))\n",
        "m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "m_tl = tf.keras.layers.Dense(512, activation = 'relu')(m_tl)\n",
        "m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "m_tl = tf.keras.layers.Dense(256, activation = 'relu')(m_tl)\n",
        "m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "m_tl = tf.keras.layers.Flatten()(m_tl)\n",
        "m_tl = tf.keras.layers.Dense(2, activation = 'softmax')(m_tl)\n",
        "model = tf.keras.Model(inputs = inputs, outputs = m_tl)\n",
        "tf.keras.utils.plot_model(model)\n",
        "'''"
      ],
      "metadata": {
        "id": "Y2LlqfPtgG2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_images_train_path = '/content/processed_images/train'\n",
        "processed_images_validation_path = '/content/processed_images/val'\n",
        "processed_images_test_path = '/content/processed_images/test'"
      ],
      "metadata": {
        "id": "WMziw8LBhgBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_accuracy_and_loss(history, chosen_model):\n",
        "   \"\"\"\n",
        "   This method plots model training and validation accuracies.\n",
        "   \"\"\"\n",
        "   tf.keras.backend.clear_session()\n",
        "\n",
        "   hist = history.history\n",
        "   x_arr = np.arange(len(hist['loss'])) + 1\n",
        "        \n",
        "   fig = plt.figure(figsize=(12, 4))\n",
        "   ax = fig.add_subplot(1, 2, 1)\n",
        "   ax.plot(x_arr, hist['loss'], '-o', label = 'Train loss')\n",
        "   ax.plot(x_arr, hist['val_loss'], '--<', label = 'Validation loss')\n",
        "   ax.legend(fontsize=15)\n",
        "   ax.set_xlabel('Epoch', size = 15)\n",
        "   ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "   ax = fig.add_subplot(1, 2, 2)\n",
        "   ax.plot(x_arr, hist['accuracy'], '-o', label = 'Train acc.')\n",
        "   ax.plot(x_arr, hist['val_accuracy'], '--<', label = 'Validation acc.')\n",
        "   ax.legend(fontsize = 15)\n",
        "   ax.set_xlabel('Epoch', size = 15)\n",
        "   ax.set_ylabel('Accuracy', size = 15)\n",
        "   ax.set_ylim(0,1)\n",
        "   plt.title(f\"Training and validation loss and accuracies for model : {chosen_model}\")\n",
        "   plt.show(block = False)"
      ],
      "metadata": {
        "id": "Trd2ptW-jJmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random_state = 1234"
      ],
      "metadata": {
        "id": "ikoj2vbvpD-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epoch = 20\n",
        "train_data_generator = datagen.flow_from_directory(processed_images_train_path,\n",
        "                                                                     target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                     class_mode = 'binary',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'rgb',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "val_data_generator = datagen.flow_from_directory(processed_images_validation_path,\n",
        "                                                                 target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                 class_mode = 'binary',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'rgb',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "test_data_generator = datagen.flow_from_directory(processed_images_test_path,\n",
        "                                                                   target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'binary',\n",
        "                                                                   color_mode = 'rgb',\n",
        "                                                                   shuffle = False,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "        \n",
        "tf.random.set_seed(random_state)\n",
        "np.random.seed(random_state)\n",
        "# Model compile\n",
        "print(\"Compiling the model...\")\n",
        "model_cnn_5.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
        "              loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "              metrics = ['accuracy']) \n",
        "\n",
        "# Model fit\n",
        "print(\"Model fit...\")\n",
        "history = model_cnn_5.fit(train_data_generator,\n",
        "                    epochs = epochs,\n",
        "                    steps_per_epoch = len(train_data_generator),\n",
        "                    validation_data = val_data_generator,\n",
        "                    validation_steps = len(val_data_generator),\n",
        "                    verbose = 1\n",
        "                   )\n",
        "\n",
        "# Model save\n",
        "print(\"Saving model...\")\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "model_cnn_5.save('breast_cancer_detection_' + chosen_model + '.h5')\n",
        "\n",
        "# Plot train and val accuracy and loss\n",
        "print(f\"Plotting train and validation accuracy and loss for model {chosen_model}\")\n",
        "plot_model_accuracy_and_loss(history = history, chosen_model = chosen_model)\n",
        "\n",
        "# Model Predict, transform logits to probabilities\n",
        "step_size_test = np.ceil(test_data_generator.n / test_data_generator.batch_size)\n",
        "test_data_generator.reset()\n",
        "pred_logits = model_cnn_5.predict(test_data_generator, steps = step_size_test, verbose = 1)\n",
        "probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "predictions_binary = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "\n",
        "print();print('Execution time %s seconds: ' % (time.time() - start_time),'\\n')\n",
        "\n",
        "test_loss, test_accuracy = model_cnn_5.evaluate(test_data_generator, verbose = 0)\n",
        "print(test_loss, test_accuracy)"
      ],
      "metadata": {
        "id": "PIbByCKtgGH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ZfEp2W-gGA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_size = 40000\n",
        "#batch_size = 256\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "lr = 0.01\n",
        "\n",
        "# IMG_SIZE = 50\n",
        "#number_of_splits = 8\n",
        "number_of_splits = 8\n",
        "run_mode = ['interim_test', 'final_test']\n",
        "\n",
        "# Transfer learning model list\n",
        "transfer_learning_model_list = ['VGG16', \n",
        "                                'VGG19', \n",
        "                                'DenseNet201', \n",
        "                                'InceptionV3', \n",
        "                                'ResNet50', \n",
        "                                'EfficientNetB7', \n",
        "                                'MobileNet', \n",
        "                                'Xception'\n",
        "                               ]\n",
        "learning_rate_list = [.01, .001, .0001, .00001]\n",
        "optimizer_list = ['sgd', 'adam']\n",
        "dropout_list = [.2, .4, .6]\n",
        "kernel_size_list = [(3,3), (4,4), (5,5)]\n",
        "dense_layer_node_list = [512, 256, 128]\n",
        "fully_conneted_layer_list = [1, 2, 3]\n",
        "epoch_list = [5, 10, 15, 20]"
      ],
      "metadata": {
        "id": "kSQVGMh1cPTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stores each model and kfold specific train and validation accuracies \n",
        "# and losses for each epoch\n",
        "temp_df_model_kpi = pd.DataFrame()\n",
        "# Consolidates the above results across all model and kfolds.\n",
        "consolidated_df_model_kpi = pd.DataFrame()\n",
        "\n",
        "# Holds model and kfold specific actual, prediction %, perdiction binary value\n",
        "# along with test loss and accuracy.\n",
        "temp_df_acttual_vs_pred_bin_pred_pct = pd.DataFrame()\n",
        "# Consolidates the above result for each model and kfold.\n",
        "df_actual_vs_pred_bin_pred_pct = pd.DataFrame()\n",
        "\n",
        "df_kfold_ensemble_stats = pd.DataFrame()\n",
        "\n",
        "for chosen_model in transfer_learning_model_list:\n",
        "\n",
        "    temp_df_model_kpi = pd.DataFrame()\n",
        "    temp_df_acttual_vs_pred_bin_pred_pct = pd.DataFrame()\n",
        "    for kfold, (train_indices, validation_indices) in enumerate(StratifiedKFold(n_splits =  number_of_splits, \n",
        "                                                                                shuffle = True, \n",
        "                                                                                random_state = random_state\n",
        "                                                                               ).split(data_proc.df_train_original['label'].values.tolist(), \n",
        "                                                                                       data_proc.df_train_original['label'].values.tolist()\n",
        "                                                                                      )):\n",
        "        print(f\"Model : {chosen_model}, k-fold : {kfold + 1}, length of train data : {len(train_indices)}, length of validation data : {len(validation_indices)}\")\n",
        "        data_proc.split_data_based_on_indices(train_indices = train_indices, validation_indices = validation_indices)\n",
        "\n",
        "        train_data_generator = train_datagen.flow_from_directory(processed_images_train_path,\n",
        "                                                                     target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                     class_mode = 'binary',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'rgb',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "        val_data_generator = val_datagen.flow_from_directory(processed_images_validation_path,\n",
        "                                                                 target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                 class_mode = 'binary',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'rgb',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "        test_data_generator = test_datagen.flow_from_directory(processed_images_test_path,\n",
        "                                                                   target_size = (IMG_SIZE, IMG_SIZE),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'binary',\n",
        "                                                                   color_mode = 'rgb',\n",
        "                                                                   shuffle = False,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "        \n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "        # Pre-trained model build\n",
        "        print(f\"Building pretainined model for {chosen_model}\")\n",
        "        try:\n",
        "            del model_tl\n",
        "        except:\n",
        "            None\n",
        "        model_tl = model_proc.build_transfer_learning_model(chosen_model = chosen_model)\n",
        "        model_tl.trainable = False\n",
        "        model_proc.model_summary_and_display_structure(model_tl)\n",
        "        \n",
        "        # Plug the pre-trained model to custom model\n",
        "        print(f\"Plugging in the pretainined model for {chosen_model} to custom model\")\n",
        "        try:\n",
        "            del model\n",
        "        except:\n",
        "            None\n",
        "        input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "        inputs = tf.keras.Input(input_shape)\n",
        "        m_tl = tf.keras.layers.GlobalAveragePooling2D()(model_tl(inputs))\n",
        "        m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "        m_tl = tf.keras.layers.Dense(512, activation = 'relu')(m_tl)\n",
        "        m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "        m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "        m_tl = tf.keras.layers.Dense(256, activation = 'relu')(m_tl)\n",
        "        m_tl = tf.keras.layers.BatchNormalization()(m_tl)\n",
        "        m_tl = tf.keras.layers.Dropout(dropout_rate)(m_tl)\n",
        "        m_tl = tf.keras.layers.Flatten()(m_tl)\n",
        "        m_tl = tf.keras.layers.Dense(1, activation = None)(m_tl)\n",
        "        model = tf.keras.Model(inputs = inputs, outputs = m_tl)\n",
        "        # Model compile\n",
        "        print(\"Compiling the model...\")\n",
        "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
        "                      loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
        "                      metrics = ['accuracy']) \n",
        "\n",
        "        # Model fit\n",
        "        print(\"Model fit...\")\n",
        "        #es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, min_delta = 1)\n",
        "        history = model.fit(train_data_generator,\n",
        "                            epochs = epochs,\n",
        "                            steps_per_epoch = len(train_data_generator),\n",
        "                            validation_data = val_data_generator,\n",
        "                            validation_steps = len(val_data_generator),\n",
        "                            verbose = 1\n",
        "                           )\n",
        "\n",
        "        # Model save\n",
        "        print(\"Saving model...\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "        model.save('tumor_detection_' + chosen_model + '_k' + str(kfold + 1) + '.h5')\n",
        "        #tf.saved_model.save(model, os.getcwd())\n",
        "        saved_chosen_models_list.append('tumor_detection_' + chosen_model + '_k' + str(kfold + 1))\n",
        "        \n",
        "        # Append the final train and validation accuracy and loss.\n",
        "        print(f\"Storing train and validation accuracy and loss for model {chosen_model}, fold {kfold + 1}\")\n",
        "        temp_df_model_kpi = pd.DataFrame(history.history)\n",
        "        temp_df_model_kpi['model'] = chosen_model\n",
        "        temp_df_model_kpi['kfold'] = kfold + 1\n",
        "        temp_df_model_kpi['epoch'] = range(1, epochs + 1)\n",
        "        temp_df_model_kpi = temp_df_model_kpi[['model', \n",
        "                                               'kfold', \n",
        "                                               'epoch', \n",
        "                                               'accuracy', \n",
        "                                               'loss', \n",
        "                                               'val_accuracy', \n",
        "                                               'val_loss'\n",
        "                                               ]]\n",
        "        # Consolidating training and validation accuracies in single data frame \n",
        "        # along with model name, epoch, kfold number.\n",
        "        consolidated_df_model_kpi = pd.concat([temp_df_model_kpi, consolidated_df_model_kpi], axis = 0)\n",
        "        \n",
        "        # Plot train and val accuracy and loss\n",
        "        print(f\"Plotting train and validation accuracy and loss for model {chosen_model}, fold {kfold + 1}\")\n",
        "        model_proc.plot_model_accuracy_and_loss(history = history, chosen_model = chosen_model)\n",
        "\n",
        "        # Model Predict, transform logits to probabilities\n",
        "        step_size_test = np.ceil(test_data_generator.n / test_data_generator.batch_size)\n",
        "        test_data_generator.reset()\n",
        "        pred_logits = model.predict(test_data_generator, steps = step_size_test, verbose = 1)\n",
        "        probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "        probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "        predictions_binary = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "        test_loss, test_accuracy = model.evaluate(test_data_generator, verbose = 0)\n",
        "\n",
        "        temp_df_actual_vs_pred_bin_pred_pct = pd.DataFrame({\"model\"         : chosen_model, \n",
        "                                                            \"kfold\"         : kfold + 1, \n",
        "                                                            \"actual\"        : data_proc.y_test, \n",
        "                                                            \"pred_pct\"      : probas_sigmoid, \n",
        "                                                            \"pred_bin\"      : predictions_binary,\n",
        "                                                            \"test_loss\"     : test_loss,\n",
        "                                                            \"test_accuracy\" : test_accuracy\n",
        "                                                           }\n",
        "                                                          )\n",
        "        # Assign the index value of the index position\n",
        "        temp_df_actual_vs_pred_bin_pred_pct['output_pos'] = temp_df_actual_vs_pred_bin_pred_pct.groupby(['model','kfold']).cumcount() + 1\n",
        "        df_actual_vs_pred_bin_pred_pct = pd.concat([temp_df_actual_vs_pred_bin_pred_pct, \n",
        "                                                    df_actual_vs_pred_bin_pred_pct\n",
        "                                                   ], \n",
        "                                                   axis = 0)\n",
        "    \n",
        "    # Summary stats across all folds for a model\n",
        "    model_proc.display_model_stats_across_all_spilts(chosen_model, \n",
        "                                                     consolidated_df_model_kpi, \n",
        "                                                     df_actual_vs_pred_bin_pred_pct\n",
        "                                                    )\n",
        "    \n",
        "    # voting across model, kfold\n",
        "    print(f\"Calling ensemble_across_model_kfolds for model {chosen_model}\")\n",
        "    temp_df_kfold_ensemble_stats = model_proc.ensemble_across_model_kfolds(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == chosen_model])\n",
        "\n",
        "    # Appending the result back\n",
        "    df_kfold_ensemble_stats = pd.concat([temp_df_kfold_ensemble_stats, \n",
        "                                         df_kfold_ensemble_stats\n",
        "                                        ],\n",
        "                                        axis = 0)\n",
        "\n",
        "# voting across model, kfold\n",
        "print(f\"Calling ensemble_across_models\")\n",
        "df_ensemble_stats = model_proc.ensemble_across_models(df_kfold_ensemble_stats)\n"
      ],
      "metadata": {
        "id": "3GOPzKQyRQHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xewdeHiRRQEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6i5PR-BRQBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IeqCdWpoRPuj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}