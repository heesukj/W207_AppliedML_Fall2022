{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/W207_AppliedML_Fall2022/blob/main/Breast_Cancer_IDC_Prediction_Using_CNN_heesuk_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FALL 2022<br>\n",
        "W207 Applied Machine Learning<br>\n",
        "Heesuk Jang\n",
        " \n",
        "\n",
        "#Predicting IDC with Breast Histopathology Images using CNN\n",
        "\n"
      ],
      "metadata": {
        "id": "5DebDWCL0KeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SRkZHKoWswZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ffc2d5-581b-4b85-b4f7-0a5986e0346c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import *                            # confusion_matrix, log_loss, accuracy_score\n",
        "from sklearn.model_selection import *                    # train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import *\n",
        "# from sklearn.ensemble import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.linear_model import *                       # LinearRegression\n",
        "from sklearn.discriminant_analysis import *\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import metrics\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import RandomFlip, RandomZoom, RandomRotation, Conv2D, MaxPooling2D, AveragePooling2D, Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "tf.get_logger().setLevel('INFO')\n",
        "\n",
        "import cv2 as cv\n",
        "import skimage.io as io\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN - ML pipeline\n",
        "\n",
        "  1) EDA and Image Visualization<br>\n",
        "  2) Randomly sample from training/test/validation = 800/ 200/ 200 (66%/ 17%/ 17%)<br>\n",
        "  3) Image Transformations<br>\n",
        "> Image resize<br>\n",
        "> Image normalization to [0, 1]<br>\n",
        "  \n",
        "  4) [Image Augmentations](https://iq.opengenus.org/data-augmentation/)<br>\n",
        "> Adjust brightness<br>\n",
        "> Adjust contrast<br>\n",
        "> Flip left and right<br>\n",
        "> Rotate 90 degrees<br>\n",
        "\n",
        " 5) CNN Model using Tensorflow Keras API<br>\n",
        "> Build model<br>\n",
        "> Compile model<br>\n",
        "> Fit model<br>\n",
        "\n",
        " 6) Evaluate the Model<br>\n",
        " : Determine how good our trained model applies in predicting unseen (test) data.\n",
        "> model.**evaluate**<br>\n",
        "> model.**predict**<br>\n",
        "> Evaluation Metrics:  True Labels VS. Predicted Labels<br>\n",
        "\n",
        " 7) Hyper Parameter Tuning<br>\n",
        "> Optimizer<br>\n",
        "> Learning Rate<br>\n",
        "> Dropout ratio<br>\n",
        "> Number of Epochs<br>\n",
        "> Contrast Factor<br>\n",
        "> Delta<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oslfl6Ot7RYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1CFw-aOtGQm",
        "outputId": "bafa431d-00a6-4e45-f05d-73d0e2580250"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip gdrive/MyDrive/Kaggle/CNN_IDC/Dataset.zip\n",
        "\n",
        "#replace these paths with the paths of your \n",
        "val_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Validate'\n",
        "train_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train'\n",
        "test_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Test'\n",
        "directory_path = '/content/gdrive/MyDrive/Kaggle/CNN_IDC'"
      ],
      "metadata": {
        "id": "uyWJuOkZuCVl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# directory_path"
      ],
      "metadata": {
        "id": "fzRi4z0Emx1x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paths(directory):\n",
        "  all_path = []\n",
        "  idc_image_path = []\n",
        "  idc_image_label = []\n",
        "\n",
        "  for dir, subdir, files in os.walk(directory):\n",
        "    path = dir + \"/\"\n",
        "    all_path.append(path)\n",
        "\n",
        "  for i in range(len(all_path)):\n",
        "    for file in os.listdir(all_path[i]):\n",
        "      test = file\n",
        "      path = all_path[i] + test\n",
        "      if path.lower().endswith('.png'):\n",
        "        idc_image_path.append(path)\n",
        "\n",
        "  for i in range(len(idc_image_path)):\n",
        "    split_test = idc_image_path[i]\n",
        "    split_path = split_test.split(\"/\")\n",
        "    directory_name = split_path[7]\n",
        "    idc_image_label.append('class_' + split_path[8])\n",
        "    # idc_image_label.append(str(split_path[8]))\n",
        "  return idc_image_path, idc_image_label, directory_name"
      ],
      "metadata": {
        "id": "R_-TmPzBmxsB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, train_labels, train_dir = get_paths(train_image_directory)\n",
        "val_paths, val_labels, val_dir = get_paths(val_image_directory)\n",
        "test_paths, test_labels, test_dir = get_paths(test_image_directory)"
      ],
      "metadata": {
        "id": "SJ6Cl4wtmxjO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_paths), len(train_labels))\n",
        "print(len(test_paths), len(test_labels))\n",
        "print(len(val_paths), len(val_labels))"
      ],
      "metadata": {
        "id": "NIf9ETAsmxa2",
        "outputId": "4c226c9c-0aac-4aa4-80e1-0d03dd793055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 800\n",
            "200 200\n",
            "200 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_paths)\n",
        "print(train_labels)\n",
        "print(train_dir)"
      ],
      "metadata": {
        "id": "uCJzEwS8mxSR",
        "outputId": "c723a12e-3767-4d4b-f8c3-85f83d84372c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12880_idx5_x451_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9345_idx5_x2001_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12817_idx5_x2401_y201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10259_idx5_x2351_y251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x1301_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x1951_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14210_idx5_x1251_y1751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10278_idx5_x901_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9261_idx5_x1151_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12930_idx5_x1901_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8867_idx5_x851_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9036_idx5_x2651_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10254_idx5_x1051_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12896_idx5_x2301_y2051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12749_idx5_x2201_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12751_idx5_x801_y1601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12930_idx5_x501_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13459_idx5_x401_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14306_idx5_x1701_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10285_idx5_x1701_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12905_idx5_x2251_y1351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9123_idx5_x2051_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15903_idx5_x551_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12905_idx5_x1851_y2301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15902_idx5_x2951_y2501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16550_idx5_x1601_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13460_idx5_x1401_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14156_idx5_x1851_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9037_idx5_x2251_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10300_idx5_x2951_y1351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16014_idx5_x1401_y251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9075_idx5_x2601_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10282_idx5_x1351_y2501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14191_idx5_x3251_y2501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13462_idx5_x1601_y2551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14156_idx5_x2001_y401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9078_idx5_x601_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10268_idx5_x2451_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12934_idx5_x451_y1601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16569_idx5_x401_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13400_idx5_x1301_y2051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9029_idx5_x701_y201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13021_idx5_x2101_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12824_idx5_x1901_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12908_idx5_x1651_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13106_idx5_x351_y1901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10291_idx5_x3251_y401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9075_idx5_x2201_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10302_idx5_x2801_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x301_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10301_idx5_x1851_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10259_idx5_x1551_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10259_idx5_x1551_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12810_idx5_x801_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16165_idx5_x951_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9125_idx5_x701_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10286_idx5_x1051_y901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16552_idx5_x701_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8956_idx5_x2601_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10302_idx5_x501_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12931_idx5_x901_y1751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13021_idx5_x2351_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8956_idx5_x2751_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8867_idx5_x2201_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14156_idx5_x601_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15513_idx5_x1201_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10262_idx5_x501_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10258_idx5_x1001_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16555_idx5_x451_y301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10254_idx5_x651_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9320_idx5_x3301_y1851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9077_idx5_x851_y101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9073_idx5_x1851_y51_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9259_idx5_x1601_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10308_idx5_x751_y1951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9076_idx5_x501_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9382_idx5_x201_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12897_idx5_x2251_y2101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15510_idx5_x1201_y1951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x2951_y1801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15632_idx5_x3101_y2551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10307_idx5_x2151_y401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9043_idx5_x1651_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16085_idx5_x901_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12750_idx5_x1651_y1601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12821_idx5_x501_y451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13693_idx5_x501_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14211_idx5_x1801_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9076_idx5_x2601_y2051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10300_idx5_x2201_y1751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13693_idx5_x851_y2451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10268_idx5_x1351_y51_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12819_idx5_x2601_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9319_idx5_x1601_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9181_idx5_x1101_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x201_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x901_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12751_idx5_x1701_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10282_idx5_x1151_y2251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9256_idx5_x1901_y51_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13022_idx5_x2851_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10302_idx5_x1351_y301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13591_idx5_x3101_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12934_idx5_x1601_y2551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9126_idx5_x2751_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10301_idx5_x2201_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12878_idx5_x601_y2651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12947_idx5_x2151_y2351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12947_idx5_x3001_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10285_idx5_x851_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13689_idx5_x1451_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14157_idx5_x2551_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15516_idx5_x2901_y1951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12870_idx5_x901_y1351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9036_idx5_x1851_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10253_idx5_x1601_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10303_idx5_x1151_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8867_idx5_x2251_y901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12910_idx5_x401_y251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12895_idx5_x3401_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15473_idx5_x1151_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13401_idx5_x1351_y1351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9126_idx5_x1651_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9320_idx5_x2201_y1601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9023_idx5_x651_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9125_idx5_x1551_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9023_idx5_x601_y401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15473_idx5_x1401_y251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9346_idx5_x1001_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10274_idx5_x1151_y1851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12820_idx5_x1801_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8975_idx5_x3551_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9177_idx5_x2951_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10275_idx5_x651_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10307_idx5_x2101_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13024_idx5_x551_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12905_idx5_x2151_y2151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12896_idx5_x751_y1601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9135_idx5_x1001_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16551_idx5_x1651_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13916_idx5_x2351_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12932_idx5_x1151_y51_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8975_idx5_x1301_y2551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9323_idx5_x1501_y1851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12908_idx5_x1801_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13462_idx5_x2451_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8956_idx5_x2901_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13020_idx5_x2051_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8913_idx5_x2201_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8984_idx5_x1651_y101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13693_idx5_x2601_y2101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12947_idx5_x2801_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13459_idx5_x1301_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9383_idx5_x1801_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12826_idx5_x3501_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13021_idx5_x1501_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9346_idx5_x951_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10282_idx5_x3101_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9250_idx5_x2201_y451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12823_idx5_x1751_y1951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12749_idx5_x1101_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12626_idx5_x1551_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8918_idx5_x1101_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8864_idx5_x3051_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9250_idx5_x1801_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15902_idx5_x3751_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12810_idx5_x2451_y2301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13617_idx5_x1001_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10290_idx5_x3101_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12935_idx5_x701_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9226_idx5_x1301_y1901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10255_idx5_x1301_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10291_idx5_x801_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12819_idx5_x1151_y451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15902_idx5_x301_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9345_idx5_x1951_y2651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13024_idx5_x2201_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12911_idx5_x1851_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15472_idx5_x3051_y2201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13400_idx5_x2001_y2251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8863_idx5_x551_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13018_idx5_x401_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8974_idx5_x251_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9324_idx5_x851_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8956_idx5_x2551_y1901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12891_idx5_x2801_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9250_idx5_x1451_y401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9265_idx5_x151_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10278_idx5_x1001_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16550_idx5_x2101_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10262_idx5_x301_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10264_idx5_x2451_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8918_idx5_x551_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9181_idx5_x951_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8975_idx5_x1401_y2501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12750_idx5_x351_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12820_idx5_x3251_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14154_idx5_x1751_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9181_idx5_x551_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10277_idx5_x1351_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9078_idx5_x2201_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9255_idx5_x1901_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12892_idx5_x1001_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9029_idx5_x2801_y451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12819_idx5_x3051_y2401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9383_idx5_x1851_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16550_idx5_x1351_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12911_idx5_x2301_y251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13460_idx5_x2001_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14156_idx5_x551_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8865_idx5_x2101_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9265_idx5_x3101_y1951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13462_idx5_x2751_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9075_idx5_x1951_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9123_idx5_x1051_y1801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12934_idx5_x951_y2251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10282_idx5_x801_y2151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13460_idx5_x1751_y901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12947_idx5_x1651_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x1851_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x501_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16085_idx5_x1101_y2351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9176_idx5_x701_y2101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14157_idx5_x3401_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10295_idx5_x901_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x3351_y151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10261_idx5_x2351_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10308_idx5_x3101_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12821_idx5_x2301_y201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10301_idx5_x651_y1351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9176_idx5_x1951_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10291_idx5_x251_y2101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10274_idx5_x1051_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10282_idx5_x1801_y2501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15514_idx5_x1901_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16531_idx5_x901_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9041_idx5_x2601_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12910_idx5_x3351_y1101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9041_idx5_x3251_y1751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13460_idx5_x1351_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10304_idx5_x1901_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9173_idx5_x401_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9181_idx5_x401_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12826_idx5_x501_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13591_idx5_x2401_y2301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x2351_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10279_idx5_x2451_y301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10276_idx5_x951_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15513_idx5_x1001_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x3351_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12910_idx5_x2951_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14191_idx5_x1701_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12934_idx5_x1101_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13459_idx5_x1651_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9022_idx5_x201_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13021_idx5_x2201_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12907_idx5_x2201_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9259_idx5_x551_y2151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10259_idx5_x2451_y1451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9257_idx5_x301_y1851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9075_idx5_x2601_y2351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10273_idx5_x1651_y251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12879_idx5_x201_y301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12810_idx5_x3201_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14192_idx5_x1751_y101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14190_idx5_x2401_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9265_idx5_x1301_y301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12877_idx5_x301_y1351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9265_idx5_x1901_y1901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10259_idx5_x2101_y51_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8867_idx5_x2551_y1901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12896_idx5_x1551_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16551_idx5_x1351_y2851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10300_idx5_x3201_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8951_idx5_x2151_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13022_idx5_x2551_y251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8974_idx5_x251_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8956_idx5_x1901_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15515_idx5_x1551_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12749_idx5_x3301_y401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12930_idx5_x451_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13460_idx5_x301_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13692_idx5_x1301_y2401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10292_idx5_x3351_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8974_idx5_x1251_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x1601_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15513_idx5_x1351_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16085_idx5_x2801_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12826_idx5_x451_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x101_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12954_idx5_x1651_y2951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14155_idx5_x3501_y2051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10288_idx5_x2101_y2101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8867_idx5_x2801_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8959_idx5_x501_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9178_idx5_x351_y1751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9177_idx5_x1151_y151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9325_idx5_x1151_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10300_idx5_x901_y1801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10282_idx5_x2351_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9324_idx5_x801_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12749_idx5_x2201_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12823_idx5_x3551_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8867_idx5_x1401_y1801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12934_idx5_x2901_y2551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12954_idx5_x2301_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10300_idx5_x2451_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10261_idx5_x751_y451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9075_idx5_x1601_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10301_idx5_x1501_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10277_idx5_x651_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9259_idx5_x3051_y2151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16896_idx5_x651_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12935_idx5_x1301_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9126_idx5_x1651_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10272_idx5_x3051_y2051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13693_idx5_x2151_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14192_idx5_x2601_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13687_idx5_x2551_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16553_idx5_x301_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12905_idx5_x1951_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16550_idx5_x601_y2401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15513_idx5_x651_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13106_idx5_x1_y2951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14079_idx5_x2301_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14189_idx5_x3001_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8913_idx5_x2151_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9225_idx5_x601_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10268_idx5_x2401_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9267_idx5_x501_y1351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12886_idx5_x751_y1001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9347_idx5_x2101_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12869_idx5_x651_y1751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16552_idx5_x801_y901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15840_idx5_x1251_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9123_idx5_x2101_y2401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10276_idx5_x251_y501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12932_idx5_x1651_y201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10299_idx5_x451_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9265_idx5_x2351_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16555_idx5_x351_y301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10254_idx5_x2151_y451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x2901_y1951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9073_idx5_x2851_y1251_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10295_idx5_x1251_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10259_idx5_x1201_y1951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10292_idx5_x3451_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16568_idx5_x2551_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14305_idx5_x2201_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13460_idx5_x351_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13459_idx5_x401_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8864_idx5_x1901_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12910_idx5_x2201_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10259_idx5_x1851_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14079_idx5_x2701_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13106_idx5_x3201_y2001_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12894_idx5_x2401_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9324_idx5_x851_y1501_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9320_idx5_x2851_y2101_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13024_idx5_x1051_y1301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12930_idx5_x2601_y1651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12822_idx5_x1951_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9078_idx5_x1401_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16570_idx5_x601_y1201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16551_idx5_x1751_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10308_idx5_x101_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9075_idx5_x851_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16014_idx5_x1751_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9322_idx5_x1651_y301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12870_idx5_x2551_y201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9173_idx5_x1151_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14156_idx5_x2501_y2151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12929_idx5_x1101_y1_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9225_idx5_x851_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16568_idx5_x2851_y351_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12954_idx5_x1251_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14155_idx5_x2401_y2051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16553_idx5_x451_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16550_idx5_x851_y1551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12750_idx5_x2651_y1401_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/16570_idx5_x2801_y1151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9076_idx5_x2451_y2301_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9036_idx5_x3401_y1051_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8918_idx5_x301_y151_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12911_idx5_x2351_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8980_idx5_x601_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14210_idx5_x1101_y1801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12821_idx5_x901_y451_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12933_idx5_x1051_y551_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10274_idx5_x851_y651_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9266_idx5_x3201_y751_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9290_idx5_x2501_y951_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/8959_idx5_x1751_y2201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/15513_idx5_x301_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12908_idx5_x1451_y801_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14079_idx5_x2851_y851_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14155_idx5_x2851_y2201_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/10260_idx5_x2401_y601_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/13693_idx5_x1401_y1701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/14157_idx5_x1851_y1901_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x1501_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9173_idx5_x1551_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12882_idx5_x1401_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10299_idx5_x1351_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9044_idx5_x701_y601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16166_idx5_x1501_y1801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9261_idx5_x1101_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12907_idx5_x2301_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13687_idx5_x1951_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16165_idx5_x2201_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12935_idx5_x1651_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16568_idx5_x2001_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16568_idx5_x1551_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10302_idx5_x1851_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9255_idx5_x2901_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13404_idx5_x1851_y1801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10293_idx5_x1401_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x2201_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13024_idx5_x451_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12949_idx5_x1651_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9267_idx5_x2201_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9324_idx5_x1051_y351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10307_idx5_x1601_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9173_idx5_x2151_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16570_idx5_x1601_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14154_idx5_x2051_y1251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12752_idx5_x2501_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10302_idx5_x2101_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12749_idx5_x2751_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x2351_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15510_idx5_x2401_y2101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16553_idx5_x601_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10264_idx5_x1701_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12884_idx5_x1451_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8867_idx5_x551_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10293_idx5_x1401_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x1651_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15516_idx5_x2251_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12751_idx5_x2051_y2401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9124_idx5_x1701_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9256_idx5_x1751_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12895_idx5_x1901_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16165_idx5_x2051_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10299_idx5_x2001_y2151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9262_idx5_x551_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9383_idx5_x1751_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13591_idx5_x2551_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15471_idx5_x2051_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12817_idx5_x1201_y501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16165_idx5_x1151_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12879_idx5_x601_y251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10256_idx5_x1951_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1601_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8864_idx5_x2101_y2501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10264_idx5_x1301_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10293_idx5_x1301_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9255_idx5_x3151_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1201_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8974_idx5_x751_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16165_idx5_x1251_y2301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13402_idx5_x2001_y251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14155_idx5_x2551_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14078_idx5_x1151_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13693_idx5_x551_y1801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14155_idx5_x3251_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13019_idx5_x1701_y1801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14154_idx5_x1551_y401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10303_idx5_x2101_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12901_idx5_x2151_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8864_idx5_x2301_y2601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8867_idx5_x1151_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16553_idx5_x1501_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9226_idx5_x1001_y2251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14191_idx5_x2201_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12817_idx5_x1801_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x2401_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9267_idx5_x2301_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12891_idx5_x551_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10299_idx5_x1601_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1601_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12818_idx5_x2551_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14190_idx5_x1051_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9267_idx5_x1851_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x1801_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x2001_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15840_idx5_x501_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x1501_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10300_idx5_x2101_y601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12892_idx5_x2051_y451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8864_idx5_x2101_y2151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12884_idx5_x1501_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12826_idx5_x2801_y451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12873_idx5_x1251_y351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12886_idx5_x251_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10303_idx5_x1001_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15840_idx5_x801_y1051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8867_idx5_x951_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9267_idx5_x2251_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9029_idx5_x2251_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10262_idx5_x1901_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14154_idx5_x2751_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12935_idx5_x1501_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x1301_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13402_idx5_x2301_y51_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10276_idx5_x1001_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1951_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10262_idx5_x1651_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12891_idx5_x1801_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x1451_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12909_idx5_x1251_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9226_idx5_x951_y2601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15473_idx5_x1901_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x2301_y1051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13693_idx5_x701_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13693_idx5_x451_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13459_idx5_x1051_y501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13022_idx5_x1451_y2451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12826_idx5_x2851_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9226_idx5_x1601_y2551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14191_idx5_x2401_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12752_idx5_x2601_y501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12752_idx5_x1851_y501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15473_idx5_x901_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13022_idx5_x2201_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16165_idx5_x1601_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9176_idx5_x1851_y2001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12934_idx5_x1951_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x1801_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9346_idx5_x1351_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12823_idx5_x2851_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12934_idx5_x2251_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14154_idx5_x2101_y351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10299_idx5_x1601_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1151_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16167_idx5_x2251_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16570_idx5_x2451_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16568_idx5_x2201_y1051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13462_idx5_x501_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13591_idx5_x2301_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16166_idx5_x1551_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9023_idx5_x1451_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14190_idx5_x2451_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9023_idx5_x1351_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9261_idx5_x2501_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13462_idx5_x601_y2151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x1201_y1801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16554_idx5_x351_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14154_idx5_x2001_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12934_idx5_x2451_y1901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9261_idx5_x1651_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15516_idx5_x1601_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10293_idx5_x901_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13693_idx5_x1201_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9344_idx5_x1751_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16532_idx5_x2251_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9255_idx5_x2651_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9125_idx5_x1501_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8950_idx5_x1301_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12817_idx5_x2501_y451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8917_idx5_x501_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13019_idx5_x1701_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12907_idx5_x1751_y2451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x2501_y2001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14157_idx5_x2251_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13459_idx5_x1201_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12818_idx5_x1651_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9078_idx5_x1901_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9123_idx5_x1851_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10304_idx5_x801_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10264_idx5_x851_y1801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9173_idx5_x2401_y1901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13691_idx5_x2451_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15633_idx5_x1401_y651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8956_idx5_x1301_y301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8917_idx5_x1151_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9250_idx5_x851_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1451_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8864_idx5_x2501_y2451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14191_idx5_x2451_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12823_idx5_x3351_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12897_idx5_x2201_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9346_idx5_x2101_y2301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15473_idx5_x1751_y1901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12867_idx5_x2051_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10303_idx5_x2551_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9173_idx5_x2401_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12826_idx5_x2801_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9250_idx5_x851_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x1501_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x2351_y2201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14213_idx5_x1701_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12880_idx5_x301_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12820_idx5_x2651_y601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9260_idx5_x701_y101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12895_idx5_x1851_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12818_idx5_x1401_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9259_idx5_x1401_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12751_idx5_x2601_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x2201_y2351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12908_idx5_x2251_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15633_idx5_x1351_y301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12935_idx5_x1701_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12893_idx5_x251_y2151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9177_idx5_x1751_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14188_idx5_x1551_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12931_idx5_x1451_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12900_idx5_x2301_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12949_idx5_x1451_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10264_idx5_x1151_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8917_idx5_x1551_y351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15473_idx5_x2101_y1051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10274_idx5_x2051_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9083_idx5_x1451_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9345_idx5_x1951_y401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12947_idx5_x1701_y2451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13616_idx5_x2351_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12752_idx5_x2851_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12895_idx5_x1951_y2451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9043_idx5_x3251_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12752_idx5_x2351_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9043_idx5_x3501_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9078_idx5_x1651_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9344_idx5_x2351_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12910_idx5_x901_y251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14154_idx5_x1451_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10274_idx5_x1501_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10256_idx5_x1801_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15634_idx5_x1001_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12908_idx5_x2251_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13613_idx5_x2001_y2151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14306_idx5_x2201_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13403_idx5_x901_y251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9382_idx5_x1551_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9175_idx5_x1801_y201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10299_idx5_x1601_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x2101_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15902_idx5_x2201_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10308_idx5_x1951_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x451_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14191_idx5_x2201_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12817_idx5_x1901_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10256_idx5_x1801_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12895_idx5_x1401_y1251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12751_idx5_x1201_y1301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10264_idx5_x1301_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15902_idx5_x2451_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x2701_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12893_idx5_x1201_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10253_idx5_x551_y651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12626_idx5_x1301_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12821_idx5_x1951_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15516_idx5_x1951_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9023_idx5_x1351_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9124_idx5_x1151_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x2001_y2501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9135_idx5_x1151_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10302_idx5_x851_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10302_idx5_x1601_y2051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16554_idx5_x951_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10264_idx5_x1151_y1251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12820_idx5_x3051_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9324_idx5_x1301_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8956_idx5_x1051_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x2351_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12820_idx5_x3151_y251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8950_idx5_x451_y651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9041_idx5_x2351_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9125_idx5_x1251_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9324_idx5_x1151_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15473_idx5_x1651_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9265_idx5_x1801_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16165_idx5_x2301_y2051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16532_idx5_x951_y651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x1601_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15903_idx5_x1151_y1251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12752_idx5_x1951_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9321_idx5_x1851_y2001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9029_idx5_x2251_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12811_idx5_x801_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10264_idx5_x1301_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13025_idx5_x2101_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9176_idx5_x1651_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15515_idx5_x251_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12817_idx5_x1251_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10306_idx5_x801_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12908_idx5_x2201_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12909_idx5_x1151_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8974_idx5_x1351_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14155_idx5_x3551_y501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12934_idx5_x2751_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9255_idx5_x2801_y401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12895_idx5_x1951_y1251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9347_idx5_x701_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16896_idx5_x801_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x2551_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9126_idx5_x2201_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12749_idx5_x3301_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x2351_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12894_idx5_x1351_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13459_idx5_x1051_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9043_idx5_x2751_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13024_idx5_x1001_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14211_idx5_x1901_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12820_idx5_x2901_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10277_idx5_x751_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13616_idx5_x1151_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12949_idx5_x1701_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9381_idx5_x751_y1251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8864_idx5_x1801_y2151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10259_idx5_x1501_y1801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12880_idx5_x901_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13613_idx5_x2201_y2001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9043_idx5_x2801_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9345_idx5_x2451_y51_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12880_idx5_x1651_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9226_idx5_x701_y2401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9267_idx5_x2001_y301_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15902_idx5_x2701_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12909_idx5_x1551_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10292_idx5_x1251_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12872_idx5_x1301_y351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9257_idx5_x1801_y451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1101_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9250_idx5_x1201_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13022_idx5_x2101_y1951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13616_idx5_x1901_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14190_idx5_x2101_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14081_idx5_x2651_y201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9043_idx5_x3151_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9022_idx5_x2451_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9323_idx5_x1501_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12906_idx5_x1901_y2501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15902_idx5_x2951_y1251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9077_idx5_x1101_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12910_idx5_x651_y51_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9226_idx5_x1251_y2051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16554_idx5_x1351_y1051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8980_idx5_x1001_y1201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12873_idx5_x1401_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10303_idx5_x1801_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12951_idx5_x1401_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13691_idx5_x3101_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9346_idx5_x2001_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9257_idx5_x1301_y401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14155_idx5_x2901_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14154_idx5_x2201_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14079_idx5_x1201_y1051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15473_idx5_x801_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15902_idx5_x2651_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9023_idx5_x2201_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12949_idx5_x1701_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14209_idx5_x1351_y401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9320_idx5_x2001_y2251_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15840_idx5_x1551_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9346_idx5_x1701_y1901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14191_idx5_x2001_y2051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9257_idx5_x1701_y451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9323_idx5_x1251_y1401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14155_idx5_x2301_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9178_idx5_x901_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12901_idx5_x2301_y1001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9041_idx5_x2301_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9254_idx5_x2751_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10269_idx5_x1351_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12823_idx5_x2751_y851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16570_idx5_x1701_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14191_idx5_x1701_y2201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13616_idx5_x1401_y2201_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16166_idx5_x2151_y1501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8917_idx5_x1051_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12242_idx5_x1951_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10306_idx5_x351_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8917_idx5_x1051_y601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13691_idx5_x2551_y1101_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12910_idx5_x1001_y551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13692_idx5_x2401_y751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16896_idx5_x251_y1151_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10274_idx5_x1901_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9126_idx5_x2251_y1851_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12242_idx5_x1501_y951_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/13916_idx5_x1751_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14157_idx5_x1701_y1701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16165_idx5_x1651_y1651_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12894_idx5_x1551_y701_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16553_idx5_x1501_y1051_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9258_idx5_x1501_y1451_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14155_idx5_x2451_y351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8975_idx5_x2701_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12821_idx5_x1651_y1601_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/16550_idx5_x2851_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14081_idx5_x2451_y401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12884_idx5_x1701_y501_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/15473_idx5_x1251_y1351_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14305_idx5_x1451_y901_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14082_idx5_x1251_y1751_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/14190_idx5_x2701_y1551_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/8864_idx5_x1701_y2401_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/9320_idx5_x1701_y2001_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/12909_idx5_x951_y801_class1.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/1/10273_idx5_x2151_y1751_class1.png']\n",
            "['class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1', 'class_1']\n",
            "Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframes(idc_image_path, idc_image_label, directory_name):\n",
        "  same_name = directory_name.lower() + '_'\n",
        "  #creating the dataframes that we will be passing to our generators\n",
        "  idc_data_cleaned = {'path': idc_image_path,\n",
        "            'label': idc_image_label}\n",
        "  idc_df = pd.DataFrame(idc_data_cleaned)\n",
        "  df = idc_df.sample(frac = 1)\n",
        "  print(df)\n",
        "  csv_path = directory_path\n",
        "  csv_file = df.to_csv(csv_path + '/' + same_name + 'idc_dataframe.csv')\n",
        "  csv_file_path = csv_path + '/' + same_name + 'idc_dataframe.csv'\n",
        "  return csv_file_path"
      ],
      "metadata": {
        "id": "_WU9qt2RmxHZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_dataframes(idc_image_path, idc_image_label, directory_name):\n",
        "#   same_name = directory_name.lower() + '_'\n",
        "#   #creating the dataframes that we will be passing to our generators\n",
        "#   idc_data_cleaned = {'path': idc_image_path,\n",
        "#             'label': idc_image_label}\n",
        "#   idc_df = pd.DataFrame(idc_data_cleaned)\n",
        "#   df = idc_df.sample(frac = 1)\n",
        "#   print(df)\n",
        "#   csv_path = directory_path\n",
        "#   csv_file = df.to_csv(csv_path + '/' + same_name + 'idc_dataframe.csv')\n",
        "#   # csv_file_path = csv_path + '/' + same_name + 'idc_dataframe.csv'\n",
        "#   return csv_file"
      ],
      "metadata": {
        "id": "Lsz7FKbTNepA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "print(type(train_dataframe))\n",
        "train_dataframe"
      ],
      "metadata": {
        "id": "MJxUgm39NeU7",
        "outputId": "7fca9ab4-84fc-4052-a6b2-5d8fc8b664c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  path    label\n",
            "297  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "637  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "387  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "485  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "674  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "..                                                 ...      ...\n",
            "740  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "122  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "119  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "516  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "777  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "\n",
            "[800 rows x 2 columns]\n",
            "<class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Kaggle/CNN_IDC/train_idc_dataframe.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "train_generator = pd.read_csv(train_dataframe)\n",
        "\n",
        "test_dataframe = create_dataframes(test_paths, test_labels, test_dir)\n",
        "test_generator = pd.read_csv(test_dataframe)\n",
        "\n",
        "val_dataframe = create_dataframes(val_paths, val_labels, val_dir)\n",
        "val_generator = pd.read_csv(val_dataframe)"
      ],
      "metadata": {
        "id": "hnDu_3N4mw1G",
        "outputId": "7a3c8163-2666-49fd-d9f7-45a37901fdbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  path    label\n",
            "461  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "719  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "267  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "670  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "89   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "..                                                 ...      ...\n",
            "407  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "65   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "530  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "422  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "365  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "\n",
            "[800 rows x 2 columns]\n",
            "                                                  path    label\n",
            "149  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "50   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "152  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "158  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "39   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "..                                                 ...      ...\n",
            "18   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "5    /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "109  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "94   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "154  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "\n",
            "[200 rows x 2 columns]\n",
            "                                                  path    label\n",
            "76   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "96   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "61   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "166  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "44   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "..                                                 ...      ...\n",
            "79   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "179  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "182  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "50   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "55   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "\n",
            "[200 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator = ImageDataGenerator()\n",
        "\n",
        "train_data_generator = data_generator.flow_from_dataframe(\n",
        "    train_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        "    # seed=1234\n",
        "    # validate_filenames=True\n",
        ")\n",
        "\n",
        "validation_data_generator = data_generator.flow_from_dataframe(\n",
        "    val_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        "    # seed=1234\n",
        "    # validate_filenames=True\n",
        ")\n",
        "\n",
        "test_data_generator = data_generator.flow_from_dataframe(\n",
        "    test_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        "    # seed=1234\n",
        "    # validate_filenames=True\n",
        ")"
      ],
      "metadata": {
        "id": "eC0S3je4Jnwb",
        "outputId": "eddf6b1f-8d42-4181-9777-0defde93deb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 50\n",
        "img_width = 50\n",
        "img_channel = 1"
      ],
      "metadata": {
        "id": "OQcHdDdYJnol"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_doc_id_model():\n",
        "  return tf.keras.Sequential([\n",
        "                           keras.layers.Conv2D(input_shape = (img_height, img_width, img_channel), \n",
        "                                               filters=32, \n",
        "                                               kernel_size=(3, 3),\n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                           \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                                  strides=(2, 2)),\n",
        "                           \n",
        "                           keras.layers.Conv2D(filters=64, \n",
        "                                               kernel_size=(3, 3), \n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                              \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                                  strides=(2, 2)),\n",
        "                          \n",
        "                           keras.layers.Conv2D(filters=128, \n",
        "                                               kernel_size=(3, 3), \n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                          \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2), \n",
        "                                                  strides=(2, 2)),\n",
        "                           \n",
        "                           keras.layers.Flatten(),\n",
        "                           \n",
        "                           keras.layers.Dense(units = 256, \n",
        "                                              activation = 'relu'),\n",
        "                           \n",
        "                          #  keras.layers.Dense(units = 512, \n",
        "                          #                     activation = 'relu'),\n",
        "                           \n",
        "                           keras.layers.Dense(units = 2, \n",
        "                                              activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "-aJNqzI4JngT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = get_doc_id_model()\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001), \n",
        "                    loss=keras.losses.categorical_crossentropy, \n",
        "                    metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "8FPJqXiDJnZC",
        "outputId": "96a834f3-5785-40f3-b7c3-7949bd4f39b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 50, 50, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 25, 25, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1179904   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,273,090\n",
            "Trainable params: 1,273,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "val_acc_early_stopping = EarlyStopping(monitor = 'val_acc', \n",
        "                                       patience = 6, \n",
        "                                       verbose = 1,\n",
        "                                       mode = 'auto')"
      ],
      "metadata": {
        "id": "TCHVLIBUJnQ8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data_generator,\n",
        "                 epochs=7,\n",
        "                #  callbacks=[val_acc_early_stopping],\n",
        "                 validation_data = validation_data_generator\n",
        "                 )"
      ],
      "metadata": {
        "id": "1aK-mML9JnID",
        "outputId": "22ef2b7f-d298-4b7a-f3be-5e5527fefeea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "25/25 [==============================] - 113s 5s/step - loss: 12.9503 - accuracy: 0.5250 - val_loss: 0.6258 - val_accuracy: 0.6300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = history.history\n",
        "x_arr = np.arange(len(hist['loss'])) + 1\n",
        "# print(x_arr)\n",
        "\n",
        "fig = plt.figure(figsize=(16,6))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.plot(x_arr, hist['loss'], '-o', label='Train Loss')\n",
        "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation Loss')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Loss', size=14)\n",
        "ax.set_title('Loss', size=20)\n",
        "\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.plot(x_arr, hist['accuracy'], '-o', label='Train Acc.')\n",
        "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation Acc.')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Accuracy', size=14)\n",
        "ax.set_title('Accuracy', size=20);"
      ],
      "metadata": {
        "id": "v1a4RY1gK5kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test = model.evaluate(test_data_generator)\n",
        "print(f'Test Accuracy: {eval_test[1]*100:.2f}%\\n')\n",
        "\n",
        "eval_train = model.evaluate(train_data_generator)\n",
        "print(f'Train Accuracy: {eval_train[1]*100:.2f}%')"
      ],
      "metadata": {
        "id": "YEAMNOELK5bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = test_data_generator.classes\n",
        "y_pred = (model.predict(test_data_generator) > 0.5).astype('int32')\n",
        "# y_pred"
      ],
      "metadata": {
        "id": "kJPHLF45bvjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "conf_max = confusion_matrix(y_true, y_pred)\n",
        "# sns.heatmap(conf_max, annot=True, fmt='d')\n",
        "\n",
        "# plt.xlable('pred label')\n",
        "# plt.ylabel('true label')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "XQNddxDYb8v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data_generator"
      ],
      "metadata": {
        "id": "GARos0NOaqpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Transform logits to probabilities\n",
        "pred_logits = model.predict(test_data_generator)\n",
        "probabilities = tf.sigmoid(pred_logits)\n",
        "probabilities = probabilities.numpy().flatten()*100\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "Fg8mGcfKK5Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize=(16,25))\n",
        "\n",
        "# for j, example in enumerate(test_data_generator[:20]):\n",
        "#     ax = fig.add_subplot(8,4, j+1)\n",
        "#     ax.set_xticks([])\n",
        "#     ax.set_yticks([])\n",
        "#     ax.imshow(array_to_img(example))\n",
        "#     if y_test[j]==0:\n",
        "#         label='Non-IDC'\n",
        "#     else:\n",
        "#         label='IDC'\n",
        "    \n",
        "#     ax.text(\n",
        "#         0.5, -0.15, \n",
        "#         'True Label: {:s}\\nPr(IDC)={:.0f}%'.format(label, probabilities[j]), \n",
        "#         size=14, \n",
        "#         color='grey',\n",
        "#         horizontalalignment='center',\n",
        "#         verticalalignment='center', \n",
        "#         transform=ax.transAxes)\n",
        "    \n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "iydlEDpFK5GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiMC7RfGJm4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read training/test/validation images \n"
      ],
      "metadata": {
        "id": "SYpLshTCwEci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_images(binary_class, folder):\n",
        "  current_working_dir = os.getcwd()\n",
        "  image_files_w_path, image_files_wo_path = [], []\n",
        "  for img in glob.glob(os.path.join(current_working_dir, folder + binary_class + '/') + '*.png'):\n",
        "    image_files_w_path.append(img)\n",
        "    image_wo_path = os.path.basename(img)\n",
        "    image_files_wo_path.append(image_wo_path) \n",
        "  # if folder == 'Dataset/Train/':\n",
        "  #   image_files_wo_path, image_files_w_path = image_files_wo_path[:200], image_files_w_path[:200]\n",
        "  return image_files_wo_path, image_files_w_path    "
      ],
      "metadata": {
        "id": "oEVGLHwn-k-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Read Training Images ============================= #\n",
        "# ======================================================================== #\n",
        "\n",
        "train_class_1_wo_path, train_class_1_w_path = read_images('1', 'Dataset/Train/')\n",
        "train_class_0_wo_path, train_class_0_w_path = read_images('0', 'Dataset/Train/')\n",
        "train_full_wo_path = train_class_1_wo_path + train_class_0_wo_path\n",
        "train_full_w_path = train_class_1_w_path + train_class_0_w_path\n",
        "\n",
        "print(f'Size of Train Class 1 = {len(train_class_1_wo_path)} | {type(train_class_1_wo_path)}\\nSample Images in Train Class 1:\\n {train_class_1_wo_path[:2]}')\n",
        "print(f'\\nxSize of Train Class 0 = {len(train_class_0_wo_path)} | {type(train_class_0_wo_path)}\\nSample Images in Train Class 0:\\n {train_class_0_wo_path[:2]}')\n",
        "print('\\nTrain class_1 and class_0 combined:\\n',train_full_wo_path[0], ',', train_full_wo_path[-1])\n",
        "print('\\nTrain class_1 with full path:\\n',train_class_1_w_path[:2])"
      ],
      "metadata": {
        "id": "HzYSVtoT8yr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Read Test Images ================================= #\n",
        "# ======================================================================== #\n",
        "\n",
        "test_class_1_wo_path, test_class_1_w_path = read_images('1', 'Dataset/Test/')\n",
        "test_class_0_wo_path, test_class_0_w_path = read_images('0', 'Dataset/Test/')\n",
        "test_full_wo_path = test_class_1_wo_path + test_class_0_wo_path\n",
        "test_full_w_path = test_class_1_w_path + test_class_0_w_path\n",
        "\n",
        "print(f'Size of Test Class 1 = {len(test_class_1_wo_path)} | {type(test_class_1_wo_path)}\\nSample Images in Test Class 1:\\n {test_class_1_wo_path[:2]}')\n",
        "print(f'\\nSize of Test Class 0 = {len(test_class_0_wo_path)} | {type(test_class_0_wo_path)}\\nSample Images in Test Class 0:\\n {test_class_0_wo_path[:2]}')\n",
        "print('\\nTest class_1 and class_0 combined:\\n',test_full_wo_path[0], ',', test_full_wo_path[-1])\n",
        "print('\\nTest class_1 with full path:\\n',test_class_1_wo_path[:2])"
      ],
      "metadata": {
        "id": "UtVObov-4P86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Read Validation Images =========================== #\n",
        "# ======================================================================== #\n",
        "\n",
        "val_class_1_wo_path, val_class_1_w_path = read_images('1', 'Dataset/Validate/')\n",
        "val_class_0_wo_path, val_class_0_w_path = read_images('0', 'Dataset/Validate/')\n",
        "val_full_wo_path = val_class_1_wo_path + val_class_0_wo_path\n",
        "val_full_w_path = val_class_1_w_path + val_class_0_w_path\n",
        "\n",
        "print(f'Size of Validation Class 1 = {len(val_class_1_wo_path)} | {type(val_class_1_wo_path)}\\nSample Images in Validation Class 1:\\n {val_class_1_wo_path[:2]}')\n",
        "print(f'\\nSize of Validation Class 0 = {len(val_class_0_wo_path)} | {type(val_class_0_wo_path)}\\nSample Images in Validation Class 0:\\n {val_class_0_wo_path[:2]}')\n",
        "print('\\nValidation class_1 and class_0 combined:\\n',val_full_wo_path[0], ',', val_full_wo_path[-1])\n",
        "print('\\nValidation class_1 with full path:\\n',val_class_1_wo_path[:2])"
      ],
      "metadata": {
        "id": "3hM8u4SI4tiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the number of train images in each class\n"
      ],
      "metadata": {
        "id": "2Tm1-FAi0Ivz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_class_size(class_1, class_0):\n",
        "  class_1_size, class_0_size = len(class_1), len(class_0)\n",
        "  count = pd.Series([class_1_size, class_0_size])\n",
        "  percent = round(count/(class_1_size + class_0_size)*100, 2)\n",
        "  df_perc = pd.concat({'class_count':count, 'class_percent(%)':percent}, axis=1)\n",
        "  df_perc['class'] = ['Class 1 (Malignant)', 'Class 0 (Benign)']\n",
        "  df_perc = df_perc[['class','class_count','class_percent(%)']]\n",
        "  print('Total Count (Balanced) = ', class_1_size + class_0_size)\n",
        "  return df_perc\n",
        "\n",
        "check_class_size(train_class_1_wo_path, train_class_0_wo_path)"
      ],
      "metadata": {
        "id": "EcPA8klvyBaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataframes of training/test/validation for each class"
      ],
      "metadata": {
        "id": "0xsLnUUBmfCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_class_df(class_1_w_path, class_0_w_path): \n",
        "  image_list_w_path = [x for x in class_1_w_path]\n",
        "  image_list_w_path.extend([x for x in class_0_w_path])\n",
        "  df_idc= pd.DataFrame(np.concatenate([['IDC']*len(class_1_w_path), ['Non_IDC']*len(class_0_w_path)]), columns=['class_str'])\n",
        "  df_idc['class'] = np.where(df_idc.class_str == 'IDC', 1, 0)\n",
        "  df_idc['image'] = [x for x in image_list_w_path]\n",
        "  print('Shape: ', df_idc.shape)\n",
        "  return df_idc"
      ],
      "metadata": {
        "id": "8EbfD5bymcWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Create Train DF ================================== #\n",
        "# ======================================================================== #\n",
        "df_train_full = create_class_df(train_class_1_w_path, train_class_0_w_path)\n",
        "training_sample_size = df_train_full.shape[0]\n",
        "df_train_full"
      ],
      "metadata": {
        "id": "MwPd_r3N9L5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Create Test DF ================================== #\n",
        "# ======================================================================== #\n",
        "df_test_full = create_class_df(test_class_1_w_path, test_class_0_w_path)\n",
        "df_test_full"
      ],
      "metadata": {
        "id": "7ZW6YphC9pjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Create Validation DF ============================= #\n",
        "# ======================================================================== #\n",
        "df_val_full = create_class_df(val_class_1_w_path, val_class_0_w_path)\n",
        "df_val_full"
      ],
      "metadata": {
        "id": "jxKruoce9puO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image distribution in the training data set"
      ],
      "metadata": {
        "id": "Ea7hjtdQ967V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "ax = sns.countplot(df_train_full['class_str'], data=df_train_full)\n",
        "plt.xlabel('Class', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.title('Number of Cases', fontsize=18)\n",
        "plt.ylim(0,450)\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "               (p.get_x() + p.get_width()/2., \n",
        "                p.get_height()), ha='center', va='center', size=15, xytext=(0,9),\n",
        "               textcoords = 'offset points', fontsize=13)"
      ],
      "metadata": {
        "id": "fzBCqbbspPsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display 6 train images for each class\n"
      ],
      "metadata": {
        "id": "8b3Am88FHQVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(subclass, class_name):\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(17,6))\n",
        "  # images = []\n",
        "  for idx, ax in enumerate(axes.flat):\n",
        "    img = io.imread(subclass[idx])\n",
        "    img = cv.resize(img, (224,224))    # resize an image from 50 by 50 to 512 by 512\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(class_name)\n",
        "    ax.set_xticks([])       # remove xticks passing an empty array\n",
        "    ax.set_yticks([])       # remove yticks passing an empty array\n",
        "  fig.tight_layout() \n",
        "  plt.show() \n",
        "\n",
        "display_images(train_class_1_w_path, 'Class 1: IDC')\n",
        "display_images(train_class_0_w_path, 'Class 0: Non-IDC')"
      ],
      "metadata": {
        "id": "xGK7hj3rNwPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Invasive ductal carcinoma (IDC) of the breast](https://www.mypathologyreport.ca/breast-invasive-ductal-carcinoma/)"
      ],
      "metadata": {
        "id": "tIBcckEAm-vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(cv.resize(io.imread('9383_idx5_x1951_y951_class1.png'), (80,80)))"
      ],
      "metadata": {
        "id": "WGcct9bEm99R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store actual color images as a vector\n"
      ],
      "metadata": {
        "id": "FOBIuMqY1n9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from skimage import color\n",
        "def store_actual_images_to_grayscale(class_1_w_path, class_0_w_path):\n",
        "  # read and store actual images (not the image paths) into the respective variable as a single vector then pass these to the model below\n",
        "  image_pixels_class1 = [io.imread(img) for img in class_1_w_path]\n",
        "  image_pixels_class0 = [io.imread(img) for img in class_0_w_path]\n",
        "  full_image_pixels = np.asarray(image_pixels_class1 + image_pixels_class1)   # => (#samples, width, height)\n",
        "  return image_pixels_class1, image_pixels_class0, full_image_pixels"
      ],
      "metadata": {
        "id": "bgERy51o1xuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Store Train Images =============================== #\n",
        "# ======================================================================== #\n",
        "train_img_class1, train_img_class0, train_full_img = store_actual_images_to_grayscale(train_class_1_w_path, train_class_0_w_path)\n",
        "\n",
        "print('Shape of each train image: ', train_img_class1[0].shape)\n",
        "print('\\nTotal number of images = ', len(train_full_img))\n",
        "print('Number of class 1 images = ', len(train_img_class1))\n",
        "print('Number of class 0 images = ', len(train_img_class0))\n",
        "print('train_full_img = ', train_full_img.shape)"
      ],
      "metadata": {
        "id": "0LwOFDh5-jnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Store Test Images ================================ #\n",
        "# ======================================================================== #\n",
        "test_img_class1, test_img_class0, test_full_img = store_actual_images_to_grayscale(test_class_1_w_path, test_class_0_w_path)\n",
        "\n",
        "print('Shape of each test image: ', test_img_class1[0].shape)\n",
        "print('\\nTotal number of images = ', len(test_full_img))\n",
        "print('Number of class 1 images = ', len(test_img_class1))\n",
        "print('Number of class 0 images = ', len(test_img_class0))\n",
        "print('test_full_img = ', test_full_img.shape)"
      ],
      "metadata": {
        "id": "KxXP8HZD_LdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Store Validation Images ========================== #\n",
        "# ======================================================================== #\n",
        "val_img_class1, val_img_class0, val_full_img = store_actual_images_to_grayscale(val_class_1_w_path, val_class_0_w_path)\n",
        "\n",
        "print('Shape of each validataion image: ', val_img_class1[0].shape)\n",
        "print('\\nTotal number of images = ', len(val_full_img))\n",
        "print('Number of class 1 images = ', len(val_img_class1))\n",
        "print('Number of class 0 images = ', len(val_img_class0))\n",
        "print('val_full_img = ', val_full_img.shape)"
      ],
      "metadata": {
        "id": "tOXd6Kb0_Ll6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image augmentation techniques on a training image"
      ],
      "metadata": {
        "id": "FsBDt4AnKGx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage import util\n",
        "from skimage.util import random_noise\n",
        "from skimage.restoration import denoise_tv_chambolle, denoise_bilateral, denoise_wavelet, estimate_sigma\n",
        "\n",
        "fig = plt.figure(figsize=(22,9))\n",
        "\n",
        "# original image\n",
        "original = io.imread(train_class_1_w_path[3])\n",
        "\n",
        "# resized image\n",
        "resized_img = cv.resize(train_img_class1[3], (120,120))\n",
        "\n",
        "# pull an original image as is\n",
        "ax = fig.add_subplot(2,5,1)\n",
        "ax.imshow(original)\n",
        "# ax.axis('off')\n",
        "ax.set_title('Original: 50 x 50', size=14)\n",
        "\n",
        "# resize an original image to 120 x 120\n",
        "ax = fig.add_subplot(2,5,2)\n",
        "ax.imshow(resized_img)                         \n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 1: Resize 120 x 120', size=14)\n",
        "\n",
        "# rotate an original image 90 degrees\n",
        "ax = fig.add_subplot(2,5,3)\n",
        "rot90_img = tf.image.rot90(resized_img, k=1)\n",
        "ax.imshow(rot90_img)\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 2: Rotate 90', size=14)\n",
        "\n",
        "# invert the resized image\n",
        "ax = fig.add_subplot(2,5,4)\n",
        "inverted_img = util.invert(resized_img)\n",
        "plt.imshow(inverted_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 3: Invert', size=14)\n",
        "\n",
        "# adjust brightness of the resized image\n",
        "ax = fig.add_subplot(2,5,5)\n",
        "bright_img = tf.image.adjust_brightness(resized_img, 0.3)\n",
        "plt.imshow(bright_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 4: Brightness', size=14)\n",
        "\n",
        "# adjust contrast of the brightened image\n",
        "ax = fig.add_subplot(2,5,6)\n",
        "contrast_img = tf.image.adjust_contrast(bright_img, contrast_factor=3)\n",
        "plt.imshow(contrast_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 5: Contrast', size=14)\n",
        "\n",
        "# flip left right of the contrasted image\n",
        "ax = fig.add_subplot(2,5,7)\n",
        "flipped_img = tf.image.flip_left_right(contrast_img)\n",
        "plt.imshow(flipped_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 6: Flip Left Right', size=14)\n",
        "\n",
        "# random noise: function to add random noise of various types to a floating-point image\n",
        "ax = fig.add_subplot(2,5,8)\n",
        "sigma = 0.355\n",
        "noisy_img = random_noise(resized_img, var=sigma**2)\n",
        "plt.imshow(noisy_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 7: Random Noise', size=14)\n",
        "\n",
        "# denoise_tv_chambolle: perform total-variation denoising on n-dimentional images\n",
        "ax = fig.add_subplot(2,5,9)\n",
        "dchambolle_img = denoise_tv_chambolle(resized_img, weight=0.1, multichannel=True)\n",
        "plt.imshow(dchambolle_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 8: Denoise TV Chambolle', size=14)\n",
        "\n",
        "# denoise_wavelet:  perform wavelet denoising on an image\n",
        "ax = fig.add_subplot(2,5,10)\n",
        "dwavelet_img = denoise_wavelet(resized_img, multichannel=True)\n",
        "plt.imshow(dwavelet_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 9: Denoise Wavelet', size=14);"
      ],
      "metadata": {
        "id": "7d4HILAgEFVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify image data (X) and labels (y)"
      ],
      "metadata": {
        "id": "dqbsZUPHEJ4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_X_and_y(data_pixels, df_data):\n",
        "  X = data_pixels\n",
        "  y = np.array(df_data['class']).flatten()   # no need to flatten here but maybe later on before I feed this to the model \n",
        "  return X, y"
      ],
      "metadata": {
        "id": "PKwcCotDDE9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = define_X_and_y(train_full_img, df_train_full)\n",
        "X_test, y_test = define_X_and_y(test_full_img, df_test_full)\n",
        "X_val, y_val = define_X_and_y(val_full_img, df_val_full)\n",
        "\n",
        "print('X_train: ', X_train.shape, type(X_train))\n",
        "print('X_test: ',X_test.shape, type(X_test))\n",
        "print('X_val: ',X_val.shape, type(X_val))"
      ],
      "metadata": {
        "id": "KGZ3ttrVT9_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomize images (X) and labels (y) \n"
      ],
      "metadata": {
        "id": "5tokO5_18Sxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train[0],'\\n')\n",
        "def shuffle_X_and_y(X, y):\n",
        "  tf.random.set_seed(1234)\n",
        "  np.random.seed(1234)\n",
        "  shuffle = np.random.permutation(np.arange(X_train.shape[0]))      # randomize \n",
        "  return X_train[shuffle], y_train[shuffle]"
      ],
      "metadata": {
        "id": "fCtWX0Q7_1w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = shuffle_X_and_y(X_train, y_train)\n",
        "X_test, y_test = shuffle_X_and_y(X_test, y_test)\n",
        "X_val, y_val = shuffle_X_and_y(X_val, y_val)\n",
        "\n",
        "print('y_val_shuffled:\\n', y_val)\n",
        "print('\\ny_test_shuffled:\\n', y_test)\n",
        "print('\\ny_train: total number of labels = ', len(y_train), type(y_train) ,'\\n', y_train[:5], y_train[-5:])\n",
        "print('\\nX_train: total number of images = ', len(X_train), type(X_train), '\\n', X_train[0])"
      ],
      "metadata": {
        "id": "Rt2UPJSOZkWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize images from (50, 50) to (80, 80) on X"
      ],
      "metadata": {
        "id": "itphNGmDas7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (80,80)\n",
        "X_train = tf.image.resize(X_train, size=image_size)\n",
        "X_test = tf.image.resize(X_test, size=image_size)\n",
        "X_val = tf.image.resize(X_val, size=image_size)\n",
        "print(type(X_train), X_train.shape)\n",
        "print('\\nX_train[0]:\\n',X_train[0])\n"
      ],
      "metadata": {
        "id": "1EDBNjh4arF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to gray scale and normalize images\n",
        "Rescale images to [0,1]"
      ],
      "metadata": {
        "id": "1AikiJ6fcYbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.image.rgb_to_grayscale(X_train)/255.0\n",
        "X_test = tf.image.rgb_to_grayscale(X_test)/255.0\n",
        "X_val = tf.image.rgb_to_grayscale(X_val)/255.0\n",
        "print(X_train.shape)\n",
        "# print(X_train[0])"
      ],
      "metadata": {
        "id": "aBfWdZqWasL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image augmentation on training images\n",
        "- Adjust brightness\n",
        "- Adjust contrast\n",
        "- Flip left and right\n",
        "- Rotate 90 degrees"
      ],
      "metadata": {
        "id": "sxpcYtSPiQnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brightness_delta = 0.3\n",
        "contrast_factor = 3\n",
        "rot_degree = 1               # rotate mapping => key:val = angle:k = {90:1, 180:2, 270:3}\n",
        "\n",
        "# add a set of augmented images to X_train_norm rather than overwrite the existing ones\n",
        "X_train_bright = tf.image.adjust_brightness(X_train, delta=brightness_delta)\n",
        "X_train_contrast = tf.image.adjust_contrast(X_train, contrast_factor=contrast_factor)\n",
        "X_train_flip = tf.image.random_flip_left_right(X_train)\n",
        "X_train_rot90 = tf.image.rot90(X_train, k=rot_degree)            \n",
        "# X_train_invert = util.invert(X_train)\n",
        "# X_train_noise = random_noise(X_train, var=0.355**2)   # sigma = 0.355\n",
        "# dchambolle_img = denoise_tv_chambolle(X_train, weight=0.1, multichannel=True)\n",
        "# X_train_dwavelet = denoise_wavelet(X_train, multichannel=True)"
      ],
      "metadata": {
        "id": "J9Aye3g5ar-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge original training images with the augmented images"
      ],
      "metadata": {
        "id": "e1m4AbsCCUnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate X_train_final with augmented X_train\n",
        "X_train = tf.concat([X_train, \n",
        "                    X_train_bright, \n",
        "                    X_train_contrast, \n",
        "                    X_train_flip,\n",
        "                    X_train_rot90], axis=0)\n",
        "print('X_train with augmentation: ', X_train.shape)\n",
        "\n",
        "# concatenate y_train (the label is preserved)\n",
        "y_train = y_train\n",
        "y_train_bright, y_train_contrast, y_train_flip, y_train_rot90 = y_train, y_train, y_train, y_train\n",
        "y_train = tf.concat([y_train, \n",
        "                    y_train_bright, \n",
        "                    y_train_contrast, \n",
        "                    y_train_flip,\n",
        "                    y_train_rot90], axis=0)\n",
        "print('y_train_bright: ', y_train_bright.shape)\n",
        "print('y_train with augmentation: ', y_train.shape)"
      ],
      "metadata": {
        "id": "SLYMuzo0CT7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffle X_train and y_train\n",
        "Shuffle two tensors in the same order"
      ],
      "metadata": {
        "id": "TkJCVacE5LZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.shape(X_train))\n",
        "shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
        "X_train = tf.gather(X_train, shuffle)\n",
        "y_train = tf.gather(y_train, shuffle).numpy()  # also transforms y_train to numpy array"
      ],
      "metadata": {
        "id": "VWx31lrkarjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0][1][1])\n",
        "print(y_train[:100])"
      ],
      "metadata": {
        "id": "d5HzmiT2ljeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display the first 10 train and validation examples with the label of each example as the title"
      ],
      "metadata": {
        "id": "Q9tSF_8q7rt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Print training data examples:')\n",
        "nrows, ncols = 1,5 \n",
        "f, axs = plt.subplots(nrows, ncols, figsize=(19,15))\n",
        "for i in range(ncols):\n",
        "    axs[i].imshow(array_to_img(X_train[i]))\n",
        "    axs[i].set(title=y_train[i])"
      ],
      "metadata": {
        "id": "y4H4Pbawli-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print validation data\n",
        "print('Print validation data examples:')\n",
        "nrows, ncols = 1,5 \n",
        "f, axs = plt.subplots(nrows, ncols, figsize=(19,15))\n",
        "for i in range(ncols):\n",
        "    axs[i].imshow(array_to_img(X_val[i]))\n",
        "    axs[i].set(title=y_val[i])"
      ],
      "metadata": {
        "id": "FBGKsVHC8yV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model using Tensorflow Keras API<br>\n",
        "1) Build model<br>\n",
        "2) Compile model<br>\n",
        "3) Fit model"
      ],
      "metadata": {
        "id": "HQrBgIc-IiYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (80,80,1)\n",
        "filters_1 = 32\n",
        "# filters_2 = 32\n",
        "# filters_3 = 64\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "strides = (1, 1)\n",
        "fully_connected_layer_units = 100\n",
        "dropout_rate = 0.3\n",
        "\n",
        "# 1)  Build model\n",
        "def build_model(activation='tanh',\n",
        "                optimizer='SGD',\n",
        "                learning_rate=0.01):\n",
        "  \n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.random.set_seed(0)\n",
        "\n",
        "  # Building the CNN\n",
        "  model = Sequential()      # initialize the model using Sequential(), which indicates our network will be stacked with different layers\n",
        "\n",
        "  # Define activation function\n",
        "  if activation.lower() == 'leakyrelu':\n",
        "    activation = tf.keras.layers.LeakyReLU(alpha=0.3)    # alpha = Float >= 0. Negative slope coefficient. Default to 0.3\n",
        "  \n",
        "  # Add the convolutional layers\n",
        "  model.add(Conv2D(filters=filters_1, kernel_size=kernel_size, activation=activation, padding='same', input_shape=input_shape))                  # 1st convolutional layer\n",
        "  model.add(MaxPooling2D(pool_size=pool_size, strides=strides))                                                                                 # 1st Pooling\n",
        "  # model.add(Conv2D(filters=filters_2, kernel_size=kernel_size, activation=activation, padding='same'))                                           # 2nd convolutional layer\n",
        "  # model.add(MaxPooling2D(pool_size=pool_size, strides=strides))                                                                                 # 2nd Pooling\n",
        "  # model.add(Conv2D(filters=filters_3, kernel_size=kernel_size, activation=activation, padding='same'))                                           # 3rd convolutional layer\n",
        "  # model.add(MaxPooling2D(pool_size=pool_size, strides=strides))                                                                                 # 3rd Pooling\n",
        "\n",
        "  # Flatten the dataset to feed into a fully connected layer\n",
        "  model.add(Flatten())    \n",
        "\n",
        "  # Fully connected layer\n",
        "  model.add(Dense(units=fully_connected_layer_units,                 # This can be adjusted (a hyper param)\n",
        "                  activation=activation))                            # For the first layer: the number of units or neurons\n",
        "\n",
        "  # Dropout layer\n",
        "  # model.add(Dropout(rate=dropout_rate))\n",
        "  \n",
        "  # Output layer\n",
        "  model.add(Dense(\n",
        "        units=1,                                 # binary output dimension (only one neuron)\n",
        "        # use_bias=True,                           # Alternative: use_bias=False\n",
        "        activation=None))                     # activation='sigmoid'\n",
        "\n",
        "  if optimizer.lower() == 'adam':\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "  elif optimizer.lower() == 'sgd':\n",
        "    optimizer = SGD(learning_rate=learning_rate)   \n",
        "\n",
        "# 2) Compile Model\n",
        "  model.compile(loss=BinaryCrossentropy(from_logits=True),             # for a binary classification\n",
        "                optimizer=optimizer,                    # used to change the attributes of a neural network such as weights and learning rate to reduce the losses.\n",
        "                metrics=['accuracy'])            \n",
        "  print(f'CNN Model:\\nActivation = {activation}\\nOptimizer = {optimizer}\\nlearning_rate = {learning_rate}\\n')\n",
        "  return model"
      ],
      "metadata": {
        "id": "sxT8brxoHqis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "activation='relu'\n",
        "optimizer='sgd'\n",
        "\n",
        "model = build_model(activation=activation,              # relu, leakyrelu, tanh, sigmoid\n",
        "                optimizer=optimizer,                    # adam, [SGD]        \n",
        "                learning_rate=learning_rate)        # 0.1, 0.01, 0.001\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "F1dNPPAEKyo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Fit Model"
      ],
      "metadata": {
        "id": "RqqEKDQxUTP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "\n",
        "print(f'Hyperparameters: \\\n",
        "      \\n\\ttraining_sample_size = {training_sample_size} \\\n",
        "      \\n\\tnum_epochs = {num_epochs} \\\n",
        "      \\n\\tbatch_size = {batch_size} \\\n",
        "      \\n\\timage_size = {image_size} \\\n",
        "      \\n\\tinput_shape = {input_shape} \\\n",
        "      \\n\\tfilters_1 = {filters_1} \\\n",
        "      \\n\\tfully_connected_layer_units = {fully_connected_layer_units} \\\n",
        "      \\n\\tkernel_size = {kernel_size} \\\n",
        "      \\n\\tpool_size = {pool_size} \\\n",
        "      \\n\\tstrides = {strides} \\\n",
        "      \\n\\tlearning_rate = {learning_rate} \\\n",
        "      \\n\\tactivation = {activation} \\\n",
        "      \\n\\toptimizer = {optimizer} \\\n",
        "      \\n\\nImage Agumentation Params: \\\n",
        "      \\n\\tbrightness_delta = {brightness_delta} \\\n",
        "      \\n\\tcontrast_factor = {contrast_factor} \\\n",
        "      \\n\\trot_degree = {rot_degree}\\n')\n",
        "\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "m5wx4yDED2AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot loss and accuracy for training and validation sets"
      ],
      "metadata": {
        "id": "TJjErwA0KHyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = history.history\n",
        "x_arr = np.arange(len(hist['loss'])) + 1\n",
        "# print(x_arr)\n",
        "\n",
        "fig = plt.figure(figsize=(16,6))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.plot(x_arr, hist['loss'], '-o', label='Train Loss')\n",
        "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation Loss')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Loss', size=14)\n",
        "ax.set_title('Loss', size=20)\n",
        "\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.plot(x_arr, hist['accuracy'], '-o', label='Train Acc.')\n",
        "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation Acc.')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Accuracy', size=14)\n",
        "ax.set_title('Accuracy', size=20);"
      ],
      "metadata": {
        "id": "KddTvpgPKG8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "EZFVmfn-kn7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {eval_test[1]*100:.2f}%\\n')\n",
        "\n",
        "eval_train = model.evaluate(X_train, y_train)\n",
        "print(f'Train Accuracy: {eval_train[1]*100:.2f}%')"
      ],
      "metadata": {
        "id": "t0SiQn-0kmrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Prediction"
      ],
      "metadata": {
        "id": "SDRX8Oy9AGCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {eval_test[1]*100:.2f}%\\n')\n",
        "\n",
        "eval_train = model.evaluate(X_train, y_train)\n",
        "print(f'Train Accuracy: {eval_train[1]*100:.2f}%')\n",
        "\n",
        "# Transform logits to probabilities\n",
        "pred_logits = model.predict(X_test)\n",
        "probabilities = tf.sigmoid(pred_logits)\n",
        "probabilities = probabilities.numpy().flatten()*100\n",
        "# print(probabilities)"
      ],
      "metadata": {
        "id": "myoOFoqaAI50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Test vs. Predicted"
      ],
      "metadata": {
        "id": "rPP6CK90BQE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,25))\n",
        "\n",
        "for j, example in enumerate(X_test[:20]):\n",
        "    ax = fig.add_subplot(8,4, j+1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.imshow(array_to_img(example))\n",
        "    if y_test[j]==0:\n",
        "        label='Non-IDC'\n",
        "    else:\n",
        "        label='IDC'\n",
        "    \n",
        "    ax.text(\n",
        "        0.5, -0.15, \n",
        "        'True Label: {:s}\\nPr(IDC)={:.0f}%'.format(label, probabilities[j]), \n",
        "        size=14, \n",
        "        color='grey',\n",
        "        horizontalalignment='center',\n",
        "        verticalalignment='center', \n",
        "        transform=ax.transAxes)\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k4YsAskUBPFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=False,\n",
        "    show_layer_activations=True,\n",
        ")"
      ],
      "metadata": {
        "id": "8U10Myhjtoco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Prediction the most common area that may be detected IDC using patch locations\n",
        "\n"
      ],
      "metadata": {
        "id": "GUKNtN_358aK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features from file names"
      ],
      "metadata": {
        "id": "coT9K_SwVjSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_features(file_list): \n",
        "#   features = []\n",
        "#   for file in file_list:\n",
        "#     str_feat = re.findall(r'\\d+', file)\n",
        "#     int_feat = [int(feat) for feat in str_feat]\n",
        "#     features.append(int_feat)\n",
        "#   df_feat = pd.DataFrame(features, columns=['patient_id', 'd', 'x_coord', 'y_coord', 'class']).drop('d', axis=1)\n",
        "#   df_feat['patch_coord'] = list(zip(df_feat.x_coord, df_feat.y_coord))\n",
        "#   return df_feat[['patient_id','x_coord', 'y_coord', 'patch_coord','class']]\n",
        "\n",
        "\n",
        "# df_features = extract_features(full_data_wo_path)\n",
        "# print(df_features.shape)\n",
        "# display(df_features.head().append(df_features.tail()))"
      ],
      "metadata": {
        "id": "NWcorv_BtX5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_features.info()"
      ],
      "metadata": {
        "id": "DWDHLh8_CXIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomize data \n",
        ": As we may use SGD for training, we will randomize sample of the data for each batch so that the gradient computed is representative."
      ],
      "metadata": {
        "id": "_jaH_54ZzvcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# indexes = np.arange(df_features.shape[0])\n",
        "# print('indexes:', indexes)\n",
        "\n",
        "# np.random.seed(0)    # get the same results each time    ??????\n",
        "# shuffled_indexes = np.random.permutation(indexes)\n",
        "# print('shuffled indexes:', shuffled_indexes, '\\n')\n",
        "\n",
        "# # change the ordering of the original df_features using .reindex()\n",
        "# df_features = df_features.reindex(shuffled_indexes)\n",
        "# display(df_features)"
      ],
      "metadata": {
        "id": "XLxz9aqOdY5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test split (80/20) & Feature Selection"
      ],
      "metadata": {
        "id": "LqVR7YRO5smx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split_boundary = int(df_features.shape[0]*.8)\n",
        "\n",
        "# train = pd.DataFrame(df_features.iloc[:split_boundary, 3:])\n",
        "# test = pd.DataFrame(df_features.iloc[split_boundary:, 3:])\n",
        "\n",
        "# print('Train Shape: ', train.shape, '\\n', train.head(3))\n",
        "# print('\\nTest Shape: ', test.shape, '\\n', test.head(3))"
      ],
      "metadata": {
        "id": "L4s4IiY1-XGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAtuZaJuFyXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}