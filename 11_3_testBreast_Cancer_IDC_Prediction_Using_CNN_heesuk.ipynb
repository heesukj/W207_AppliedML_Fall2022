{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/W207_AppliedML_Fall2022/blob/main/11_3_testBreast_Cancer_IDC_Prediction_Using_CNN_heesuk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FALL 2022<br>\n",
        "W207 Applied Machine Learning<br>\n",
        "Heesuk Jang\n",
        " \n",
        "\n",
        "#Predicting IDC with Breast Histopathology Images using CNN\n",
        "\n"
      ],
      "metadata": {
        "id": "5DebDWCL0KeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SRkZHKoWswZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f979437-6d91-43ee-a207-cddf28e18366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import *                            # confusion_matrix, log_loss, accuracy_score\n",
        "from sklearn.model_selection import *                    # train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import *\n",
        "# from sklearn.ensemble import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.linear_model import *                       # LinearRegression\n",
        "from sklearn.discriminant_analysis import *\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import metrics\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import RandomFlip, RandomZoom, RandomRotation, Conv2D, MaxPooling2D, AveragePooling2D, Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "tf.get_logger().setLevel('INFO')\n",
        "\n",
        "import cv2 as cv\n",
        "import skimage.io as io\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN - ML pipeline\n",
        "\n",
        "  1) EDA and Image Visualization<br>\n",
        "  2) Randomly sample from training/test/validation = 800/ 200/ 200 (66%/ 17%/ 17%)<br>\n",
        "  3) Image Transformations<br>\n",
        "> Image resize<br>\n",
        "> Image normalization to [0, 1]<br>\n",
        "  \n",
        "  4) [Image Augmentations](https://iq.opengenus.org/data-augmentation/)<br>\n",
        "> Adjust brightness<br>\n",
        "> Adjust contrast<br>\n",
        "> Flip left and right<br>\n",
        "> Rotate 90 degrees<br>\n",
        "\n",
        " 5) CNN Model using Tensorflow Keras API<br>\n",
        "> Build model<br>\n",
        "> Compile model<br>\n",
        "> Fit model<br>\n",
        "\n",
        " 6) Evaluate the Model<br>\n",
        " : Determine how good our trained model applies in predicting unseen (test) data.\n",
        "> model.**evaluate**<br>\n",
        "> model.**predict**<br>\n",
        "> Evaluation Metrics:  True Labels VS. Predicted Labels<br>\n",
        "\n",
        " 7) Hyper Parameter Tuning<br>\n",
        "> Optimizer<br>\n",
        "> Learning Rate<br>\n",
        "> Dropout ratio<br>\n",
        "> Number of Epochs<br>\n",
        "> Contrast Factor<br>\n",
        "> Delta<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oslfl6Ot7RYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b1CFw-aOtGQm",
        "outputId": "d145395a-e363-4770-bb5b-f1c0618ccc55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip gdrive/MyDrive/Kaggle/CNN_IDC/Dataset.zip\n",
        "\n",
        "#replace these paths with the paths of your \n",
        "val_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Validate'\n",
        "train_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train'\n",
        "test_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Test'\n",
        "directory_path = '/content/gdrive/MyDrive/Kaggle/CNN_IDC'"
      ],
      "metadata": {
        "id": "uyWJuOkZuCVl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paths(directory):\n",
        "  all_path = []\n",
        "  idc_image_path = []\n",
        "  idc_image_label = []\n",
        "\n",
        "  for dir, subdir, files in os.walk(directory):\n",
        "    path = dir + \"/\"\n",
        "    all_path.append(path)\n",
        "\n",
        "  for i in range(len(all_path)):\n",
        "    for file in os.listdir(all_path[i]):\n",
        "      test = file\n",
        "      path = all_path[i] + test\n",
        "      if path.lower().endswith('.png'):\n",
        "        idc_image_path.append(path)\n",
        "\n",
        "  for i in range(len(idc_image_path)):\n",
        "    split_test = idc_image_path[i]\n",
        "    split_path = split_test.split(\"/\")\n",
        "    directory_name = split_path[7]\n",
        "    idc_image_label.append('class_' + split_path[8])\n",
        "    # idc_image_label.append(str(split_path[8]))\n",
        "  return idc_image_path, idc_image_label, directory_name"
      ],
      "metadata": {
        "id": "N892xh1IM4q7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, train_labels, train_dir = get_paths(train_image_directory)\n",
        "val_paths, val_labels, val_dir = get_paths(val_image_directory)\n",
        "test_paths, test_labels, test_dir = get_paths(test_image_directory)"
      ],
      "metadata": {
        "id": "SJ6Cl4wtmxjO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[:5])\n",
        "print(train_labels[-5:])\n",
        "\n",
        "print(len(train_paths), len(train_labels))\n",
        "print(len(test_paths), len(test_labels))\n",
        "print(len(val_paths), len(val_labels))"
      ],
      "metadata": {
        "id": "NIf9ETAsmxa2",
        "outputId": "a315a4c1-3baf-4233-c47b-ea89fb1577a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['class_0', 'class_0', 'class_0', 'class_0', 'class_0']\n",
            "['class_1', 'class_1', 'class_1', 'class_1', 'class_1']\n",
            "800 800\n",
            "200 200\n",
            "200 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_paths[:2])\n",
        "print(train_labels[:10])\n",
        "print(train_dir)"
      ],
      "metadata": {
        "id": "uCJzEwS8mxSR",
        "outputId": "c231ccfe-7bae-4f44-fb44-f70439e88393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/12880_idx5_x451_y701_class0.png', '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train/0/9345_idx5_x2001_y2001_class0.png']\n",
            "['class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0', 'class_0']\n",
            "Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframes(idc_image_path, idc_image_label, directory_name):\n",
        "  same_name = directory_name.lower() + '_'\n",
        "  #creating the dataframes that we will be passing to our generators\n",
        "  idc_data_cleaned = {'path': idc_image_path,\n",
        "            'label': idc_image_label}\n",
        "  idc_df = pd.DataFrame(idc_data_cleaned)\n",
        "  df = idc_df.sample(frac = 1)\n",
        "  print(df)\n",
        "  csv_path = directory_path\n",
        "  csv_file = df.to_csv(csv_path + '/' + same_name + 'idc_dataframe.csv')\n",
        "  csv_file_path = csv_path + '/' + same_name + 'idc_dataframe.csv'\n",
        "  return csv_file_path"
      ],
      "metadata": {
        "id": "_WU9qt2RmxHZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "print('type(train_dataframe): ',type(train_dataframe))\n",
        "train_dataframe"
      ],
      "metadata": {
        "id": "MJxUgm39NeU7",
        "outputId": "8e0dd625-1648-4343-8026-99280a1c3d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  path    label\n",
            "227  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "193  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "169  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "567  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "398  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "..                                                 ...      ...\n",
            "358  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "94   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "31   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "751  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "560  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "\n",
            "[800 rows x 2 columns]\n",
            "type(train_dataframe):  <class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Kaggle/CNN_IDC/train_idc_dataframe.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "train_generator = pd.read_csv(train_dataframe)\n",
        "\n",
        "test_dataframe = create_dataframes(test_paths, test_labels, test_dir)\n",
        "test_generator = pd.read_csv(test_dataframe)\n",
        "\n",
        "val_dataframe = create_dataframes(val_paths, val_labels, val_dir)\n",
        "val_generator = pd.read_csv(val_dataframe)"
      ],
      "metadata": {
        "id": "hnDu_3N4mw1G",
        "outputId": "b49c7b0f-49bc-4692-eb15-a15b6052652a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  path    label\n",
            "260  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "614  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "655  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "264  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "797  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "..                                                 ...      ...\n",
            "426  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "47   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "65   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "776  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "744  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "\n",
            "[800 rows x 2 columns]\n",
            "                                                  path    label\n",
            "75   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "33   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "78   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "48   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "45   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "..                                                 ...      ...\n",
            "126  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "139  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "98   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "130  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "15   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "\n",
            "[200 rows x 2 columns]\n",
            "                                                  path    label\n",
            "7    /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "25   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "198  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "174  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "29   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "..                                                 ...      ...\n",
            "121  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "144  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "155  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "197  /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_1\n",
            "51   /content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset...  class_0\n",
            "\n",
            "[200 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator"
      ],
      "metadata": {
        "id": "YyKDuRpXPXIn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://faroit.com/keras-docs/0.3.3/preprocessing/image/\n",
        "# data_generator = ImageDataGenerator(\n",
        "#     featurewise_center = True,\n",
        "#     featurewise_std_normalization = True,\n",
        "#     #these are the augmentation features that you can adjust\n",
        "#     # link to read more about them https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "#     zca_whitening=False,\n",
        "#     zca_epsilon=1e-06,\n",
        "#     rotation_range=0,\n",
        "#     width_shift_range=0.0,\n",
        "#     height_shift_range=0.0,\n",
        "#     brightness_range=None,\n",
        "#     shear_range=0.0,\n",
        "#     zoom_range=0.0,\n",
        "#     channel_shift_range=0.0,\n",
        "#     fill_mode='nearest',\n",
        "#     cval=0.0,\n",
        "#     horizontal_flip=False,\n",
        "#     vertical_flip=False,\n",
        "#     rescale=None,\n",
        "# )\n",
        "\n",
        "data_generator = ImageDataGenerator()\n",
        "\n",
        "train_data_generator = data_generator.flow_from_dataframe(\n",
        "    train_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,                     # transforms the images to 0 mean\n",
        "    featurewise_std_normalization = True,          # divide inputs by std of the dataset\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        "    # seed=1234\n",
        "    # validate_filenames=True\n",
        ")\n",
        "\n",
        "validation_data_generator = data_generator.flow_from_dataframe(\n",
        "    val_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        "    # seed=1234\n",
        "    # validate_filenames=True\n",
        ")\n",
        "\n",
        "test_data_generator = data_generator.flow_from_dataframe(\n",
        "    test_generator,\n",
        "    directory = None,\n",
        "    x_col =  'path',\n",
        "    y_col =  'label',\n",
        "    weight_col=None,\n",
        "    featurewise_center = True,\n",
        "    featurewise_std_normalization = True,\n",
        "    #readjust the target size based on max size of images\n",
        "    target_size=(50, 50),\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=False              # Kesha set to shuffle=True\n",
        "    # seed=1234\n",
        "    # validate_filenames=True\n",
        ")"
      ],
      "metadata": {
        "id": "eC0S3je4Jnwb",
        "outputId": "a570f47e-ee17-46b2-ed4c-f15aaef24483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 50\n",
        "img_width = 50\n",
        "img_channel = 1"
      ],
      "metadata": {
        "id": "OQcHdDdYJnol"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_doc_id_model():\n",
        "  return tf.keras.Sequential([\n",
        "                           keras.layers.Conv2D(input_shape = (img_height, img_width, img_channel), \n",
        "                                               filters=32, \n",
        "                                               kernel_size=(3, 3),\n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                           \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                                  strides=(2, 2)),\n",
        "                           \n",
        "                           keras.layers.Conv2D(filters=64, \n",
        "                                               kernel_size=(3, 3), \n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                              \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
        "                                                  strides=(2, 2)),\n",
        "                          \n",
        "                           keras.layers.Conv2D(filters=128, \n",
        "                                               kernel_size=(3, 3), \n",
        "                                               padding='same', \n",
        "                                               activation='relu'),\n",
        "                          \n",
        "                           keras.layers.MaxPooling2D(pool_size=(2, 2), \n",
        "                                                  strides=(2, 2)),\n",
        "                           \n",
        "                           keras.layers.Flatten(),\n",
        "                           \n",
        "                           keras.layers.Dense(units = 256, \n",
        "                                              activation = 'relu'),\n",
        "                           \n",
        "                          #  keras.layers.Dense(units = 512, \n",
        "                          #                     activation = 'relu'),\n",
        "                           \n",
        "                           keras.layers.Dense(units = 2, \n",
        "                                              activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "-aJNqzI4JngT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "model = get_doc_id_model()\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001), \n",
        "                    loss=keras.losses.categorical_crossentropy, \n",
        "                    metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "8FPJqXiDJnZC",
        "outputId": "75dcb242-c110-4067-d7ca-21ec9a7b5ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 50, 50, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 25, 25, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1179904   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,273,090\n",
            "Trainable params: 1,273,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.callbacks.EarlyStopping => Stop training when a monitored metric has stopped improving.\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# This callback will stop the training when there is no improvement in the val_acc for 6 consecutive epochs\n",
        "val_acc_early_stopping = EarlyStopping(monitor = 'val_acc', \n",
        "                                       patience = 6,        # Number of epochs with no improvement after which training will be stopped.\n",
        "                                       verbose = 1,         # 1: displays messages when the callback takes an action\n",
        "                                       mode = 'auto')"
      ],
      "metadata": {
        "id": "TCHVLIBUJnQ8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data_generator,\n",
        "                 epochs=7,\n",
        "                #  callbacks=[val_acc_early_stopping],\n",
        "                 validation_data = validation_data_generator\n",
        "                 )\n",
        "# len(history.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "1aK-mML9JnID",
        "outputId": "76992ba7-cb66-41eb-aa4f-85add5bb6dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "25/25 [==============================] - 11s 402ms/step - loss: 10.9381 - accuracy: 0.5175 - val_loss: 0.6497 - val_accuracy: 0.6350\n",
            "Epoch 2/7\n",
            "25/25 [==============================] - 12s 481ms/step - loss: 0.6529 - accuracy: 0.6012 - val_loss: 0.6330 - val_accuracy: 0.6500\n",
            "Epoch 3/7\n",
            "25/25 [==============================] - 7s 288ms/step - loss: 0.5732 - accuracy: 0.7013 - val_loss: 0.6807 - val_accuracy: 0.5850\n",
            "Epoch 4/7\n",
            "25/25 [==============================] - 6s 226ms/step - loss: 0.5512 - accuracy: 0.7138 - val_loss: 0.5715 - val_accuracy: 0.7050\n",
            "Epoch 5/7\n",
            "25/25 [==============================] - 6s 227ms/step - loss: 0.5210 - accuracy: 0.7300 - val_loss: 0.6364 - val_accuracy: 0.6350\n",
            "Epoch 6/7\n",
            "25/25 [==============================] - 6s 229ms/step - loss: 0.5042 - accuracy: 0.7462 - val_loss: 0.5782 - val_accuracy: 0.7200\n",
            "Epoch 7/7\n",
            "25/25 [==============================] - 6s 229ms/step - loss: 0.4904 - accuracy: 0.7625 - val_loss: 0.5977 - val_accuracy: 0.7250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = history.history\n",
        "x_arr = np.arange(len(hist['loss'])) + 1\n",
        "# print(x_arr)\n",
        "\n",
        "fig = plt.figure(figsize=(16,6))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.plot(x_arr, hist['loss'], '-o', label='Train Loss')\n",
        "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation Loss')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Loss', size=14)\n",
        "ax.set_title('Loss', size=20)\n",
        "\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.plot(x_arr, hist['accuracy'], '-o', label='Train Acc.')\n",
        "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation Acc.')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Accuracy', size=14)\n",
        "ax.set_title('Accuracy', size=20);"
      ],
      "metadata": {
        "id": "v1a4RY1gK5kg",
        "outputId": "f712a04f-6961-4d0e-aac6-f469d72841dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_train = model.evaluate(train_data_generator)\n",
        "print(f'Train Accuracy: {eval_train[1]*100:.2f}%')\n",
        "print()\n",
        "eval_test = model.evaluate(test_data_generator)\n",
        "print(f'Test Accuracy: {eval_test[1]*100:.2f}%\\n')"
      ],
      "metadata": {
        "id": "YEAMNOELK5bA",
        "outputId": "5c1c7f9b-33f7-4927-e01a-e2f4b570bc80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 2s 87ms/step - loss: 0.4891 - accuracy: 0.7550\n",
            "Train Accuracy: 75.50%\n",
            "\n",
            "7/7 [==============================] - 60s 10s/step - loss: 0.5529 - accuracy: 0.7050\n",
            "Test Accuracy: 70.50%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = test_data_generator.classes\n",
        "y_pred = (model.predict(test_data_generator) > 0.5).astype('int32')\n",
        "# y_pred"
      ],
      "metadata": {
        "id": "kJPHLF45bvjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8318b0fb-3475-42bc-c26f-1515b746211d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 73ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "conf_max = confusion_matrix(y_true, y_pred)\n",
        "# sns.heatmap(conf_max, annot=True, fmt='d')\n",
        "\n",
        "# plt.xlable('pred label')\n",
        "# plt.ylabel('true label')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "XQNddxDYb8v7",
        "outputId": "ca745e88-dd72-4e42-9f49-698da4141a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3b89b84dd28c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconf_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# sns.heatmap(conf_max, annot=True, fmt='d')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data_generator"
      ],
      "metadata": {
        "id": "GARos0NOaqpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Transform logits to probabilities\n",
        "pred_logits = model.predict(test_data_generator)\n",
        "probabilities = tf.sigmoid(pred_logits)\n",
        "probabilities = probabilities.numpy().flatten()*100\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "Fg8mGcfKK5Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize=(16,25))\n",
        "\n",
        "# for j, example in enumerate(test_data_generator[:20]):\n",
        "#     ax = fig.add_subplot(8,4, j+1)\n",
        "#     ax.set_xticks([])\n",
        "#     ax.set_yticks([])\n",
        "#     ax.imshow(array_to_img(example))\n",
        "#     if y_test[j]==0:\n",
        "#         label='Non-IDC'\n",
        "#     else:\n",
        "#         label='IDC'\n",
        "    \n",
        "#     ax.text(\n",
        "#         0.5, -0.15, \n",
        "#         'True Label: {:s}\\nPr(IDC)={:.0f}%'.format(label, probabilities[j]), \n",
        "#         size=14, \n",
        "#         color='grey',\n",
        "#         horizontalalignment='center',\n",
        "#         verticalalignment='center', \n",
        "#         transform=ax.transAxes)\n",
        "    \n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "iydlEDpFK5GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiMC7RfGJm4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read training/test/validation images \n"
      ],
      "metadata": {
        "id": "SYpLshTCwEci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_images(binary_class, folder):\n",
        "  current_working_dir = os.getcwd()\n",
        "  image_files_w_path, image_files_wo_path = [], []\n",
        "  for img in glob.glob(os.path.join(current_working_dir, folder + binary_class + '/') + '*.png'):\n",
        "    image_files_w_path.append(img)\n",
        "    image_wo_path = os.path.basename(img)\n",
        "    image_files_wo_path.append(image_wo_path) \n",
        "  # if folder == 'Dataset/Train/':\n",
        "  #   image_files_wo_path, image_files_w_path = image_files_wo_path[:200], image_files_w_path[:200]\n",
        "  return image_files_wo_path, image_files_w_path    "
      ],
      "metadata": {
        "id": "oEVGLHwn-k-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Read Training Images ============================= #\n",
        "# ======================================================================== #\n",
        "\n",
        "train_class_1_wo_path, train_class_1_w_path = read_images('1', 'Dataset/Train/')\n",
        "train_class_0_wo_path, train_class_0_w_path = read_images('0', 'Dataset/Train/')\n",
        "train_full_wo_path = train_class_1_wo_path + train_class_0_wo_path\n",
        "train_full_w_path = train_class_1_w_path + train_class_0_w_path\n",
        "\n",
        "print(f'Size of Train Class 1 = {len(train_class_1_wo_path)} | {type(train_class_1_wo_path)}\\nSample Images in Train Class 1:\\n {train_class_1_wo_path[:2]}')\n",
        "print(f'\\nxSize of Train Class 0 = {len(train_class_0_wo_path)} | {type(train_class_0_wo_path)}\\nSample Images in Train Class 0:\\n {train_class_0_wo_path[:2]}')\n",
        "print('\\nTrain class_1 and class_0 combined:\\n',train_full_wo_path[0], ',', train_full_wo_path[-1])\n",
        "print('\\nTrain class_1 with full path:\\n',train_class_1_w_path[:2])"
      ],
      "metadata": {
        "id": "HzYSVtoT8yr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Read Test Images ================================= #\n",
        "# ======================================================================== #\n",
        "\n",
        "test_class_1_wo_path, test_class_1_w_path = read_images('1', 'Dataset/Test/')\n",
        "test_class_0_wo_path, test_class_0_w_path = read_images('0', 'Dataset/Test/')\n",
        "test_full_wo_path = test_class_1_wo_path + test_class_0_wo_path\n",
        "test_full_w_path = test_class_1_w_path + test_class_0_w_path\n",
        "\n",
        "print(f'Size of Test Class 1 = {len(test_class_1_wo_path)} | {type(test_class_1_wo_path)}\\nSample Images in Test Class 1:\\n {test_class_1_wo_path[:2]}')\n",
        "print(f'\\nSize of Test Class 0 = {len(test_class_0_wo_path)} | {type(test_class_0_wo_path)}\\nSample Images in Test Class 0:\\n {test_class_0_wo_path[:2]}')\n",
        "print('\\nTest class_1 and class_0 combined:\\n',test_full_wo_path[0], ',', test_full_wo_path[-1])\n",
        "print('\\nTest class_1 with full path:\\n',test_class_1_wo_path[:2])"
      ],
      "metadata": {
        "id": "UtVObov-4P86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Read Validation Images =========================== #\n",
        "# ======================================================================== #\n",
        "\n",
        "val_class_1_wo_path, val_class_1_w_path = read_images('1', 'Dataset/Validate/')\n",
        "val_class_0_wo_path, val_class_0_w_path = read_images('0', 'Dataset/Validate/')\n",
        "val_full_wo_path = val_class_1_wo_path + val_class_0_wo_path\n",
        "val_full_w_path = val_class_1_w_path + val_class_0_w_path\n",
        "\n",
        "print(f'Size of Validation Class 1 = {len(val_class_1_wo_path)} | {type(val_class_1_wo_path)}\\nSample Images in Validation Class 1:\\n {val_class_1_wo_path[:2]}')\n",
        "print(f'\\nSize of Validation Class 0 = {len(val_class_0_wo_path)} | {type(val_class_0_wo_path)}\\nSample Images in Validation Class 0:\\n {val_class_0_wo_path[:2]}')\n",
        "print('\\nValidation class_1 and class_0 combined:\\n',val_full_wo_path[0], ',', val_full_wo_path[-1])\n",
        "print('\\nValidation class_1 with full path:\\n',val_class_1_wo_path[:2])"
      ],
      "metadata": {
        "id": "3hM8u4SI4tiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the number of train images in each class\n"
      ],
      "metadata": {
        "id": "2Tm1-FAi0Ivz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_class_size(class_1, class_0):\n",
        "  class_1_size, class_0_size = len(class_1), len(class_0)\n",
        "  count = pd.Series([class_1_size, class_0_size])\n",
        "  percent = round(count/(class_1_size + class_0_size)*100, 2)\n",
        "  df_perc = pd.concat({'class_count':count, 'class_percent(%)':percent}, axis=1)\n",
        "  df_perc['class'] = ['Class 1 (Malignant)', 'Class 0 (Benign)']\n",
        "  df_perc = df_perc[['class','class_count','class_percent(%)']]\n",
        "  print('Total Count (Balanced) = ', class_1_size + class_0_size)\n",
        "  return df_perc\n",
        "\n",
        "check_class_size(train_class_1_wo_path, train_class_0_wo_path)"
      ],
      "metadata": {
        "id": "EcPA8klvyBaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataframes of training/test/validation for each class"
      ],
      "metadata": {
        "id": "0xsLnUUBmfCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_class_df(class_1_w_path, class_0_w_path): \n",
        "  image_list_w_path = [x for x in class_1_w_path]\n",
        "  image_list_w_path.extend([x for x in class_0_w_path])\n",
        "  df_idc= pd.DataFrame(np.concatenate([['IDC']*len(class_1_w_path), ['Non_IDC']*len(class_0_w_path)]), columns=['class_str'])\n",
        "  df_idc['class'] = np.where(df_idc.class_str == 'IDC', 1, 0)\n",
        "  df_idc['image'] = [x for x in image_list_w_path]\n",
        "  print('Shape: ', df_idc.shape)\n",
        "  return df_idc"
      ],
      "metadata": {
        "id": "8EbfD5bymcWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Create Train DF ================================== #\n",
        "# ======================================================================== #\n",
        "df_train_full = create_class_df(train_class_1_w_path, train_class_0_w_path)\n",
        "training_sample_size = df_train_full.shape[0]\n",
        "df_train_full"
      ],
      "metadata": {
        "id": "MwPd_r3N9L5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Create Test DF ================================== #\n",
        "# ======================================================================== #\n",
        "df_test_full = create_class_df(test_class_1_w_path, test_class_0_w_path)\n",
        "df_test_full"
      ],
      "metadata": {
        "id": "7ZW6YphC9pjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Create Validation DF ============================= #\n",
        "# ======================================================================== #\n",
        "df_val_full = create_class_df(val_class_1_w_path, val_class_0_w_path)\n",
        "df_val_full"
      ],
      "metadata": {
        "id": "jxKruoce9puO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image distribution in the training data set"
      ],
      "metadata": {
        "id": "Ea7hjtdQ967V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "ax = sns.countplot(df_train_full['class_str'], data=df_train_full)\n",
        "plt.xlabel('Class', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.title('Number of Cases', fontsize=18)\n",
        "plt.ylim(0,450)\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "               (p.get_x() + p.get_width()/2., \n",
        "                p.get_height()), ha='center', va='center', size=15, xytext=(0,9),\n",
        "               textcoords = 'offset points', fontsize=13)"
      ],
      "metadata": {
        "id": "fzBCqbbspPsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display 6 train images for each class\n"
      ],
      "metadata": {
        "id": "8b3Am88FHQVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(subclass, class_name):\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(17,6))\n",
        "  # images = []\n",
        "  for idx, ax in enumerate(axes.flat):\n",
        "    img = io.imread(subclass[idx])\n",
        "    img = cv.resize(img, (224,224))    # resize an image from 50 by 50 to 512 by 512\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(class_name)\n",
        "    ax.set_xticks([])       # remove xticks passing an empty array\n",
        "    ax.set_yticks([])       # remove yticks passing an empty array\n",
        "  fig.tight_layout() \n",
        "  plt.show() \n",
        "\n",
        "display_images(train_class_1_w_path, 'Class 1: IDC')\n",
        "display_images(train_class_0_w_path, 'Class 0: Non-IDC')"
      ],
      "metadata": {
        "id": "xGK7hj3rNwPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Invasive ductal carcinoma (IDC) of the breast](https://www.mypathologyreport.ca/breast-invasive-ductal-carcinoma/)"
      ],
      "metadata": {
        "id": "tIBcckEAm-vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(cv.resize(io.imread('9383_idx5_x1951_y951_class1.png'), (80,80)))"
      ],
      "metadata": {
        "id": "WGcct9bEm99R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store actual color images as a vector\n"
      ],
      "metadata": {
        "id": "FOBIuMqY1n9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from skimage import color\n",
        "def store_actual_images_to_grayscale(class_1_w_path, class_0_w_path):\n",
        "  # read and store actual images (not the image paths) into the respective variable as a single vector then pass these to the model below\n",
        "  image_pixels_class1 = [io.imread(img) for img in class_1_w_path]\n",
        "  image_pixels_class0 = [io.imread(img) for img in class_0_w_path]\n",
        "  full_image_pixels = np.asarray(image_pixels_class1 + image_pixels_class1)   # => (#samples, width, height)\n",
        "  return image_pixels_class1, image_pixels_class0, full_image_pixels"
      ],
      "metadata": {
        "id": "bgERy51o1xuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Store Train Images =============================== #\n",
        "# ======================================================================== #\n",
        "train_img_class1, train_img_class0, train_full_img = store_actual_images_to_grayscale(train_class_1_w_path, train_class_0_w_path)\n",
        "\n",
        "print('Shape of each train image: ', train_img_class1[0].shape)\n",
        "print('\\nTotal number of images = ', len(train_full_img))\n",
        "print('Number of class 1 images = ', len(train_img_class1))\n",
        "print('Number of class 0 images = ', len(train_img_class0))\n",
        "print('train_full_img = ', train_full_img.shape)"
      ],
      "metadata": {
        "id": "0LwOFDh5-jnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Store Test Images ================================ #\n",
        "# ======================================================================== #\n",
        "test_img_class1, test_img_class0, test_full_img = store_actual_images_to_grayscale(test_class_1_w_path, test_class_0_w_path)\n",
        "\n",
        "print('Shape of each test image: ', test_img_class1[0].shape)\n",
        "print('\\nTotal number of images = ', len(test_full_img))\n",
        "print('Number of class 1 images = ', len(test_img_class1))\n",
        "print('Number of class 0 images = ', len(test_img_class0))\n",
        "print('test_full_img = ', test_full_img.shape)"
      ],
      "metadata": {
        "id": "KxXP8HZD_LdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================== #\n",
        "# ===================== Store Validation Images ========================== #\n",
        "# ======================================================================== #\n",
        "val_img_class1, val_img_class0, val_full_img = store_actual_images_to_grayscale(val_class_1_w_path, val_class_0_w_path)\n",
        "\n",
        "print('Shape of each validataion image: ', val_img_class1[0].shape)\n",
        "print('\\nTotal number of images = ', len(val_full_img))\n",
        "print('Number of class 1 images = ', len(val_img_class1))\n",
        "print('Number of class 0 images = ', len(val_img_class0))\n",
        "print('val_full_img = ', val_full_img.shape)"
      ],
      "metadata": {
        "id": "tOXd6Kb0_Ll6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image augmentation techniques on a training image"
      ],
      "metadata": {
        "id": "FsBDt4AnKGx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage import util\n",
        "from skimage.util import random_noise\n",
        "from skimage.restoration import denoise_tv_chambolle, denoise_bilateral, denoise_wavelet, estimate_sigma\n",
        "\n",
        "fig = plt.figure(figsize=(22,9))\n",
        "\n",
        "# original image\n",
        "original = io.imread(train_class_1_w_path[3])\n",
        "\n",
        "# resized image\n",
        "resized_img = cv.resize(train_img_class1[3], (120,120))\n",
        "\n",
        "# pull an original image as is\n",
        "ax = fig.add_subplot(2,5,1)\n",
        "ax.imshow(original)\n",
        "# ax.axis('off')\n",
        "ax.set_title('Original: 50 x 50', size=14)\n",
        "\n",
        "# resize an original image to 120 x 120\n",
        "ax = fig.add_subplot(2,5,2)\n",
        "ax.imshow(resized_img)                         \n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 1: Resize 120 x 120', size=14)\n",
        "\n",
        "# rotate an original image 90 degrees\n",
        "ax = fig.add_subplot(2,5,3)\n",
        "rot90_img = tf.image.rot90(resized_img, k=1)\n",
        "ax.imshow(rot90_img)\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 2: Rotate 90', size=14)\n",
        "\n",
        "# invert the resized image\n",
        "ax = fig.add_subplot(2,5,4)\n",
        "inverted_img = util.invert(resized_img)\n",
        "plt.imshow(inverted_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 3: Invert', size=14)\n",
        "\n",
        "# adjust brightness of the resized image\n",
        "ax = fig.add_subplot(2,5,5)\n",
        "bright_img = tf.image.adjust_brightness(resized_img, 0.3)\n",
        "plt.imshow(bright_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 4: Brightness', size=14)\n",
        "\n",
        "# adjust contrast of the brightened image\n",
        "ax = fig.add_subplot(2,5,6)\n",
        "contrast_img = tf.image.adjust_contrast(bright_img, contrast_factor=3)\n",
        "plt.imshow(contrast_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 5: Contrast', size=14)\n",
        "\n",
        "# flip left right of the contrasted image\n",
        "ax = fig.add_subplot(2,5,7)\n",
        "flipped_img = tf.image.flip_left_right(contrast_img)\n",
        "plt.imshow(flipped_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 6: Flip Left Right', size=14)\n",
        "\n",
        "# random noise: function to add random noise of various types to a floating-point image\n",
        "ax = fig.add_subplot(2,5,8)\n",
        "sigma = 0.355\n",
        "noisy_img = random_noise(resized_img, var=sigma**2)\n",
        "plt.imshow(noisy_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 7: Random Noise', size=14)\n",
        "\n",
        "# denoise_tv_chambolle: perform total-variation denoising on n-dimentional images\n",
        "ax = fig.add_subplot(2,5,9)\n",
        "dchambolle_img = denoise_tv_chambolle(resized_img, weight=0.1, multichannel=True)\n",
        "plt.imshow(dchambolle_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 8: Denoise TV Chambolle', size=14)\n",
        "\n",
        "# denoise_wavelet:  perform wavelet denoising on an image\n",
        "ax = fig.add_subplot(2,5,10)\n",
        "dwavelet_img = denoise_wavelet(resized_img, multichannel=True)\n",
        "plt.imshow(dwavelet_img);\n",
        "# ax.axis('off')\n",
        "ax.set_title('Step 9: Denoise Wavelet', size=14);"
      ],
      "metadata": {
        "id": "7d4HILAgEFVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify image data (X) and labels (y)"
      ],
      "metadata": {
        "id": "dqbsZUPHEJ4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_X_and_y(data_pixels, df_data):\n",
        "  X = data_pixels\n",
        "  y = np.array(df_data['class']).flatten()   # no need to flatten here but maybe later on before I feed this to the model \n",
        "  return X, y"
      ],
      "metadata": {
        "id": "PKwcCotDDE9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = define_X_and_y(train_full_img, df_train_full)\n",
        "X_test, y_test = define_X_and_y(test_full_img, df_test_full)\n",
        "X_val, y_val = define_X_and_y(val_full_img, df_val_full)\n",
        "\n",
        "print('X_train: ', X_train.shape, type(X_train))\n",
        "print('X_test: ',X_test.shape, type(X_test))\n",
        "print('X_val: ',X_val.shape, type(X_val))"
      ],
      "metadata": {
        "id": "KGZ3ttrVT9_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomize images (X) and labels (y) \n"
      ],
      "metadata": {
        "id": "5tokO5_18Sxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train[0],'\\n')\n",
        "def shuffle_X_and_y(X, y):\n",
        "  tf.random.set_seed(1234)\n",
        "  np.random.seed(1234)\n",
        "  shuffle = np.random.permutation(np.arange(X_train.shape[0]))      # randomize \n",
        "  return X_train[shuffle], y_train[shuffle]"
      ],
      "metadata": {
        "id": "fCtWX0Q7_1w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = shuffle_X_and_y(X_train, y_train)\n",
        "X_test, y_test = shuffle_X_and_y(X_test, y_test)\n",
        "X_val, y_val = shuffle_X_and_y(X_val, y_val)\n",
        "\n",
        "print('y_val_shuffled:\\n', y_val)\n",
        "print('\\ny_test_shuffled:\\n', y_test)\n",
        "print('\\ny_train: total number of labels = ', len(y_train), type(y_train) ,'\\n', y_train[:5], y_train[-5:])\n",
        "print('\\nX_train: total number of images = ', len(X_train), type(X_train), '\\n', X_train[0])"
      ],
      "metadata": {
        "id": "Rt2UPJSOZkWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize images from (50, 50) to (80, 80) on X"
      ],
      "metadata": {
        "id": "itphNGmDas7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (80,80)\n",
        "X_train = tf.image.resize(X_train, size=image_size)\n",
        "X_test = tf.image.resize(X_test, size=image_size)\n",
        "X_val = tf.image.resize(X_val, size=image_size)\n",
        "print(type(X_train), X_train.shape)\n",
        "print('\\nX_train[0]:\\n',X_train[0])\n"
      ],
      "metadata": {
        "id": "1EDBNjh4arF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to gray scale and normalize images\n",
        "Rescale images to [0,1]"
      ],
      "metadata": {
        "id": "1AikiJ6fcYbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.image.rgb_to_grayscale(X_train)/255.0\n",
        "X_test = tf.image.rgb_to_grayscale(X_test)/255.0\n",
        "X_val = tf.image.rgb_to_grayscale(X_val)/255.0\n",
        "print(X_train.shape)\n",
        "# print(X_train[0])"
      ],
      "metadata": {
        "id": "aBfWdZqWasL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image augmentation on training images\n",
        "- Adjust brightness\n",
        "- Adjust contrast\n",
        "- Flip left and right\n",
        "- Rotate 90 degrees"
      ],
      "metadata": {
        "id": "sxpcYtSPiQnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brightness_delta = 0.3\n",
        "contrast_factor = 3\n",
        "rot_degree = 1               # rotate mapping => key:val = angle:k = {90:1, 180:2, 270:3}\n",
        "\n",
        "# add a set of augmented images to X_train_norm rather than overwrite the existing ones\n",
        "X_train_bright = tf.image.adjust_brightness(X_train, delta=brightness_delta)\n",
        "X_train_contrast = tf.image.adjust_contrast(X_train, contrast_factor=contrast_factor)\n",
        "X_train_flip = tf.image.random_flip_left_right(X_train)\n",
        "X_train_rot90 = tf.image.rot90(X_train, k=rot_degree)            \n",
        "# X_train_invert = util.invert(X_train)\n",
        "# X_train_noise = random_noise(X_train, var=0.355**2)   # sigma = 0.355\n",
        "# dchambolle_img = denoise_tv_chambolle(X_train, weight=0.1, multichannel=True)\n",
        "# X_train_dwavelet = denoise_wavelet(X_train, multichannel=True)"
      ],
      "metadata": {
        "id": "J9Aye3g5ar-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge original training images with the augmented images"
      ],
      "metadata": {
        "id": "e1m4AbsCCUnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate X_train_final with augmented X_train\n",
        "X_train = tf.concat([X_train, \n",
        "                    X_train_bright, \n",
        "                    X_train_contrast, \n",
        "                    X_train_flip,\n",
        "                    X_train_rot90], axis=0)\n",
        "print('X_train with augmentation: ', X_train.shape)\n",
        "\n",
        "# concatenate y_train (the label is preserved)\n",
        "y_train = y_train\n",
        "y_train_bright, y_train_contrast, y_train_flip, y_train_rot90 = y_train, y_train, y_train, y_train\n",
        "y_train = tf.concat([y_train, \n",
        "                    y_train_bright, \n",
        "                    y_train_contrast, \n",
        "                    y_train_flip,\n",
        "                    y_train_rot90], axis=0)\n",
        "print('y_train_bright: ', y_train_bright.shape)\n",
        "print('y_train with augmentation: ', y_train.shape)"
      ],
      "metadata": {
        "id": "SLYMuzo0CT7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffle X_train and y_train\n",
        "Shuffle two tensors in the same order"
      ],
      "metadata": {
        "id": "TkJCVacE5LZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.shape(X_train))\n",
        "shuffle = tf.random.shuffle(tf.range(tf.shape(X_train)[0], dtype=tf.int32))\n",
        "X_train = tf.gather(X_train, shuffle)\n",
        "y_train = tf.gather(y_train, shuffle).numpy()  # also transforms y_train to numpy array"
      ],
      "metadata": {
        "id": "VWx31lrkarjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0][1][1])\n",
        "print(y_train[:100])"
      ],
      "metadata": {
        "id": "d5HzmiT2ljeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display the first 10 train and validation examples with the label of each example as the title"
      ],
      "metadata": {
        "id": "Q9tSF_8q7rt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Print training data examples:')\n",
        "nrows, ncols = 1,5 \n",
        "f, axs = plt.subplots(nrows, ncols, figsize=(19,15))\n",
        "for i in range(ncols):\n",
        "    axs[i].imshow(array_to_img(X_train[i]))\n",
        "    axs[i].set(title=y_train[i])"
      ],
      "metadata": {
        "id": "y4H4Pbawli-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print validation data\n",
        "print('Print validation data examples:')\n",
        "nrows, ncols = 1,5 \n",
        "f, axs = plt.subplots(nrows, ncols, figsize=(19,15))\n",
        "for i in range(ncols):\n",
        "    axs[i].imshow(array_to_img(X_val[i]))\n",
        "    axs[i].set(title=y_val[i])"
      ],
      "metadata": {
        "id": "FBGKsVHC8yV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model using Tensorflow Keras API<br>\n",
        "1) Build model<br>\n",
        "2) Compile model<br>\n",
        "3) Fit model"
      ],
      "metadata": {
        "id": "HQrBgIc-IiYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (80,80,1)\n",
        "filters_1 = 32\n",
        "# filters_2 = 32\n",
        "# filters_3 = 64\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "strides = (1, 1)\n",
        "fully_connected_layer_units = 100\n",
        "dropout_rate = 0.3\n",
        "\n",
        "# 1)  Build model\n",
        "def build_model(activation='tanh',\n",
        "                optimizer='SGD',\n",
        "                learning_rate=0.01):\n",
        "  \n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.random.set_seed(0)\n",
        "\n",
        "  # Building the CNN\n",
        "  model = Sequential()      # initialize the model using Sequential(), which indicates our network will be stacked with different layers\n",
        "\n",
        "  # Define activation function\n",
        "  if activation.lower() == 'leakyrelu':\n",
        "    activation = tf.keras.layers.LeakyReLU(alpha=0.3)    # alpha = Float >= 0. Negative slope coefficient. Default to 0.3\n",
        "  \n",
        "  # Add the convolutional layers\n",
        "  model.add(Conv2D(filters=filters_1, kernel_size=kernel_size, activation=activation, padding='same', input_shape=input_shape))                  # 1st convolutional layer\n",
        "  model.add(MaxPooling2D(pool_size=pool_size, strides=strides))                                                                                 # 1st Pooling\n",
        "  # model.add(Conv2D(filters=filters_2, kernel_size=kernel_size, activation=activation, padding='same'))                                           # 2nd convolutional layer\n",
        "  # model.add(MaxPooling2D(pool_size=pool_size, strides=strides))                                                                                 # 2nd Pooling\n",
        "  # model.add(Conv2D(filters=filters_3, kernel_size=kernel_size, activation=activation, padding='same'))                                           # 3rd convolutional layer\n",
        "  # model.add(MaxPooling2D(pool_size=pool_size, strides=strides))                                                                                 # 3rd Pooling\n",
        "\n",
        "  # Flatten the dataset to feed into a fully connected layer\n",
        "  model.add(Flatten())    \n",
        "\n",
        "  # Fully connected layer\n",
        "  model.add(Dense(units=fully_connected_layer_units,                 # This can be adjusted (a hyper param)\n",
        "                  activation=activation))                            # For the first layer: the number of units or neurons\n",
        "\n",
        "  # Dropout layer\n",
        "  # model.add(Dropout(rate=dropout_rate))\n",
        "  \n",
        "  # Output layer\n",
        "  model.add(Dense(\n",
        "        units=1,                                 # binary output dimension (only one neuron)\n",
        "        # use_bias=True,                           # Alternative: use_bias=False\n",
        "        activation=None))                     # activation='sigmoid'\n",
        "\n",
        "  if optimizer.lower() == 'adam':\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "  elif optimizer.lower() == 'sgd':\n",
        "    optimizer = SGD(learning_rate=learning_rate)   \n",
        "\n",
        "# 2) Compile Model\n",
        "  model.compile(loss=BinaryCrossentropy(from_logits=True),             # for a binary classification\n",
        "                optimizer=optimizer,                    # used to change the attributes of a neural network such as weights and learning rate to reduce the losses.\n",
        "                metrics=['accuracy'])            \n",
        "  print(f'CNN Model:\\nActivation = {activation}\\nOptimizer = {optimizer}\\nlearning_rate = {learning_rate}\\n')\n",
        "  return model"
      ],
      "metadata": {
        "id": "sxT8brxoHqis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "activation='relu'\n",
        "optimizer='sgd'\n",
        "\n",
        "model = build_model(activation=activation,              # relu, leakyrelu, tanh, sigmoid\n",
        "                optimizer=optimizer,                    # adam, [SGD]        \n",
        "                learning_rate=learning_rate)        # 0.1, 0.01, 0.001\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "F1dNPPAEKyo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Fit Model"
      ],
      "metadata": {
        "id": "RqqEKDQxUTP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "\n",
        "print(f'Hyperparameters: \\\n",
        "      \\n\\ttraining_sample_size = {training_sample_size} \\\n",
        "      \\n\\tnum_epochs = {num_epochs} \\\n",
        "      \\n\\tbatch_size = {batch_size} \\\n",
        "      \\n\\timage_size = {image_size} \\\n",
        "      \\n\\tinput_shape = {input_shape} \\\n",
        "      \\n\\tfilters_1 = {filters_1} \\\n",
        "      \\n\\tfully_connected_layer_units = {fully_connected_layer_units} \\\n",
        "      \\n\\tkernel_size = {kernel_size} \\\n",
        "      \\n\\tpool_size = {pool_size} \\\n",
        "      \\n\\tstrides = {strides} \\\n",
        "      \\n\\tlearning_rate = {learning_rate} \\\n",
        "      \\n\\tactivation = {activation} \\\n",
        "      \\n\\toptimizer = {optimizer} \\\n",
        "      \\n\\nImage Agumentation Params: \\\n",
        "      \\n\\tbrightness_delta = {brightness_delta} \\\n",
        "      \\n\\tcontrast_factor = {contrast_factor} \\\n",
        "      \\n\\trot_degree = {rot_degree}\\n')\n",
        "\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "np.random.seed(1234)\n",
        "\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data = (X_val, y_val))"
      ],
      "metadata": {
        "id": "m5wx4yDED2AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot loss and accuracy for training and validation sets"
      ],
      "metadata": {
        "id": "TJjErwA0KHyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = history.history\n",
        "x_arr = np.arange(len(hist['loss'])) + 1\n",
        "# print(x_arr)\n",
        "\n",
        "fig = plt.figure(figsize=(16,6))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.plot(x_arr, hist['loss'], '-o', label='Train Loss')\n",
        "ax.plot(x_arr, hist['val_loss'], '--<', label='Validation Loss')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Loss', size=14)\n",
        "ax.set_title('Loss', size=20)\n",
        "\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.plot(x_arr, hist['accuracy'], '-o', label='Train Acc.')\n",
        "ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation Acc.')\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel('Epoch', size=14)\n",
        "ax.set_ylabel('Accuracy', size=14)\n",
        "ax.set_title('Accuracy', size=20);"
      ],
      "metadata": {
        "id": "KddTvpgPKG8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "EZFVmfn-kn7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {eval_test[1]*100:.2f}%\\n')\n",
        "\n",
        "eval_train = model.evaluate(X_train, y_train)\n",
        "print(f'Train Accuracy: {eval_train[1]*100:.2f}%')"
      ],
      "metadata": {
        "id": "t0SiQn-0kmrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Prediction"
      ],
      "metadata": {
        "id": "SDRX8Oy9AGCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {eval_test[1]*100:.2f}%\\n')\n",
        "\n",
        "eval_train = model.evaluate(X_train, y_train)\n",
        "print(f'Train Accuracy: {eval_train[1]*100:.2f}%')\n",
        "\n",
        "# Transform logits to probabilities\n",
        "pred_logits = model.predict(X_test)\n",
        "probabilities = tf.sigmoid(pred_logits)\n",
        "probabilities = probabilities.numpy().flatten()*100\n",
        "# print(probabilities)"
      ],
      "metadata": {
        "id": "myoOFoqaAI50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Test vs. Predicted"
      ],
      "metadata": {
        "id": "rPP6CK90BQE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,25))\n",
        "\n",
        "for j, example in enumerate(X_test[:20]):\n",
        "    ax = fig.add_subplot(8,4, j+1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.imshow(array_to_img(example))\n",
        "    if y_test[j]==0:\n",
        "        label='Non-IDC'\n",
        "    else:\n",
        "        label='IDC'\n",
        "    \n",
        "    ax.text(\n",
        "        0.5, -0.15, \n",
        "        'True Label: {:s}\\nPr(IDC)={:.0f}%'.format(label, probabilities[j]), \n",
        "        size=14, \n",
        "        color='grey',\n",
        "        horizontalalignment='center',\n",
        "        verticalalignment='center', \n",
        "        transform=ax.transAxes)\n",
        "    \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k4YsAskUBPFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=False,\n",
        "    show_layer_activations=True,\n",
        ")"
      ],
      "metadata": {
        "id": "8U10Myhjtoco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Prediction the most common area that may be detected IDC using patch locations\n",
        "\n"
      ],
      "metadata": {
        "id": "GUKNtN_358aK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features from file names"
      ],
      "metadata": {
        "id": "coT9K_SwVjSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_features(file_list): \n",
        "#   features = []\n",
        "#   for file in file_list:\n",
        "#     str_feat = re.findall(r'\\d+', file)\n",
        "#     int_feat = [int(feat) for feat in str_feat]\n",
        "#     features.append(int_feat)\n",
        "#   df_feat = pd.DataFrame(features, columns=['patient_id', 'd', 'x_coord', 'y_coord', 'class']).drop('d', axis=1)\n",
        "#   df_feat['patch_coord'] = list(zip(df_feat.x_coord, df_feat.y_coord))\n",
        "#   return df_feat[['patient_id','x_coord', 'y_coord', 'patch_coord','class']]\n",
        "\n",
        "\n",
        "# df_features = extract_features(full_data_wo_path)\n",
        "# print(df_features.shape)\n",
        "# display(df_features.head().append(df_features.tail()))"
      ],
      "metadata": {
        "id": "NWcorv_BtX5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_features.info()"
      ],
      "metadata": {
        "id": "DWDHLh8_CXIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomize data \n",
        ": As we may use SGD for training, we will randomize sample of the data for each batch so that the gradient computed is representative."
      ],
      "metadata": {
        "id": "_jaH_54ZzvcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# indexes = np.arange(df_features.shape[0])\n",
        "# print('indexes:', indexes)\n",
        "\n",
        "# np.random.seed(0)    # get the same results each time    ??????\n",
        "# shuffled_indexes = np.random.permutation(indexes)\n",
        "# print('shuffled indexes:', shuffled_indexes, '\\n')\n",
        "\n",
        "# # change the ordering of the original df_features using .reindex()\n",
        "# df_features = df_features.reindex(shuffled_indexes)\n",
        "# display(df_features)"
      ],
      "metadata": {
        "id": "XLxz9aqOdY5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test split (80/20) & Feature Selection"
      ],
      "metadata": {
        "id": "LqVR7YRO5smx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split_boundary = int(df_features.shape[0]*.8)\n",
        "\n",
        "# train = pd.DataFrame(df_features.iloc[:split_boundary, 3:])\n",
        "# test = pd.DataFrame(df_features.iloc[split_boundary:, 3:])\n",
        "\n",
        "# print('Train Shape: ', train.shape, '\\n', train.head(3))\n",
        "# print('\\nTest Shape: ', test.shape, '\\n', test.head(3))"
      ],
      "metadata": {
        "id": "L4s4IiY1-XGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAtuZaJuFyXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}