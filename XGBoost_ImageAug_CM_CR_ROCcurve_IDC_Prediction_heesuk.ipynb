{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heesukjang/W207_AppliedML_Fall2022/blob/main/XGBoost_ImageAug_CM_CR_ROCcurve_IDC_Prediction_heesuk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FALL 2022<br>\n",
        "W207 Applied Machine Learning<br>\n",
        "Heesuk Jang\n",
        " \n",
        "\n",
        "#Predicting IDC with Breast Histopathology Images using CNN\n",
        "\n"
      ],
      "metadata": {
        "id": "5DebDWCL0KeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRkZHKoWswZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668c2ca8-cf07-44be-8a91-ca0fe61648de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from scipy import stats\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import *                            # confusion_matrix, log_loss, accuracy_score\n",
        "from sklearn.model_selection import *                    # train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import *\n",
        "# from sklearn.ensemble import *\n",
        "from sklearn.svm import *\n",
        "from sklearn.linear_model import *                       # LinearRegression\n",
        "from sklearn.discriminant_analysis import *\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import RandomFlip, RandomZoom, RandomRotation, Conv2D, MaxPooling2D, AveragePooling2D, Input, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad, RMSprop\n",
        "from keras.layers import ReLU, LeakyReLU\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, auc\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "tf.get_logger().setLevel('INFO')\n",
        "\n",
        "import cv2 as cv\n",
        "import skimage.io as io\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Optuna and Version Check"
      ],
      "metadata": {
        "id": "2NlEwp6jmZsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --quiet optuna\n",
        "# import optuna\n",
        "# optuna.__version__"
      ],
      "metadata": {
        "id": "vbF2pFtlbJaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enabling and testing the GPU"
      ],
      "metadata": {
        "id": "2JC1sfIYmRuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "lpo1_3kNlzoo",
        "outputId": "f941d604-33b4-4911-8cfc-19cf44fba6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d1680108c58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enabling and testing the TPU"
      ],
      "metadata": {
        "id": "s3LsW0cGnF8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "# try:\n",
        "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# except ValueError:\n",
        "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "metadata": {
        "id": "FlEM5IxwnD4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU"
      ],
      "metadata": {
        "id": "Xqgm8yAcmT7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# import timeit\n",
        "\n",
        "# device_name = tf.test.gpu_device_name()\n",
        "# if device_name != '/device:GPU:0':\n",
        "#   print(\n",
        "#       '\\n\\nThis error most likely means that this notebook is not '\n",
        "#       'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "#       'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "#   raise SystemError('GPU device not found')\n",
        "\n",
        "# def cpu():\n",
        "#   with tf.device('/cpu:0'):\n",
        "#     random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "#     net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "#     return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "# def gpu():\n",
        "#   with tf.device('/device:GPU:0'):\n",
        "#     random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "#     net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "#     return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# # We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "# cpu()\n",
        "# gpu()\n",
        "\n",
        "# # Run the op several times.\n",
        "# print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "#       '(batch x height x width x channel). Sum of ten runs.')\n",
        "# print('CPU (s):')\n",
        "# cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "# print(cpu_time)\n",
        "# print('GPU (s):')\n",
        "# gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "# print(gpu_time)\n",
        "# print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "id": "obujFpYzmIgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip gdrive/MyDrive/Kaggle/CNN_IDC/Dataset.zip\n",
        "\n",
        "#replace these paths with the paths of your \n",
        "val_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Validate'\n",
        "train_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Train'\n",
        "test_image_directory = '/content/gdrive/MyDrive/Kaggle/CNN_IDC/Dataset/Test'\n",
        "directory_path = '/content/gdrive/MyDrive/Kaggle/CNN_IDC'"
      ],
      "metadata": {
        "id": "uyWJuOkZuCVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paths(directory):\n",
        "  all_path = []\n",
        "  idc_image_path = []\n",
        "  idc_image_label = []\n",
        "\n",
        "  for dir, subdir, files in os.walk(directory):\n",
        "    path = dir + \"/\"\n",
        "    all_path.append(path)\n",
        "\n",
        "  for i in range(len(all_path)):\n",
        "    for file in os.listdir(all_path[i]):\n",
        "      test = file\n",
        "      path = all_path[i] + test\n",
        "      if path.lower().endswith('.png'):\n",
        "        idc_image_path.append(path)\n",
        "\n",
        "  for i in range(len(idc_image_path)):\n",
        "    split_test = idc_image_path[i]\n",
        "    split_path = split_test.split(\"/\")\n",
        "    directory_name = split_path[7]\n",
        "    idc_image_label.append('class_' + split_path[8])\n",
        "  return idc_image_path, idc_image_label, directory_name"
      ],
      "metadata": {
        "id": "N892xh1IM4q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths, train_labels, train_dir = get_paths(train_image_directory)\n",
        "val_paths, val_labels, val_dir = get_paths(val_image_directory)\n",
        "test_paths, test_labels, test_dir = get_paths(test_image_directory)"
      ],
      "metadata": {
        "id": "SJ6Cl4wtmxjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[:5])\n",
        "print(train_labels[-5:])\n",
        "\n",
        "print(len(train_paths), len(train_labels))\n",
        "print(len(test_paths), len(test_labels))\n",
        "print(len(val_paths), len(val_labels))"
      ],
      "metadata": {
        "id": "NIf9ETAsmxa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_paths[:2])\n",
        "print(train_labels[:10])\n",
        "print(train_dir)"
      ],
      "metadata": {
        "id": "uCJzEwS8mxSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframes(idc_image_path, idc_image_label, directory_name):\n",
        "  same_name = directory_name.lower() + '_'\n",
        "  #creating the dataframes that we will be passing to our generators\n",
        "  idc_data_cleaned = {'path': idc_image_path,\n",
        "            'label': idc_image_label}\n",
        "  idc_df = pd.DataFrame(idc_data_cleaned)\n",
        "  df = idc_df.sample(frac = 1)\n",
        "  print(df)\n",
        "  csv_path = directory_path\n",
        "  csv_file = df.to_csv(csv_path + '/' + same_name + 'idc_dataframe.csv')\n",
        "  csv_file_path = csv_path + '/' + same_name + 'idc_dataframe.csv'\n",
        "  return csv_file_path"
      ],
      "metadata": {
        "id": "_WU9qt2RmxHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "print('type(train_dataframe): ',type(train_dataframe))\n",
        "train_dataframe"
      ],
      "metadata": {
        "id": "MJxUgm39NeU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe = create_dataframes(train_paths, train_labels, train_dir)\n",
        "train_generator = pd.read_csv(train_dataframe)\n",
        "\n",
        "test_dataframe = create_dataframes(test_paths, test_labels, test_dir)\n",
        "test_generator = pd.read_csv(test_dataframe)\n",
        "\n",
        "val_dataframe = create_dataframes(val_paths, val_labels, val_dir)\n",
        "val_generator = pd.read_csv(val_dataframe)"
      ],
      "metadata": {
        "id": "hnDu_3N4mw1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator"
      ],
      "metadata": {
        "id": "YyKDuRpXPXIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # import tqdm\n",
        "\n",
        "# Apply gray scale to all images, flatten and store array / shape in new columns\n",
        "def get_img_arrays(df,):\n",
        "    # read each image array from corresponding path as grayscale and flatten the image array\n",
        "    df['img_array'] = df.progress_apply(lambda x : io.imread(x['path'],as_gray=True).flatten(),axis=1) # make sure to specify axis = 1\n",
        "    # get the shape of each image array and store it in the dataframe\n",
        "    df['array_shape'] = df.progress_apply(lambda x : x['img_array'].shape[0],axis=1) # make sure to specify axis = 1\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "nkWYjNvnHrrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm # import tqdm\n",
        "tqdm.pandas() # initialize tqdm for pandas\n",
        "\n",
        "# # tqdm is a library that enables you to visualize the progress of a for loop by displaying a configurable progress bar\n",
        "\n",
        "train_generator = get_img_arrays(df = train_generator)\n",
        "val_generator = get_img_arrays(df = val_generator)\n",
        "test_generator = get_img_arrays(df = test_generator)"
      ],
      "metadata": {
        "id": "d9iPVxRZHreQ",
        "outputId": "bf00d73b-3518-4cdf-8b44-ea962a42422c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 785/800 [01:29<00:01,  7.98it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_generator.array_shape.value_counts())\n",
        "# print(val_generator.array_shape.value_counts())\n",
        "# print(test_generator.array_shape.value_counts())"
      ],
      "metadata": {
        "id": "wAv7RXmVQX4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop these images as they add unnecessary noise to our model\n",
        "train_weird_imgs = train_generator[train_generator['array_shape'] != 2500]\n",
        "val_weird_imgs = val_generator[val_generator['array_shape'] != 2500]\n",
        "test_weird_imgs = test_generator[test_generator['array_shape'] != 2500]\n",
        "\n",
        "\n",
        "weird_imgs = train_weird_imgs.append(val_weird_imgs)\n",
        "weird_imgs = weird_imgs.append(test_weird_imgs)\n",
        "weird_imgs['dataset'] = weird_imgs['path'].str.split('/', expand=True)[7]\n",
        "weird_imgs.reset_index(drop=True)\n",
        "\n",
        "train_generator.drop(train_weird_imgs.index,inplace=True)\n",
        "val_generator.drop(val_weird_imgs.index,inplace=True)\n",
        "test_generator.drop(test_weird_imgs.index,inplace=True)\n",
        "\n",
        "# print(len(weird_imgs))\n",
        "# print(len(train_generator))\n",
        "# print(len(val_generator))\n",
        "# print(len(test_generator))\n",
        "# print(train_generator.columns)\n",
        "# val_generator.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "gpOS9_alHrTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import skimage.io as io\n",
        "\n",
        "def display_images(subclass):\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=7, figsize=(20,8))\n",
        "  for idx, ax in enumerate(axes.flat):\n",
        "    image_wo_path = os.path.basename(subclass.path[idx])\n",
        "    # print(image_wo_path)\n",
        "    subtitle = 'Class ' + image_wo_path.rsplit('.')[0][-1] + ': ' + subclass.dataset[idx]\n",
        "    img = io.imread(subclass.path[idx])\n",
        "    ax.imshow(img)\n",
        "    # ax.axis('off')\n",
        "    ax.set_title(subtitle, size=14)   \n",
        "  fig.tight_layout() \n",
        "  plt.show() \n",
        "\n",
        "print()\n",
        "display_images(weird_imgs.reset_index(drop=True))"
      ],
      "metadata": {
        "id": "x9euSsBNHrIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing data using ImageDataGenerator"
      ],
      "metadata": {
        "id": "iHdf3Jd0ipmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://faroit.com/keras-docs/0.3.3/preprocessing/image/\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "def data_generator(target_size = (50,50),\n",
        "                  with_augmented_images=False,\n",
        "                  zca_whitening=False,\n",
        "                  zca_epsilon=1e-06,\n",
        "                  rotation_range=10,                             \n",
        "                  width_shift_range=0.0,\n",
        "                  height_shift_range=0.0,\n",
        "                  brightness_range=None,\n",
        "                  shear_range=0.2,                                  \n",
        "                  zoom_range=0.2,                                \n",
        "                  channel_shift_range=0.0,                       \n",
        "                  fill_mode='nearest',                           \n",
        "                  cval=0.0,\n",
        "                  horizontal_flip=True,\n",
        "                  vertical_flip=False,\n",
        "                  rescale=None):\n",
        "  \n",
        "  with_aug_datagen = ImageDataGenerator(\n",
        "      featurewise_center = True,                     # transforms the images to 0 mean\n",
        "      featurewise_std_normalization = True,          # divide inputs by std of the dataset\n",
        "      zca_whitening=zca_whitening,\n",
        "      zca_epsilon=zca_epsilon,\n",
        "      rotation_range=rotation_range,                 # randomly rotate image by 10 degrees\n",
        "      width_shift_range=width_shift_range,\n",
        "      height_shift_range=height_shift_range,\n",
        "      brightness_range=brightness_range,\n",
        "      shear_range=shear_range,                       # distort image along an axis mostly to create or recify the perception angles     \n",
        "      zoom_range=zoom_range,                         # zomming image: zoom_range > 1 => zoom out, zoom_range < 1 => zoom in\n",
        "      channel_shift_range=channel_shift_range,                       \n",
        "      fill_mode=fill_mode,                           # when the image is rotated, some pixels will move outside the image and leave an empty area that needs to be filled in, 'nearest': simply replace the empty area with the nearest spectral values.\n",
        "      cval=cval,\n",
        "      horizontal_flip=horizontal_flip,\n",
        "      vertical_flip=vertical_flip,\n",
        "      rescale=rescale)                               # rescale=1./255\n",
        "\n",
        "  without_aug_datagen = ImageDataGenerator(\n",
        "      featurewise_center = True,                     \n",
        "      featurewise_std_normalization = True)\n",
        "  \n",
        "# =================================================================\n",
        "  if with_augmented_images:\n",
        "    train_data_generator = with_aug_datagen.flow_from_dataframe(\n",
        "        train_generator,\n",
        "        directory = None,\n",
        "        x_col =  'path',\n",
        "        y_col =  'label',\n",
        "        weight_col=None,\n",
        "        target_size=target_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=1234\n",
        "        # validate_filenames=True\n",
        "    )\n",
        "  else:\n",
        "    train_data_generator = without_aug_datagen.flow_from_dataframe(\n",
        "        train_generator,\n",
        "        directory = None,\n",
        "        x_col =  'path',\n",
        "        y_col =  'label',\n",
        "        weight_col=None,\n",
        "        target_size=target_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode=\"categorical\",\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        seed=1234\n",
        "        # validate_filenames=True\n",
        "    )\n",
        "\n",
        "  validation_data_generator = without_aug_datagen.flow_from_dataframe(\n",
        "      val_generator,\n",
        "      directory = None,\n",
        "      x_col =  'path',\n",
        "      y_col =  'label',\n",
        "      weight_col=None,\n",
        "      target_size=target_size,\n",
        "      color_mode=\"grayscale\",\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=32,\n",
        "      shuffle=True,\n",
        "      seed=1234\n",
        "      # validate_filenames=True\n",
        "  )\n",
        "\n",
        "  test_data_generator = without_aug_datagen.flow_from_dataframe(\n",
        "      test_generator,\n",
        "      directory = None,\n",
        "      x_col =  'path',\n",
        "      y_col =  'label',\n",
        "      weight_col=None,\n",
        "      target_size=target_size,\n",
        "      color_mode=\"grayscale\",\n",
        "      class_mode=\"categorical\",\n",
        "      batch_size=32,\n",
        "      shuffle=True,              # Kesha set to shuffle=True but we don't want to shuffle our testing data around, which it does so by default\n",
        "      seed=1234\n",
        "      # validate_filenames=True\n",
        "  )\n",
        "  return train_data_generator, validation_data_generator, test_data_generator\n",
        "\n",
        "train_data_generator, validation_data_generator, test_data_generator = data_generator(with_augmented_images=False)"
      ],
      "metadata": {
        "id": "eC0S3je4Jnwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build CNN Model"
      ],
      "metadata": {
        "id": "I19l1YOYsfOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 50\n",
        "img_width = 50\n",
        "img_channel = 1\n",
        "input_shape = (img_height, img_width, img_channel)"
      ],
      "metadata": {
        "id": "OQcHdDdYJnol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import ReLU, LeakyReLU\n",
        "\n",
        "# 'Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD'\n",
        "#  Tanh, Leaky ReLU, Parametric ReLU, ELU, GELU, SELU, Swish \n",
        "def build_cnn(kernel_size = (3,3),\n",
        "              strides = (1,1),\n",
        "              pool_size = (2,2),\n",
        "              learning_rate = 0.001,\n",
        "              optimizer = 'Adam',\n",
        "              activation = 'relu',\n",
        "              average_over_position=False,\n",
        "              batch_normalization=True,\n",
        "              dropout_layer=True,\n",
        "              dropout_rate=0.5, \n",
        "              filters_1=32,\n",
        "              filters_2=64,\n",
        "              filters_3=128,\n",
        "              dense_units=256,\n",
        "              conv_layer_2=True,\n",
        "              conv_layer_3=True):    \n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  tf.random.set_seed(0)\n",
        "\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(Conv2D(filters=filters_1, kernel_size=kernel_size, padding='same', activation=activation.lower(), input_shape = input_shape))\n",
        "\n",
        "  def have_batch_normalization(batch_normalization):\n",
        "    if batch_normalization:\n",
        "      model.add(BatchNormalization())\n",
        "\n",
        "  def nn_layer(average_over_position):\n",
        "    if average_over_position:\n",
        "      model.add(GlobalAveragePooling2D(keepdims=True))\n",
        "    else:\n",
        "      model.add(MaxPooling2D(pool_size=pool_size, strides=strides))\n",
        "  \n",
        "  def have_dropout(dropout_layer):\n",
        "    if dropout_layer:\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "  def selected_optimizer(optimizer):\n",
        "    if optimizer.lower() == 'sgd':\n",
        "        return SGD(learning_rate=learning_rate)           # SGD(learning_rate=learning_rate, momentum=0.95, decay=1, nesterov=True)\n",
        "    elif optimizer.lower() == 'adam':\n",
        "        return Adam(learning_rate=learning_rate)          # Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-8, kappa=1-1e-8)\n",
        "    elif optimizer.lower() == 'adadelta':\n",
        "        return Adadelta(learning_rate=learning_rate)      # Adadelta(learning_rate=learning_rate, rho=0.95, epsilon=1e-6)\n",
        "    elif optimizer.lower() == 'adagrad':\n",
        "        return Adagrad(learning_rate=learning_rate)       # Adagrad(learning_rate=learning_rate, epsilon=1e-6)\n",
        "    elif optimizer.lower() == 'rmsprop':\n",
        "        return RMSprop(learning_rate=learning_rate)       # RMSprop(learning_rate=learning_rate, rho=0.9, epsilon=1e-6)\n",
        "\n",
        "  if conv_layer_2:  \n",
        "    model.add(Conv2D(filters=filters_2, kernel_size=kernel_size, padding='same', activation=activation.lower()))\n",
        "    have_batch_normalization(batch_normalization)\n",
        "    nn_layer(average_over_position)\n",
        "    have_dropout(dropout_layer)\n",
        "\n",
        "  if conv_layer_3:  \n",
        "    # model.add(Conv2D(filters=filters_3, kernel_size=kernel_size, padding='same', activation=activation.lower()))\n",
        "    # have_batch_normalization(batch_normalization)\n",
        "    nn_layer(average_over_position)\n",
        "    have_dropout(dropout_layer)\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units = dense_units, activation = activation))\n",
        "  have_dropout(dropout_layer)\n",
        "  model.add(Dense(units = 2, activation = 'softmax'))          # output layer\n",
        "\n",
        "  model.compile(loss=CategoricalCrossentropy(from_logits=True), \n",
        "                optimizer=selected_optimizer(optimizer), \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "model =  build_cnn()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-b-MQQn9Erwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Experiments - Hyperparameter Tuning\n",
        "- **ReduceLROnPlateau**: A scheduling technique that monitors a particular quantity and decays the learning rate when the quantity is stop improving.\n",
        "- **ModelCheckpoint**: A sch\n",
        "- **BatchNormalization**: A feature that we add between the layers of neural network and it continuously takes the output from the previous layer and normalizes it before sending it to the next layer thereby helping stablizing the NN"
      ],
      "metadata": {
        "id": "LIkwGoQkh_Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(target_size=(50,50),    \n",
        "                      with_augmented_images=False,\n",
        "                      zca_whitening=False,\n",
        "                      zca_epsilon=1e-06,\n",
        "                      rotation_range=10,                             \n",
        "                      width_shift_range=0.0,\n",
        "                      height_shift_range=0.0,\n",
        "                      brightness_range=None,\n",
        "                      shear_range=0.2,                                  \n",
        "                      zoom_range=0.2,                                \n",
        "                      channel_shift_range=0.0,                       \n",
        "                      fill_mode='nearest',                           \n",
        "                      cval=0.0,\n",
        "                      horizontal_flip=True,\n",
        "                      vertical_flip=False,\n",
        "                      rescale=None,\n",
        "                      kernel_size = (3,3),\n",
        "                      strides = (1,1),\n",
        "                      pool_size = (2,2),\n",
        "                      learning_rate = 0.001,\n",
        "                      optimizer = 'Adam',                # 'Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD'\n",
        "                      activation = 'relu',               # Tanh, Leaky ReLU, Parametric ReLU, ELU, GELU, SELU, Swish\n",
        "                      average_over_position=False,\n",
        "                      batch_normalization=True,\n",
        "                      dropout_layer=True,\n",
        "                      dropout_rate=0.5, \n",
        "                      filters_1=32,\n",
        "                      filters_2=64,\n",
        "                      filters_3=128,\n",
        "                      dense_units=256,\n",
        "                      conv_layer_2=True,\n",
        "                      conv_layer_3=True,\n",
        "                      num_epochs=7):\n",
        "    \n",
        "    # preprocess the data \n",
        "    train_data_generator, validation_data_generator, test_data_generator = data_generator(\n",
        "                                                                              target_size = target_size,\n",
        "                                                                              with_augmented_images = with_augmented_images,\n",
        "                                                                              zca_whitening = zca_whitening,\n",
        "                                                                              zca_epsilon = zca_epsilon,\n",
        "                                                                              rotation_range = rotation_range,                             \n",
        "                                                                              width_shift_range = width_shift_range,\n",
        "                                                                              height_shift_range = height_shift_range,\n",
        "                                                                              brightness_range = brightness_range,\n",
        "                                                                              shear_range = shear_range,                                  \n",
        "                                                                              zoom_range = zoom_range,                                \n",
        "                                                                              channel_shift_range = channel_shift_range,                       \n",
        "                                                                              fill_mode = fill_mode,                           \n",
        "                                                                              cval = cval,\n",
        "                                                                              horizontal_flip = horizontal_flip,\n",
        "                                                                              vertical_flip = vertical_flip,\n",
        "                                                                              rescale = rescale)\n",
        "    # Build model\n",
        "    model = build_cnn(kernel_size = kernel_size,\n",
        "              strides = strides,\n",
        "              pool_size = pool_size,\n",
        "              learning_rate = learning_rate,\n",
        "              optimizer = optimizer,                # 'Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD'\n",
        "              activation = activation,               # Tanh, Leaky ReLU, Parametric ReLU, ELU, GELU, SELU, Swish\n",
        "              average_over_position = average_over_position,\n",
        "              batch_normalization = batch_normalization,\n",
        "              dropout_layer = dropout_layer,\n",
        "              dropout_rate = dropout_rate, \n",
        "              filters_1 = filters_1,\n",
        "              filters_2 = filters_2,\n",
        "              filters_3 = filters_3,\n",
        "              dense_units = dense_units,\n",
        "              conv_layer_2 = conv_layer_2,\n",
        "              conv_layer_3 = conv_layer_3)\n",
        "\n",
        "    \n",
        "    # Train the model - model.fit\n",
        "    print('\\nTraining...')\n",
        "    lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=0.0001, patience=1, verbose=1)\n",
        "\n",
        "    file_path = 'weights.hdf5'    # save the weights and biases\n",
        "    checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "    history = model.fit(train_data_generator,\n",
        "                      epochs=num_epochs,\n",
        "                      callbacks=[lr_reduce, checkpoint],\n",
        "                      validation_data = validation_data_generator)\n",
        "\n",
        "    \n",
        "    # Plot loss and accuracy on every epoch\n",
        "    hist = history.history\n",
        "    x_arr = np.arange(len(hist['loss'])) + 1\n",
        "\n",
        "    fig = plt.figure(figsize=(16,6))\n",
        "    ax = fig.add_subplot(1,2,1)\n",
        "    ax.plot(x_arr, hist['loss'], '-o', label='Train Loss')\n",
        "    ax.plot(x_arr, hist['val_loss'], '--<', label='Validation Loss')\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.set_xlabel('Epoch', size=14)\n",
        "    ax.set_ylabel('Loss', size=14)\n",
        "    ax.set_title('Loss', size=20)\n",
        "\n",
        "    ax = fig.add_subplot(1,2,2)\n",
        "    ax.plot(x_arr, hist['accuracy'], '-o', label='Train Acc.')\n",
        "    ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation Acc.')\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.set_xlabel('Epoch', size=14)\n",
        "    ax.set_ylabel('Accuracy', size=14)\n",
        "    ax.set_title('Accuracy', size=20);\n",
        "      \n",
        "    # Test accuracy - model.evaluate\n",
        "    test_accuracy = round(model.evaluate(test_data_generator, verbose=0,\n",
        "                             return_dict=True)['accuracy'], 2)\n",
        "    training_accuracy = round(history.history['accuracy'][-1], 2)\n",
        "    val_accuracy = round(history.history['val_accuracy'][-1], 2)\n",
        "    count_params = model.count_params()\n",
        "    \n",
        "    cols = ['num_epochs', 'training_accuracy', 'val_accuracy', 'test_accuracy', 'num_params', 'target_size', 'kernel_size', 'strides', 'pool_size',          \n",
        "            'learning_rate', 'optimizer', 'activation', 'average_over_position', 'batch_normalization', 'dropout_layer', 'dropout_rate', 'filters_1', 'filters_2', 'filters_3',\n",
        "            'dense_units', 'conv_layer_2', 'conv_layer_3', 'with_augmented_images', 'zca_whitening', 'zca_epsilon', 'rotation_range', 'width_shift_range', 'height_shift_range',\n",
        "            'brightness_range', 'shear_range', 'zoom_range', 'channel_shift_range', 'fill_mode', 'cval', 'horizontal_flip', 'vertical_flip', 'rescale']\n",
        "\n",
        "    vals = [num_epochs, training_accuracy, val_accuracy, test_accuracy, f'{count_params:,}', target_size, kernel_size, strides, pool_size,          \n",
        "            learning_rate, optimizer, activation, average_over_position, batch_normalization, dropout_layer, dropout_rate, filters_1, filters_2, filters_3,\n",
        "            dense_units, conv_layer_2, conv_layer_3, with_augmented_images, zca_whitening, zca_epsilon, rotation_range, width_shift_range, height_shift_range,\n",
        "            brightness_range, shear_range, zoom_range, channel_shift_range, fill_mode, cval, horizontal_flip, vertical_flip, rescale]\n",
        "    experiments = pd.DataFrame({'hyper_params':cols, 'value':vals})\n",
        "                                        \n",
        "    return model, experiments.reset_index(drop=True)\n",
        "\n",
        "model, experiments = train_and_evaluate(target_size=(50,50),    \n",
        "                      with_augmented_images=False,\n",
        "                      zca_whitening=False,\n",
        "                      zca_epsilon=1e-06,\n",
        "                      rotation_range=10,                             \n",
        "                      width_shift_range=0.0,\n",
        "                      height_shift_range=0.0,\n",
        "                      brightness_range=None,\n",
        "                      shear_range=0.2,                                  \n",
        "                      zoom_range=0.2,                                \n",
        "                      channel_shift_range=0.0,                       \n",
        "                      fill_mode='nearest',                           \n",
        "                      cval=0.0,\n",
        "                      horizontal_flip=True,\n",
        "                      vertical_flip=False,\n",
        "                      rescale=None,\n",
        "                      kernel_size = (3,3),\n",
        "                      strides = (1,1),\n",
        "                      pool_size = (3,3),\n",
        "                      learning_rate = 0.001,\n",
        "                      optimizer = 'Adam',                # 'Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD'\n",
        "                      activation = 'relu',               # Tanh, Leaky ReLU, Parametric ReLU, ELU, GELU, SELU, Swish\n",
        "                      average_over_position=False,\n",
        "                      batch_normalization=True,\n",
        "                      dropout_layer=True,\n",
        "                      dropout_rate=0.5, \n",
        "                      filters_1=32,\n",
        "                      filters_2=64,\n",
        "                      filters_3=128,\n",
        "                      dense_units=256,\n",
        "                      conv_layer_2=True,\n",
        "                      conv_layer_3=True,\n",
        "                      num_epochs=7)\n",
        "experiments"
      ],
      "metadata": {
        "id": "pUU5bCFmPMQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Cohen Kappa:**</font> a score that expresses the level of agreement between Observed Accuracy with an Expected Accuracy (random chance). value <= 0 means *no agreement* and close to 1 means almsot perfect agreement (the higher ck value, the higher agreement between the OA and EA. \n",
        "- **Zero-One Loss:**</font> return the fraction of misclassifications (float), else it returns the number of misclassifications (int). The best performance is 0."
      ],
      "metadata": {
        "id": "OgDOJv4CAXuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, classification_report\n",
        "\n",
        "def error_analysis(model_name, model, test_labels, test_data_generator):\n",
        "  num_of_test_samples = len(test_labels)\n",
        "  batch_size = 32\n",
        "  classes = ['Non-IDC(0)','IDC(1)']\n",
        "\n",
        "  y_true = test_data_generator.classes\n",
        "  y_pred = model.predict_generator(test_data_generator, num_of_test_samples // batch_size + 1)\n",
        "  y_pred = np.argmax(y_pred, axis=1)     # return the indicies of the max values along the axis (axis=1: each row)\n",
        "\n",
        "  # Confusion matrix  \n",
        "  conf_max = confusion_matrix(y_true, y_pred)\n",
        "  perf_conf_max = conf_max.astype('float')/conf_max.sum(axis=1)[:np.newaxis]*100\n",
        "  df_perf_conf_max = pd.DataFrame(perf_conf_max, index=classes, columns=classes)\n",
        "\n",
        "  plt.figure(figsize=(6,5))\n",
        "  sns.heatmap(df_perf_conf_max, annot=True, cmap='coolwarm', annot_kws={'fontsize':16}, linewidth=0.5, fmt='.0f')  \n",
        "  plt.xlabel('Predicted Label', fontsize=14)\n",
        "  plt.ylabel('True Label', fontsize=14)\n",
        "  plt.title('Confusion Matrix (%)', fontsize=15)\n",
        "  \n",
        "  # Classification report\n",
        "  print('=============== Classification Report ===============\\n\\n', classification_report(y_true, y_pred, target_names=['Non-IDC', 'IDC']), '\\n=====================================================\\n')\n",
        "  \n",
        "  # Cross validation score\n",
        "  # cv = ShuffleSplit(n_splits=100, test_size=.25, random_state=0)\n",
        "  # cv_score = np.median(cross_val_score(model, y_true, y_pred, cv=cv))*100\n",
        "  # print('cv_score = ',cv_score)\n",
        "\n",
        "  # Precision, recall, and f1_score\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()     # np.ravel(): returns contiguous flattened array (1D array with all the input-array elements and with the same type as it)\n",
        "  accuracy = round(accuracy_score(y_true, y_pred), 2)\n",
        "  precision = round(precision_score(y_true, y_pred), 2)\n",
        "  recall = round(recall_score(y_true, y_pred), 2)\n",
        "  f1score = round((2*precision*recall)/(precision+recall), 2)\n",
        "\n",
        "  # cohen_kappa score and zero_one loss\n",
        "  cohen_kappa = round(cohen_kappa_score(y_true, y_pred), 2)\n",
        "  zo_loss = round(zero_one_loss(y_true, y_pred), 2)\n",
        "\n",
        "  # Area under the ROC cuver\n",
        "  roc_log = roc_auc_score(y_true, y_pred)\n",
        "  false_positive_rate, true_positive_rate, threshold = roc_curve(y_true, y_pred)\n",
        "  area_under_curve = round(auc(false_positive_rate, true_positive_rate), 2)\n",
        "\n",
        "  plt.figure(figsize=(6,5))\n",
        "  plt.plot([0, 1], [0, 1], 'r--')  \n",
        "  plt.plot(false_positive_rate, true_positive_rate, label='ROC-AUC = {:.2f}'.format(area_under_curve))  \n",
        "  plt.xlabel('False positive rate', fontsize=14)\n",
        "  plt.ylabel('True positive rate', fontsize=14)\n",
        "  plt.title('ROC Curve', fontsize=18)\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "  # plt.savefig(ROC_PLOT_FILE, bbox_inches='tight')\n",
        "  plt.close()\n",
        "\n",
        "  model_summary = pd.DataFrame({'Model':model_name,\n",
        "                                'Accuracy': accuracy,\n",
        "                                'Precision': precision,\n",
        "                                'Recall': recall,\n",
        "                                'F1_score': f1score,\n",
        "                                'ROC-AUC score': area_under_curve,\n",
        "                                'Cohen Kappa': cohen_kappa,\n",
        "                                'Zero-One Loss': zo_loss}, index=[0]) \n",
        "  return model_summary\n",
        "  \n",
        "error_analysis('CNN', model, test_labels, test_data_generator)"
      ],
      "metadata": {
        "id": "Ecu2NAgsjmPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "- **ResNet152V2**\n",
        "- **VGG16**\n",
        "- **VGG19**"
      ],
      "metadata": {
        "id": "BvAUHEGdGpLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet152V2, VGG16, VGG19\n",
        "\n",
        "# https://keras.io/api/applications/\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "input_shape = (50,50,3)\n",
        "vgg16_base_model = VGG16(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "vgg19_base_model = VGG19(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "resnet_base_model = ResNet152V2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "\n",
        "# vgg16_base_model.summary()\n",
        "# vgg19_base_model.summary()\n",
        "# resnet_base_model.summary()"
      ],
      "metadata": {
        "id": "eo-HTvErGn6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_tl(model_tl):\n",
        "  return tf.keras.Sequential([\n",
        "                           model_tl,                           \n",
        "                           Flatten(),\n",
        "\n",
        "                           Dense(units = 1024, activation = 'relu'),\n",
        "                           BatchNormalization(),                           \n",
        "                           Dropout(rate=0.5),\n",
        "\n",
        "                           Dense(units = 128, activation = 'relu'),\n",
        "                           BatchNormalization(),                           \n",
        "                           Dropout(rate=0.4),\n",
        "\n",
        "                           Dense(units = 2, activation = 'softmax')\n",
        "])  "
      ],
      "metadata": {
        "id": "RO1VFoNBJhVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze initial layer of the network, making only the fully connected layer we added trainable\n",
        "vgg16_base_model.trainable = False\n",
        "vgg19_base_model.trainable = False\n",
        "resnet_base_model.trainable = False\n",
        "\n",
        "# run each model\n",
        "model_vgg16 = build_cnn_tl(vgg16_base_model)\n",
        "model_vgg19 = build_cnn_tl(vgg19_base_model)\n",
        "model_resnet = build_cnn_tl(resnet_base_model)"
      ],
      "metadata": {
        "id": "rA2dAeLpWPKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_compile_tl(model_tl, optimizer='Adam', learning_rate = 0.001):\n",
        "  # select optimizer\n",
        "  def selected_optimizer(optimizer):\n",
        "      if optimizer.lower() == 'sgd':\n",
        "          return SGD(learning_rate=learning_rate)\n",
        "      if optimizer.lower() == 'adam':\n",
        "          return Adam(learning_rate=learning_rate)\n",
        "\n",
        "  model_tl.compile(optimizer=selected_optimizer(optimizer), \n",
        "                      loss=keras.losses.categorical_crossentropy, \n",
        "                      metrics=['accuracy'])\n",
        "  model_tl.summary()\n",
        "  return model_tl\n",
        "\n",
        "model_vgg16 = model_compile_tl(model_vgg16, optimizer='Adam', learning_rate = 0.001)\n",
        "# model_vgg19 = model_compile_tl(model_vgg19, optimizer='Adam', learning_rate = 0.001)\n",
        "model_resnet = model_compile_tl(model_resnet, optimizer='Adam', learning_rate = 0.001)"
      ],
      "metadata": {
        "id": "SoRNd0QyXCSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def model_fit_tl(model_tl, train_data_generator, validation_data_generator, epochs=10):\n",
        "#   lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=0.0001, patience=1, verbose=1)\n",
        "\n",
        "#   file_path = 'weights.hdf5'    # save the weights and biases\n",
        "#   checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "#   history = model_tl.fit(np.repeat(train_data_generator, 3, -1),\n",
        "#                   epochs = epochs,\n",
        "#                   callbacks = [lr_reduce, checkpoint],\n",
        "#                   validation_data = np.repeat(validation_data_generator, 3, -1))\n",
        "#   return history\n",
        "# history_tl = model_fit_tl(model_vgg16, train_data_generator, validation_data_generator, 10)"
      ],
      "metadata": {
        "id": "3Qt3ZM7nzh3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def model_fit_and_plot_loss_acc(model_tl):\n",
        "#   history = model_fit_tl(model_tl, train_data_generator, validation_data_generator, 10)\n",
        "#   hist = history.history\n",
        "#   x_arr = np.arange(len(hist['loss'])) + 1\n",
        "\n",
        "#   fig = plt.figure(figsize=(16,6))\n",
        "#   ax = fig.add_subplot(1,2,1)\n",
        "#   ax.plot(x_arr, hist['loss'], '-o', label='Train Loss')\n",
        "#   ax.plot(x_arr, hist['val_loss'], '--<', label='Validation Loss')\n",
        "#   ax.legend(fontsize=12)\n",
        "#   ax.set_xlabel('Epoch', size=14)\n",
        "#   ax.set_ylabel('Loss', size=14)\n",
        "#   ax.set_title('Loss', size=20)\n",
        "\n",
        "#   ax = fig.add_subplot(1,2,2)\n",
        "#   ax.plot(x_arr, hist['accuracy'], '-o', label='Train Acc.')\n",
        "#   ax.plot(x_arr, hist['val_accuracy'], '--<', label='Validation Acc.')\n",
        "#   ax.legend(fontsize=12)\n",
        "#   ax.set_xlabel('Epoch', size=14)\n",
        "#   ax.set_ylabel('Accuracy', size=14)\n",
        "#   ax.set_title('Accuracy', size=20);\n",
        "\n",
        "# # model_fit_and_plot_loss_acc(model_vgg16)\n",
        "# # model_fit_and_plot_loss_acc(model_vgg19)\n",
        "# model_fit_and_plot_loss_acc(model_vgg16)"
      ],
      "metadata": {
        "id": "KEg8SJsb-L2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_compile_tl(model_resnet, optimizer='Adam', learning_rate = 0.001)\n",
        "# model_fit_tl(model_resnet, train_data_generator, validation_data_generator, epochs=7)\n",
        "# plot_loss_acc(history_tl)\n",
        "# model_evaluate(model_resnet, train_data_generator, test_data_generator)\n",
        "# error_analysis(test_labels, test_data_generator)"
      ],
      "metadata": {
        "id": "7aLGM0Ya2VFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_loss_acc(history_tl)"
      ],
      "metadata": {
        "id": "w2oFzLEpXN9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_evaluate(model_resnet, train_data_generator, test_data_generator)"
      ],
      "metadata": {
        "id": "OCISMTYyXakg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error_analysis(test_labels, test_data_generator)"
      ],
      "metadata": {
        "id": "mTkPSXVaYYr7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}